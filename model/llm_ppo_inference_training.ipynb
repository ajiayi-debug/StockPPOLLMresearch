{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce0441a4",
   "metadata": {},
   "source": [
    "# PPO Training for Stock Price Prediction inference\n",
    "\n",
    "This notebook handles the PPO (Proximal Policy Optimization) training component of the two-stage framework.\n",
    "\n",
    "## Prerequisites:\n",
    "- Run `llm_ppo_stock_prediction.ipynb` first to generate LLM predictions\n",
    "- Ensure checkpoint files exist in `../results/` directory\n",
    "\n",
    "## What this notebook does:\n",
    "1. Loads LLM prediction checkpoints\n",
    "2. Prepares data for PPO training\n",
    "3. Defines risk-aware environment\n",
    "4. Trains PPO agent\n",
    "5. Applies PPO adjustments to predictions\n",
    "6. Evaluates results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5b6857",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4b57ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: stable-baselines3[extra] in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (2.7.0)\n",
      "Requirement already satisfied: gymnasium<1.3.0,>=0.29.1 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from stable-baselines3[extra]) (0.29.1)\n",
      "Requirement already satisfied: numpy<3.0,>=1.20 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from stable-baselines3[extra]) (2.2.6)\n",
      "Requirement already satisfied: torch<3.0,>=2.3 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from stable-baselines3[extra]) (2.9.0)\n",
      "Requirement already satisfied: cloudpickle in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from stable-baselines3[extra]) (3.1.1)\n",
      "Requirement already satisfied: pandas in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from stable-baselines3[extra]) (2.3.2)\n",
      "Requirement already satisfied: matplotlib in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from stable-baselines3[extra]) (3.10.6)\n",
      "Requirement already satisfied: opencv-python in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from stable-baselines3[extra]) (4.12.0.88)\n",
      "Requirement already satisfied: pygame in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from stable-baselines3[extra]) (2.6.1)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from stable-baselines3[extra]) (2.20.0)\n",
      "Requirement already satisfied: psutil in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from stable-baselines3[extra]) (7.1.0)\n",
      "Requirement already satisfied: tqdm in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from stable-baselines3[extra]) (4.67.1)\n",
      "Requirement already satisfied: rich in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from stable-baselines3[extra]) (14.2.0)\n",
      "Requirement already satisfied: ale-py>=0.9.0 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from stable-baselines3[extra]) (0.11.2)\n",
      "Requirement already satisfied: pillow in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from stable-baselines3[extra]) (11.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3[extra]) (4.15.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3[extra]) (0.0.4)\n",
      "Requirement already satisfied: filelock in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.19.1)\n",
      "Requirement already satisfied: setuptools in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2025.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch<3.0,>=2.3->stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.3.1)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.76.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.9)\n",
      "Requirement already satisfied: packaging in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (6.32.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from matplotlib->stable-baselines3[extra]) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from matplotlib->stable-baselines3[extra]) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from matplotlib->stable-baselines3[extra]) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from matplotlib->stable-baselines3[extra]) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from matplotlib->stable-baselines3[extra]) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3[extra]) (1.17.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from rich->stable-baselines3[extra]) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from rich->stable-baselines3[extra]) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
      "Requirement already satisfied: setuptools in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2025.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch<3.0,>=2.3->stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.3.1)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.76.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.9)\n",
      "Requirement already satisfied: packaging in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (6.32.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from matplotlib->stable-baselines3[extra]) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from matplotlib->stable-baselines3[extra]) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from matplotlib->stable-baselines3[extra]) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from matplotlib->stable-baselines3[extra]) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from matplotlib->stable-baselines3[extra]) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3[extra]) (1.17.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from rich->stable-baselines3[extra]) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from rich->stable-baselines3[extra]) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required packages for progress bar\n",
    "!pip install \"stable-baselines3[extra]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5190688d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# HTTP requests for HF endpoint\n",
    "import requests\n",
    "\n",
    "# Environment variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Reinforcement Learning\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "# Progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce747fd7",
   "metadata": {},
   "source": [
    "## 2. Load Data and Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d88e0414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 8698\n",
      "Validation samples: 1243\n",
      "Test samples: 2477\n"
     ]
    }
   ],
   "source": [
    "# Load original JSONL data\n",
    "def load_jsonl(filepath):\n",
    "    \"\"\"Load JSONL file\"\"\"\n",
    "    data = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "train_data = load_jsonl('../finetune_paper/train.jsonl')\n",
    "val_data = load_jsonl('../finetune_paper/val.jsonl')\n",
    "test_data = load_jsonl('../finetune_paper/test.jsonl')\n",
    "\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Validation samples: {len(val_data)}\")\n",
    "print(f\"Test samples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c685a5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation functions defined.\n"
     ]
    }
   ],
   "source": [
    "def safe_float(value, default=0.0) -> float:\n",
    "    \"\"\"Safely convert a value to float.\"\"\"\n",
    "    try:\n",
    "        return float(value)\n",
    "    except (TypeError, ValueError):\n",
    "        return float(default)\n",
    "\n",
    "def parse_prompt_data(prompt_text):\n",
    "    \"\"\"Extract key information from prompt text.\"\"\"\n",
    "    lines = prompt_text.split('\\n')\n",
    "    data = {}\n",
    "    \n",
    "    for line in lines:\n",
    "        if 'TICKER:' in line:\n",
    "            data['ticker'] = line.split('TICKER:')[1].strip()\n",
    "        elif 'DATE:' in line:\n",
    "            data['date'] = line.split('DATE:')[1].strip()\n",
    "        elif 'RECENT CLOSING PRICES' in line:\n",
    "            if ':' in line:\n",
    "                prices_part = line.split(':', 1)[1].strip()\n",
    "                if '(' in prices_part:\n",
    "                    prices_part = prices_part.split('(')[0].strip()\n",
    "                try:\n",
    "                    data['recent_prices'] = [float(p.strip()) for p in prices_part.split(',') if p.strip()]\n",
    "                except ValueError:\n",
    "                    data['recent_prices'] = []\n",
    "    \n",
    "    return data\n",
    "\n",
    "print(\"Data preparation functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7620c363",
   "metadata": {},
   "source": [
    "## 3. Data Preparation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b786949e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data from ../results/llm_predictions_checkpoint.json...\n",
      "Successfully prepared 2477 test samples.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>recent_prices</th>\n",
       "      <th>llm_prediction</th>\n",
       "      <th>actual_price</th>\n",
       "      <th>llm_likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HSBC</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>[31.07, 31.03, 31.21, 31.16, 31.63]</td>\n",
       "      <td>31.63</td>\n",
       "      <td>32.680000</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0700.HK</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>[304.1191, 309.8178, 318.3658, 317.226, 327.8636]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>342.870056</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PEP</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>[183.07, 181.75, 181.98, 180.66, 179.41]</td>\n",
       "      <td>181.00</td>\n",
       "      <td>178.970001</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>[130.03, 126.04, 129.61, 129.93, 125.07]</td>\n",
       "      <td>130.03</td>\n",
       "      <td>126.360001</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7203.T</td>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>[1817.5, 1819.0, 1817.0, 1812.5, 1799.0]</td>\n",
       "      <td>1817.50</td>\n",
       "      <td>1807.500000</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker        date                                      recent_prices  \\\n",
       "0     HSBC  2023-01-03                [31.07, 31.03, 31.21, 31.16, 31.63]   \n",
       "1  0700.HK  2023-01-03  [304.1191, 309.8178, 318.3658, 317.226, 327.8636]   \n",
       "2      PEP  2023-01-03           [183.07, 181.75, 181.98, 180.66, 179.41]   \n",
       "3     AAPL  2023-01-03           [130.03, 126.04, 129.61, 129.93, 125.07]   \n",
       "4   7203.T  2023-01-04           [1817.5, 1819.0, 1817.0, 1812.5, 1799.0]   \n",
       "\n",
       "   llm_prediction  actual_price  llm_likelihood  \n",
       "0           31.63     32.680000             0.8  \n",
       "1            0.00    342.870056             0.0  \n",
       "2          181.00    178.970001             0.7  \n",
       "3          130.03    126.360001             0.5  \n",
       "4         1817.50   1807.500000             0.8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare test data from checkpoint\n",
    "print(\"Loading test data from ../results/llm_predictions_checkpoint.json...\")\n",
    "try:\n",
    "    with open('../results/llm_predictions_checkpoint.json', 'r') as f:\n",
    "        test_checkpoint = json.load(f)\n",
    "    test_llm_results = test_checkpoint.get('llm_results', [])\n",
    "\n",
    "    test_parsed = []\n",
    "    for idx, item in enumerate(test_data):\n",
    "        if idx >= len(test_llm_results): break\n",
    "        parsed = parse_prompt_data(item['prompt'])\n",
    "        response = json.loads(item['response'])\n",
    "        llm_output = test_llm_results[idx]\n",
    "\n",
    "        if isinstance(llm_output, dict) and llm_output.get('predicted_close') is not None:\n",
    "            parsed['llm_prediction'] = safe_float(llm_output.get('predicted_close'), response['predicted_close'])\n",
    "        else:\n",
    "            parsed['llm_prediction'] = response['predicted_close']\n",
    "\n",
    "        parsed['actual_price'] = response['predicted_close']\n",
    "        parsed['llm_likelihood'] = safe_float(llm_output.get('likelihood') if isinstance(llm_output, dict) else None, 0.5)\n",
    "        test_parsed.append(parsed)\n",
    "\n",
    "    test_df = pd.DataFrame(test_parsed)\n",
    "    if 'recent_prices' not in test_df.columns:\n",
    "        test_df['recent_prices'] = test_df['llm_prediction'].apply(lambda x: [float(x)] * 5 if pd.notna(x) else [0.0] * 5)\n",
    "    test_df['llm_prediction'].fillna(test_df['actual_price'], inplace=True)\n",
    "    test_df['llm_likelihood'].fillna(0.5, inplace=True)\n",
    "    print(f\"Successfully prepared {len(test_df)} test samples.\")\n",
    "    display(test_df.head())\n",
    "except Exception as e:\n",
    "    print(f\"Error loading test checkpoint: {e}\")\n",
    "    test_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30f552c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data from ../results/llm_predictions_val_checkpoint.json...\n",
      "Successfully prepared 1243 validation samples.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>recent_prices</th>\n",
       "      <th>llm_prediction</th>\n",
       "      <th>actual_price</th>\n",
       "      <th>llm_likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0700.HK</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>[415.2041, 410.0417, 408.7512, 421.104, 418.3385]</td>\n",
       "      <td>420.00</td>\n",
       "      <td>414.835388</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HSBC</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>[30.15, 30.22, 30.17, 30.15, 30.45]</td>\n",
       "      <td>30.15</td>\n",
       "      <td>31.820000</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>[179.29, 179.38, 178.2, 177.57, 182.01]</td>\n",
       "      <td>179.29</td>\n",
       "      <td>179.699997</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PEP</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>[172.36, 172.97, 172.67, 173.71, 172.98]</td>\n",
       "      <td>173.00</td>\n",
       "      <td>173.229996</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>[179.38, 178.2, 177.57, 182.01, 179.7]</td>\n",
       "      <td>179.38</td>\n",
       "      <td>174.919998</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker        date                                      recent_prices  \\\n",
       "0  0700.HK  2022-01-03  [415.2041, 410.0417, 408.7512, 421.104, 418.3385]   \n",
       "1     HSBC  2022-01-03                [30.15, 30.22, 30.17, 30.15, 30.45]   \n",
       "2     AAPL  2022-01-03            [179.29, 179.38, 178.2, 177.57, 182.01]   \n",
       "3      PEP  2022-01-03           [172.36, 172.97, 172.67, 173.71, 172.98]   \n",
       "4     AAPL  2022-01-04             [179.38, 178.2, 177.57, 182.01, 179.7]   \n",
       "\n",
       "   llm_prediction  actual_price  llm_likelihood  \n",
       "0          420.00    414.835388             0.8  \n",
       "1           30.15     31.820000             0.8  \n",
       "2          179.29    179.699997             0.8  \n",
       "3          173.00    173.229996             0.8  \n",
       "4          179.38    174.919998             0.8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare validation data from checkpoint\n",
    "print(\"Loading validation data from ../results/llm_predictions_val_checkpoint.json...\")\n",
    "try:\n",
    "    with open('../results/llm_predictions_val_checkpoint.json', 'r') as f:\n",
    "        val_checkpoint = json.load(f)\n",
    "    val_llm_results = val_checkpoint.get('llm_results', [])\n",
    "\n",
    "    val_parsed = []\n",
    "    for idx, item in enumerate(val_data):\n",
    "        if idx >= len(val_llm_results): break\n",
    "        parsed = parse_prompt_data(item['prompt'])\n",
    "        response = json.loads(item['response'])\n",
    "        llm_output = val_llm_results[idx]\n",
    "\n",
    "        if isinstance(llm_output, dict) and llm_output.get('predicted_close') is not None:\n",
    "            parsed['llm_prediction'] = safe_float(llm_output.get('predicted_close'), response['predicted_close'])\n",
    "        else:\n",
    "            parsed['llm_prediction'] = response['predicted_close']\n",
    "\n",
    "        parsed['actual_price'] = response['predicted_close']\n",
    "        parsed['llm_likelihood'] = safe_float(llm_output.get('likelihood') if isinstance(llm_output, dict) else None, 0.5)\n",
    "        val_parsed.append(parsed)\n",
    "\n",
    "    val_df_ppo = pd.DataFrame(val_parsed)\n",
    "    if 'recent_prices' not in val_df_ppo.columns:\n",
    "        val_df_ppo['recent_prices'] = val_df_ppo['llm_prediction'].apply(lambda x: [float(x)] * 5 if pd.notna(x) else [0.0] * 5)\n",
    "    val_df_ppo['llm_prediction'].fillna(val_df_ppo['actual_price'], inplace=True)\n",
    "    val_df_ppo['llm_likelihood'].fillna(0.5, inplace=True)\n",
    "    print(f\"Successfully prepared {len(val_df_ppo)} validation samples.\")\n",
    "    display(val_df_ppo.head())\n",
    "except Exception as e:\n",
    "    print(f\"Error loading validation checkpoint: {e}\")\n",
    "    val_df_ppo = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "962a3fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data from ../results/llm_predictions_train_checkpoint.json...\n",
      "Successfully prepared 8698 training samples.\n",
      "Successfully prepared 8698 training samples.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>recent_prices</th>\n",
       "      <th>llm_prediction</th>\n",
       "      <th>actual_price</th>\n",
       "      <th>llm_likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-16</td>\n",
       "      <td>[27.3125, 27.555, 27.45, 26.705, 26.4975]</td>\n",
       "      <td>27.312500</td>\n",
       "      <td>27.180000</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HSBC</td>\n",
       "      <td>2015-01-16</td>\n",
       "      <td>[45.62, 45.71, 45.24, 45.26, 45.24]</td>\n",
       "      <td>45.620000</td>\n",
       "      <td>45.360001</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0700.HK</td>\n",
       "      <td>2015-01-16</td>\n",
       "      <td>[117.168, 117.8133, 116.1539, 116.9836, 112.3743]</td>\n",
       "      <td>113.078837</td>\n",
       "      <td>113.388344</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PEP</td>\n",
       "      <td>2015-01-16</td>\n",
       "      <td>[96.42, 96.35, 96.67, 96.67, 97.29]</td>\n",
       "      <td>97.290000</td>\n",
       "      <td>97.510002</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0700.HK</td>\n",
       "      <td>2015-01-19</td>\n",
       "      <td>[117.8133, 116.1539, 116.9836, 112.3743, 113.3...</td>\n",
       "      <td>113.388300</td>\n",
       "      <td>114.402382</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker        date                                      recent_prices  \\\n",
       "0     AAPL  2015-01-16          [27.3125, 27.555, 27.45, 26.705, 26.4975]   \n",
       "1     HSBC  2015-01-16                [45.62, 45.71, 45.24, 45.26, 45.24]   \n",
       "2  0700.HK  2015-01-16  [117.168, 117.8133, 116.1539, 116.9836, 112.3743]   \n",
       "3      PEP  2015-01-16                [96.42, 96.35, 96.67, 96.67, 97.29]   \n",
       "4  0700.HK  2015-01-19  [117.8133, 116.1539, 116.9836, 112.3743, 113.3...   \n",
       "\n",
       "   llm_prediction  actual_price  llm_likelihood  \n",
       "0       27.312500     27.180000             0.8  \n",
       "1       45.620000     45.360001             0.8  \n",
       "2      113.078837    113.388344             0.5  \n",
       "3       97.290000     97.510002             0.8  \n",
       "4      113.388300    114.402382             0.8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare training data from checkpoint\n",
    "print(\"Loading training data from ../results/llm_predictions_train_checkpoint.json...\")\n",
    "try:\n",
    "    with open('../results/llm_predictions_train_checkpoint.json', 'r') as f:\n",
    "        train_checkpoint = json.load(f)\n",
    "    train_llm_results = train_checkpoint.get('llm_results', [])\n",
    "\n",
    "    train_parsed = []\n",
    "    for idx, item in enumerate(train_data):\n",
    "        if idx >= len(train_llm_results): break\n",
    "        parsed = parse_prompt_data(item['prompt'])\n",
    "        response = json.loads(item['response'])\n",
    "        llm_output = train_llm_results[idx]\n",
    "\n",
    "        if isinstance(llm_output, dict) and llm_output.get('predicted_close') is not None:\n",
    "            parsed['llm_prediction'] = safe_float(llm_output.get('predicted_close'), response['predicted_close'])\n",
    "        else:\n",
    "            parsed['llm_prediction'] = response['predicted_close']\n",
    "        \n",
    "        parsed['actual_price'] = response['predicted_close']\n",
    "        parsed['llm_likelihood'] = safe_float(llm_output.get('likelihood') if isinstance(llm_output, dict) else None, 0.5)\n",
    "        train_parsed.append(parsed)\n",
    "\n",
    "    train_df_ppo = pd.DataFrame(train_parsed)\n",
    "    if 'recent_prices' not in train_df_ppo.columns:\n",
    "        train_df_ppo['recent_prices'] = train_df_ppo['llm_prediction'].apply(lambda x: [float(x)] * 5 if pd.notna(x) else [0.0] * 5)\n",
    "    train_df_ppo['llm_prediction'].fillna(train_df_ppo['actual_price'], inplace=True)\n",
    "    train_df_ppo['llm_likelihood'].fillna(0.5, inplace=True)\n",
    "    print(f\"Successfully prepared {len(train_df_ppo)} training samples.\")\n",
    "    display(train_df_ppo.head())\n",
    "except Exception as e:\n",
    "    print(f\"Error loading training checkpoint: {e}\")\n",
    "    train_df_ppo = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae9da74",
   "metadata": {},
   "source": [
    "## 4. Risk Metrics Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "970c350c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risk metrics functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Financial Risk Metrics\n",
    "def calculate_var(returns: np.ndarray, confidence_level: float = 0.95) -> float:\n",
    "    \"\"\"Calculate Value at Risk (VaR)\"\"\"\n",
    "    if len(returns) == 0:\n",
    "        return 0.0\n",
    "    return np.percentile(returns, (1 - confidence_level) * 100)\n",
    "\n",
    "def calculate_cvar(returns: np.ndarray, confidence_level: float = 0.95) -> float:\n",
    "    \"\"\"Calculate Conditional Value at Risk (CVaR) - Expected Shortfall\"\"\"\n",
    "    if len(returns) == 0:\n",
    "        return 0.0\n",
    "    var = calculate_var(returns, confidence_level)\n",
    "    tail_losses = returns[returns <= var]\n",
    "    if len(tail_losses) == 0:\n",
    "        return var\n",
    "    return np.mean(tail_losses)\n",
    "\n",
    "def calculate_volatility(prices: np.ndarray) -> float:\n",
    "    \"\"\"Calculate price volatility (standard deviation of returns)\"\"\"\n",
    "    if len(prices) < 2:\n",
    "        return 0.0\n",
    "    returns = np.diff(prices) / prices[:-1]\n",
    "    return np.std(returns)\n",
    "\n",
    "print(\"Risk metrics functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0336e3b6",
   "metadata": {},
   "source": [
    "## 5. PPO Environment with NaN Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029cc1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Prediction Environment defined.\n"
     ]
    }
   ],
   "source": [
    "# Custom Gym Environment for Stock Price Prediction with PPO\n",
    "class StockPredictionEnv(gym.Env):\n",
    "    \"\"\"Custom Environment for Risk-Aware Stock Price Prediction without justification features\"\"\"\n",
    "    \n",
    "    def __init__(self, data_df: pd.DataFrame, window_size: int = 5, directional_bonus_weight: float = 0.5):\n",
    "        super(StockPredictionEnv, self).__init__()\n",
    "        \n",
    "        self.data = data_df.copy()\n",
    "        self.window_size = window_size\n",
    "        self.current_step = 0\n",
    "        self.max_steps = len(self.data)\n",
    "        self.directional_bonus_weight = directional_bonus_weight\n",
    "        \n",
    "        # State: [llm_prediction, hist_prices, volatility, var, llm_likelihood, llm_trend]\n",
    "        state_dim = 1 + window_size + 2 + 1 + 1\n",
    "        \n",
    "        # Action space: adjustment factor (continuous)\n",
    "        self.action_space = spaces.Box(\n",
    "            low=-0.02, high=0.02, shape=(1,), dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        # Observation space\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf, shape=(state_dim,), dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        # Risk parameters\n",
    "        self.lambda_risk = 5.0\n",
    "        self.confidence_level = 0.95\n",
    "        \n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.current_step = self.window_size\n",
    "        return self._get_observation(), {}\n",
    "    \n",
    "    def _get_observation(self):\n",
    "        \"\"\"Construct state representation with NaN handling\"\"\"\n",
    "        idx = min(self.current_step, self.max_steps - 1)\n",
    "        \n",
    "        llm_pred = float(self.data.iloc[idx]['llm_prediction'])\n",
    "        if np.isnan(llm_pred) or np.isinf(llm_pred):\n",
    "            llm_pred = float(self.data.iloc[idx]['actual_price'])\n",
    "        \n",
    "        hist_prices = []\n",
    "        if 'recent_prices' in self.data.columns and self.data.iloc[idx]['recent_prices'] is not None:\n",
    "            try:\n",
    "                hist_prices = [float(p) for p in self.data.iloc[idx]['recent_prices']]\n",
    "                hist_prices = [p if not (np.isnan(p) or np.isinf(p)) else llm_pred for p in hist_prices]\n",
    "            except:\n",
    "                hist_prices = []\n",
    "        \n",
    "        if len(hist_prices) < self.window_size:\n",
    "            pad_value = hist_prices[-1] if hist_prices else llm_pred\n",
    "            hist_prices = hist_prices + [pad_value] * (self.window_size - len(hist_prices))\n",
    "        hist_prices = np.array(hist_prices[-self.window_size:], dtype=np.float32)\n",
    "        \n",
    "        last_price = hist_prices[-1]\n",
    "        llm_trend = llm_pred - last_price\n",
    "        if np.isnan(llm_trend) or np.isinf(llm_trend): llm_trend = 0.0\n",
    "        \n",
    "        volatility = calculate_volatility(hist_prices)\n",
    "        if np.isnan(volatility) or np.isinf(volatility): volatility = 0.0\n",
    "        \n",
    "        returns = np.diff(hist_prices) / hist_prices[:-1] if len(hist_prices) > 1 else np.array([0.0])\n",
    "        returns = np.nan_to_num(returns, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        var = calculate_var(returns, self.confidence_level)\n",
    "        if np.isnan(var) or np.isinf(var): var = 0.0\n",
    "        \n",
    "        llm_likelihood = float(self.data.iloc[idx].get('llm_likelihood', 0.5))\n",
    "        if np.isnan(llm_likelihood) or np.isinf(llm_likelihood): llm_likelihood = 0.5\n",
    "        \n",
    "        state = np.concatenate([\n",
    "            np.array([llm_pred], dtype=np.float32),\n",
    "            hist_prices,\n",
    "            np.array([volatility, var, llm_likelihood, llm_trend], dtype=np.float32)\n",
    "        ])\n",
    "        \n",
    "        state = np.nan_to_num(state, nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "        return state.astype(np.float32)\n",
    "    \n",
    "    def step(self, action):\n",
    "        idx = min(self.current_step, self.max_steps - 1)\n",
    "        llm_pred = float(self.data.iloc[idx]['llm_prediction'])\n",
    "        actual_price = float(self.data.iloc[idx]['actual_price'])\n",
    "        if np.isnan(llm_pred) or np.isinf(llm_pred): llm_pred = actual_price\n",
    "        if np.isnan(actual_price) or np.isinf(actual_price): actual_price = llm_pred\n",
    "        \n",
    "        hist_prices_list = self.data.iloc[idx]['recent_prices']\n",
    "        last_price = hist_prices_list[-1] if hist_prices_list and len(hist_prices_list) > 0 else llm_pred\n",
    "\n",
    "        adjustment = float(action[0])\n",
    "        if np.isnan(adjustment) or np.isinf(adjustment): adjustment = 0.0\n",
    "        adjusted_pred = llm_pred * (1 + adjustment)\n",
    "        pred_error = abs(adjusted_pred - actual_price)\n",
    "        if actual_price != 0 and not np.isnan(actual_price): pct_error = pred_error / abs(actual_price)\n",
    "        else: pct_error = 0.0\n",
    "        if np.isnan(pred_error) or np.isinf(pred_error): pred_error = 0.0\n",
    "        if np.isnan(pct_error) or np.isinf(pct_error): pct_error = 0.0\n",
    "        scaled_error = pct_error * 100\n",
    "        cvar = 0.0\n",
    "        if 'recent_prices' in self.data.columns and self.data.iloc[idx]['recent_prices'] is not None:\n",
    "            try:\n",
    "                hist_prices = np.array(self.data.iloc[idx]['recent_prices'][-self.window_size:], dtype=np.float32)\n",
    "                hist_prices = np.nan_to_num(hist_prices, nan=llm_pred)\n",
    "                returns = np.diff(hist_prices) / hist_prices[:-1] if len(hist_prices) > 1 else np.array([0.0])\n",
    "                returns = np.nan_to_num(returns, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "                cvar = abs(calculate_cvar(returns, self.confidence_level))\n",
    "                if np.isnan(cvar) or np.isinf(cvar): cvar = 0.0\n",
    "            except:\n",
    "                cvar = 0.0\n",
    "        risk_penalty = self.lambda_risk * cvar * 100\n",
    "        llm_error = abs(llm_pred - actual_price)\n",
    "        if actual_price != 0 and not np.isnan(actual_price): llm_pct_error = llm_error / abs(actual_price) * 100\n",
    "        else: llm_pct_error = 0.0\n",
    "        improvement = llm_pct_error - scaled_error\n",
    "        \n",
    "        actual_direction = np.sign(actual_price - last_price)\n",
    "        predicted_direction = np.sign(adjusted_pred - last_price)\n",
    "        directional_bonus = 0.0\n",
    "        if actual_direction != 0 and actual_direction == predicted_direction:\n",
    "            directional_bonus = self.directional_bonus_weight\n",
    "\n",
    "        reward = -scaled_error - risk_penalty + (improvement * 0.5) + directional_bonus\n",
    "        if np.isnan(reward) or np.isinf(reward): reward = -100.0\n",
    "        self.current_step += 1\n",
    "        terminated = self.current_step >= self.max_steps\n",
    "        truncated = False\n",
    "        next_state = self._get_observation()\n",
    "        return next_state, reward, terminated, truncated, {}\n",
    "\n",
    "print(\"Stock Prediction Environment defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c3faf4",
   "metadata": {},
   "source": [
    "## 6. Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73ae8573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing StockPredictionEnv with sample data...\n",
      "================================================================================\n",
      "Environment reset successful!\n",
      "\n",
      "Observation Details:\n",
      "   Shape: (9,)\n",
      "   Contains NaN: False\n",
      "   Contains Inf: False\n",
      "   Min value: -0.0058\n",
      "   Max value: 1531.8000\n",
      "   Mean value: 1001.4231\n",
      "\n",
      "   First 5 values: [1500.  1479.2 1505.2 1502.8 1493. ]\n",
      "\n",
      "Testing environment steps...\n",
      "   Step 1: Valid (reward=-2.7119)\n",
      "   Step 2: Valid (reward=-6.0480)\n",
      "   Step 3: Valid (reward=-19.0390)\n",
      "   Step 4: Valid (reward=-14.1962)\n",
      "   Step 5: Valid (reward=-1.6905)\n",
      "   Step 6: Valid (reward=-21.5172)\n",
      "   Step 7: Valid (reward=-17.7085)\n",
      "   Step 8: Valid (reward=-5.1227)\n",
      "   Step 9: Valid (reward=-2.4888)\n",
      "   Step 10: Valid (reward=-3.6003)\n",
      "\n",
      "================================================================================\n",
      "ENVIRONMENT TEST PASSED!\n",
      "The environment is ready for PPO training.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test the environment to ensure it produces valid observations\n",
    "print(\"Testing StockPredictionEnv with sample data...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    # Create test environment\n",
    "    test_env = StockPredictionEnv(train_df_ppo, window_size=5)\n",
    "    \n",
    "    # Reset and get first observation\n",
    "    obs, info = test_env.reset()\n",
    "    \n",
    "    print(f\"Environment reset successful!\")\n",
    "    print(f\"\\nObservation Details:\")\n",
    "    print(f\"   Shape: {obs.shape}\")\n",
    "    print(f\"   Contains NaN: {np.any(np.isnan(obs))}\")\n",
    "    print(f\"   Contains Inf: {np.any(np.isinf(obs))}\")\n",
    "    print(f\"   Min value: {np.min(obs):.4f}\")\n",
    "    print(f\"   Max value: {np.max(obs):.4f}\")\n",
    "    print(f\"   Mean value: {np.mean(obs):.4f}\")\n",
    "    print(f\"\\n   First 5 values: {obs[:5]}\")\n",
    "    \n",
    "    # Try a few steps\n",
    "    print(f\"\\nTesting environment steps...\")\n",
    "    for i in range(10):\n",
    "        action = test_env.action_space.sample()\n",
    "        next_obs, reward, terminated, truncated, info = test_env.step(action)\n",
    "        \n",
    "        has_nan = np.any(np.isnan(next_obs))\n",
    "        has_inf = np.any(np.isinf(next_obs))\n",
    "        reward_invalid = np.isnan(reward) or np.isinf(reward)\n",
    "        \n",
    "        if has_nan or has_inf or reward_invalid:\n",
    "            print(f\"   Step {i+1}: NaN={has_nan}, Inf={has_inf}, Reward NaN/Inf={reward_invalid}\")\n",
    "            print(f\"      Observation: {next_obs}\")\n",
    "            print(f\"      Reward: {reward}\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"   Step {i+1}: Valid (reward={reward:.4f})\")\n",
    "        \n",
    "        if terminated or truncated:\n",
    "            break\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ENVIRONMENT TEST PASSED!\")\n",
    "    print(f\"The environment is ready for PPO training.\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nENVIRONMENT TEST FAILED!\")\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdb9ffd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation evaluation function defined.\n"
     ]
    }
   ],
   "source": [
    "def evaluate_on_validation(model, val_df, window_size=5):\n",
    "    \"\"\"\n",
    "    Evaluate PPO model on validation set\n",
    "    Returns MAE and other metrics\n",
    "    \"\"\"\n",
    "    env = StockPredictionEnv(val_df, window_size=window_size)\n",
    "    obs, _ = env.reset()\n",
    "    \n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    rewards_list = []\n",
    "    \n",
    "    for idx in range(len(val_df)):\n",
    "        if idx < window_size:\n",
    "            # For early samples, use LLM prediction as-is\n",
    "            predictions.append(val_df.iloc[idx]['llm_prediction'])\n",
    "            actuals.append(val_df.iloc[idx]['actual_price'])\n",
    "            continue\n",
    "        \n",
    "        # Get PPO action\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        \n",
    "        # Apply adjustment\n",
    "        llm_pred = val_df.iloc[idx]['llm_prediction']\n",
    "        adjusted_pred = llm_pred * (1 + action[0])\n",
    "        predictions.append(adjusted_pred)\n",
    "        actuals.append(val_df.iloc[idx]['actual_price'])\n",
    "        \n",
    "        # Step environment\n",
    "        if idx < len(val_df) - 1:\n",
    "            obs, reward, terminated, _, _ = env.step(action)\n",
    "            rewards_list.append(reward)\n",
    "            if terminated:\n",
    "                break\n",
    "    \n",
    "    predictions = np.array(predictions)\n",
    "    actuals = np.array(actuals)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae = np.mean(np.abs(predictions - actuals))\n",
    "    mape = np.mean(np.abs((predictions - actuals) / actuals)) * 100\n",
    "    rmse = np.sqrt(np.mean((predictions - actuals) ** 2))\n",
    "    avg_reward = np.mean(rewards_list) if rewards_list else 0.0\n",
    "    \n",
    "    return {\n",
    "        'mae': mae,\n",
    "        'mape': mape,\n",
    "        'rmse': rmse,\n",
    "        'avg_reward': avg_reward,\n",
    "        'predictions': predictions,\n",
    "        'actuals': actuals\n",
    "    }\n",
    "\n",
    "print(\"Validation evaluation function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934cdbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom environment for hyperparameter search defined.\n"
     ]
    }
   ],
   "source": [
    "# Custom environment class for hyperparameter search\n",
    "class CustomStockEnv(gym.Env):\n",
    "    \"\"\"Environment with configurable hyperparameters\"\"\"\n",
    "    \n",
    "    def __init__(self, data_df: pd.DataFrame, window_size: int = 5, \n",
    "                 action_range: float = 0.02, lambda_risk: float = 5.0, \n",
    "                 improvement_bonus_weight: float = 0.5,\n",
    "                 directional_bonus_weight: float = 0.5):\n",
    "        super(CustomStockEnv, self).__init__()\n",
    "        \n",
    "        self.data = data_df.copy()\n",
    "        self.window_size = window_size\n",
    "        self.current_step = 0\n",
    "        self.max_steps = len(self.data)\n",
    "        self.lambda_risk = lambda_risk\n",
    "        self.improvement_bonus_weight = improvement_bonus_weight\n",
    "        self.directional_bonus_weight = directional_bonus_weight\n",
    "        \n",
    "        # Add llm_trend to the state\n",
    "        state_dim = 1 + window_size + 2 + 1 + 1\n",
    "        \n",
    "        self.action_space = spaces.Box(low=-action_range, high=action_range, shape=(1,), dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(state_dim,), dtype=np.float32)\n",
    "        self.confidence_level = 0.95\n",
    "        \n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.current_step = self.window_size\n",
    "        return self._get_observation(), {}\n",
    "    \n",
    "    def _get_observation(self):\n",
    "        idx = min(self.current_step, self.max_steps - 1)\n",
    "        llm_pred = float(self.data.iloc[idx]['llm_prediction'])\n",
    "        if np.isnan(llm_pred) or np.isinf(llm_pred): llm_pred = float(self.data.iloc[idx]['actual_price'])\n",
    "        \n",
    "        hist_prices = []\n",
    "        if 'recent_prices' in self.data.columns and self.data.iloc[idx]['recent_prices'] is not None:\n",
    "            try:\n",
    "                hist_prices = [float(p) for p in self.data.iloc[idx]['recent_prices']]\n",
    "                hist_prices = [p if not (np.isnan(p) or np.isinf(p)) else llm_pred for p in hist_prices]\n",
    "            except:\n",
    "                hist_prices = []\n",
    "        \n",
    "        if len(hist_prices) < self.window_size:\n",
    "            pad_value = hist_prices[-1] if hist_prices else llm_pred\n",
    "            hist_prices = hist_prices + [pad_value] * (self.window_size - len(hist_prices))\n",
    "        hist_prices = np.array(hist_prices[-self.window_size:], dtype=np.float32)\n",
    "        \n",
    "        last_price = hist_prices[-1]\n",
    "        llm_trend = llm_pred - last_price\n",
    "        if np.isnan(llm_trend) or np.isinf(llm_trend): llm_trend = 0.0\n",
    "        \n",
    "        volatility = calculate_volatility(hist_prices)\n",
    "        if np.isnan(volatility) or np.isinf(volatility): volatility = 0.0\n",
    "        \n",
    "        returns = np.diff(hist_prices) / hist_prices[:-1] if len(hist_prices) > 1 else np.array([0.0])\n",
    "        returns = np.nan_to_num(returns, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        var = calculate_var(returns, self.confidence_level)\n",
    "        if np.isnan(var) or np.isinf(var): var = 0.0\n",
    "        \n",
    "        llm_likelihood = float(self.data.iloc[idx].get('llm_likelihood', 0.5))\n",
    "        if np.isnan(llm_likelihood) or np.isinf(llm_likelihood): llm_likelihood = 0.5\n",
    "        \n",
    "        state = np.concatenate([\n",
    "            np.array([llm_pred], dtype=np.float32),\n",
    "            hist_prices,\n",
    "            np.array([volatility, var, llm_likelihood, llm_trend], dtype=np.float32)\n",
    "        ])\n",
    "        \n",
    "        state = np.nan_to_num(state, nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "        return state.astype(np.float32)\n",
    "    \n",
    "    def step(self, action):\n",
    "        idx = min(self.current_step, self.max_steps - 1)\n",
    "        llm_pred = float(self.data.iloc[idx]['llm_prediction'])\n",
    "        actual_price = float(self.data.iloc[idx]['actual_price'])\n",
    "        if np.isnan(llm_pred) or np.isinf(llm_pred): llm_pred = actual_price\n",
    "        if np.isnan(actual_price) or np.isinf(actual_price): actual_price = llm_pred\n",
    "        \n",
    "        hist_prices_list = self.data.iloc[idx]['recent_prices']\n",
    "        last_price = hist_prices_list[-1] if hist_prices_list and len(hist_prices_list) > 0 else llm_pred\n",
    "        \n",
    "        adjustment = float(action[0])\n",
    "        if np.isnan(adjustment) or np.isinf(adjustment): adjustment = 0.0\n",
    "        adjusted_pred = llm_pred * (1 + adjustment)\n",
    "        \n",
    "        pred_error = abs(adjusted_pred - actual_price)\n",
    "        pct_error = pred_error / abs(actual_price) if actual_price != 0 and not np.isnan(actual_price) else 0.0\n",
    "        if np.isnan(pred_error) or np.isinf(pred_error): pred_error = 0.0\n",
    "        if np.isnan(pct_error) or np.isinf(pct_error): pct_error = 0.0\n",
    "        scaled_error = pct_error * 100\n",
    "        \n",
    "        cvar = 0.0\n",
    "        if 'recent_prices' in self.data.columns and self.data.iloc[idx]['recent_prices'] is not None:\n",
    "            try:\n",
    "                hist_prices = np.array(self.data.iloc[idx]['recent_prices'][-self.window_size:], dtype=np.float32)\n",
    "                hist_prices = np.nan_to_num(hist_prices, nan=llm_pred)\n",
    "                returns = np.diff(hist_prices) / hist_prices[:-1] if len(hist_prices) > 1 else np.array([0.0])\n",
    "                returns = np.nan_to_num(returns, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "                cvar = abs(calculate_cvar(returns, self.confidence_level))\n",
    "                if np.isnan(cvar) or np.isinf(cvar): cvar = 0.0\n",
    "            except:\n",
    "                cvar = 0.0\n",
    "        \n",
    "        risk_penalty = self.lambda_risk * cvar * 100\n",
    "        llm_error = abs(llm_pred - actual_price)\n",
    "        llm_pct_error = llm_error / abs(actual_price) * 100 if actual_price != 0 and not np.isnan(actual_price) else 0.0\n",
    "        improvement = llm_pct_error - scaled_error\n",
    "        \n",
    "        actual_direction = np.sign(actual_price - last_price)\n",
    "        predicted_direction = np.sign(adjusted_pred - last_price)\n",
    "        directional_bonus = 0.0\n",
    "        if actual_direction != 0 and actual_direction == predicted_direction:\n",
    "            directional_bonus = self.directional_bonus_weight\n",
    "            \n",
    "        reward = -scaled_error - risk_penalty + (improvement * self.improvement_bonus_weight) + directional_bonus\n",
    "        \n",
    "        if np.isnan(reward) or np.isinf(reward): reward = -100.0\n",
    "        \n",
    "        self.current_step += 1\n",
    "        terminated = self.current_step >= self.max_steps\n",
    "        truncated = False\n",
    "        next_state = self._get_observation()\n",
    "        return next_state, reward, terminated, truncated, {}\n",
    "\n",
    "print(\"Custom environment for hyperparameter search defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178f8281",
   "metadata": {},
   "source": [
    "## 7. Hyperparameter Search\n",
    "This section defines a custom environment for the search, sets up the hyperparameter grid, and runs the training and evaluation loop for each configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ae43a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PPO HYPERPARAMETER SEARCH\n",
      "================================================================================\n",
      "\n",
      "Target to Beat: 58.9895 (LLM-only validation MAE)\n",
      "   Goal: Find PPO params that reduce MAE by >5%\n",
      "\n",
      "Testing 8 strategic configurations\n",
      "   Training: 8698 samples\n",
      "   Validation: 1243 samples\n",
      "   Training duration: 40k timesteps per config (~5 min each)\n",
      "\n",
      "================================================================================\n",
      "STARTING HYPERPARAMETER SEARCH\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Search with Validation Set\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PPO HYPERPARAMETER SEARCH\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate LLM baseline on validation set\n",
    "llm_val_mae_baseline = np.mean(np.abs(val_df_ppo['llm_prediction'] - val_df_ppo['actual_price']))\n",
    "print(f\"\\nTarget to Beat: {llm_val_mae_baseline:.4f} (LLM-only validation MAE)\")\n",
    "print(f\"   Goal: Find PPO params that reduce MAE by >5%\")\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': [1e-4, 5e-5, 1e-5],\n",
    "    'action_space_range': [0.01, 0.02, 0.05],  # 1%, 2%, 5%\n",
    "    'lambda_risk': [1.0, 5.0, 10.0],  # CVaR weight\n",
    "    'ent_coef': [0.0, 0.01, 0.02],  # Entropy coefficient\n",
    "    'improvement_bonus_weight': [0.0, 0.5, 1.0],  # Bonus for beating LLM\n",
    "    'directional_bonus_weight': [0.0, 0.5, 1.0], # Bonus for correct direction\n",
    "}\n",
    "\n",
    "# For faster iteration, we'll sample key combinations\n",
    "test_configs = [\n",
    "    {'name': 'Current Best', 'learning_rate': 5e-5, 'action_space_range': 0.02, 'lambda_risk': 5.0, 'ent_coef': 0.02, 'improvement_bonus_weight': 0.5, 'directional_bonus_weight': 0.5},\n",
    "    {'name': 'Conservative', 'learning_rate': 1e-5, 'action_space_range': 0.01, 'lambda_risk': 10.0, 'ent_coef': 0.01, 'improvement_bonus_weight': 1.0, 'directional_bonus_weight': 1.0},\n",
    "    {'name': 'Aggressive', 'learning_rate': 1e-4, 'action_space_range': 0.05, 'lambda_risk': 1.0, 'ent_coef': 0.02, 'improvement_bonus_weight': 0.5, 'directional_bonus_weight': 0.5},\n",
    "    {'name': 'High Exploration', 'learning_rate': 5e-5, 'action_space_range': 0.02, 'lambda_risk': 5.0, 'ent_coef': 0.05, 'improvement_bonus_weight': 0.5, 'directional_bonus_weight': 0.5},\n",
    "    {'name': 'Bonus Focused', 'learning_rate': 5e-5, 'action_space_range': 0.02, 'lambda_risk': 2.0, 'ent_coef': 0.01, 'improvement_bonus_weight': 2.0, 'directional_bonus_weight': 1.0},\n",
    "    {'name': 'Risk Averse', 'learning_rate': 5e-5, 'action_space_range': 0.01, 'lambda_risk': 15.0, 'ent_coef': 0.0, 'improvement_bonus_weight': 0.5, 'directional_bonus_weight': 0.5},\n",
    "    {'name': 'Balanced', 'learning_rate': 5e-5, 'action_space_range': 0.03, 'lambda_risk': 5.0, 'ent_coef': 0.015, 'improvement_bonus_weight': 1.0, 'directional_bonus_weight': 1.0},\n",
    "    {'name': 'Fast Learner', 'learning_rate': 1e-4, 'action_space_range': 0.02, 'lambda_risk': 5.0, 'ent_coef': 0.02, 'improvement_bonus_weight': 1.5, 'directional_bonus_weight': 0.75},\n",
    "]\n",
    "\n",
    "print(f\"\\nTesting {len(test_configs)} strategic configurations\")\n",
    "print(f\"   Training: {len(train_df_ppo)} samples\")\n",
    "print(f\"   Validation: {len(val_df_ppo)} samples\")\n",
    "print(f\"   Training duration: 40k timesteps per config (~5 min each)\")\n",
    "\n",
    "# Store results\n",
    "search_results = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STARTING HYPERPARAMETER SEARCH\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31c5ea13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CONFIG 1/8: Current Best\n",
      "================================================================================\n",
      "Parameters:\n",
      "   learning_rate: 5e-05\n",
      "   action_space_range: 0.02\n",
      "   lambda_risk: 5.0\n",
      "   ent_coef: 0.02\n",
      "   improvement_bonus_weight: 0.5\n",
      "\n",
      "Training for 40,000 timesteps...\n",
      "\n",
      "Training for 40,000 timesteps...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete (17.7s)\n",
      "Evaluating on validation set...\n",
      "\n",
      "Validation Results:\n",
      "   MAE: 60.2841 (LLM baseline: 58.9895)\n",
      "   MAPE: 13.48%\n",
      "   RMSE: 215.6415\n",
      "   Avg Reward: -24.0078\n",
      "   Improvement: -2.19%\n",
      "\n",
      "================================================================================\n",
      "CONFIG 2/8: Conservative\n",
      "================================================================================\n",
      "Parameters:\n",
      "   learning_rate: 1e-05\n",
      "   action_space_range: 0.01\n",
      "   lambda_risk: 10.0\n",
      "   ent_coef: 0.01\n",
      "   improvement_bonus_weight: 1.0\n",
      "\n",
      "Training for 40,000 timesteps...\n",
      "\n",
      "Validation Results:\n",
      "   MAE: 60.2841 (LLM baseline: 58.9895)\n",
      "   MAPE: 13.48%\n",
      "   RMSE: 215.6415\n",
      "   Avg Reward: -24.0078\n",
      "   Improvement: -2.19%\n",
      "\n",
      "================================================================================\n",
      "CONFIG 2/8: Conservative\n",
      "================================================================================\n",
      "Parameters:\n",
      "   learning_rate: 1e-05\n",
      "   action_space_range: 0.01\n",
      "   lambda_risk: 10.0\n",
      "   ent_coef: 0.01\n",
      "   improvement_bonus_weight: 1.0\n",
      "\n",
      "Training for 40,000 timesteps...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete (17.4s)\n",
      "Evaluating on validation set...\n",
      "\n",
      "Validation Results:\n",
      "   MAE: 58.9147 (LLM baseline: 58.9895)\n",
      "   MAPE: 13.29%\n",
      "   RMSE: 215.3470\n",
      "   Avg Reward: -34.0900\n",
      "   Improvement: +0.13%\n",
      "\n",
      "================================================================================\n",
      "CONFIG 3/8: Aggressive\n",
      "================================================================================\n",
      "Parameters:\n",
      "   learning_rate: 0.0001\n",
      "   action_space_range: 0.05\n",
      "   lambda_risk: 1.0\n",
      "   ent_coef: 0.02\n",
      "   improvement_bonus_weight: 0.5\n",
      "\n",
      "Training for 40,000 timesteps...\n",
      "\n",
      "Validation Results:\n",
      "   MAE: 58.9147 (LLM baseline: 58.9895)\n",
      "   MAPE: 13.29%\n",
      "   RMSE: 215.3470\n",
      "   Avg Reward: -34.0900\n",
      "   Improvement: +0.13%\n",
      "\n",
      "================================================================================\n",
      "CONFIG 3/8: Aggressive\n",
      "================================================================================\n",
      "Parameters:\n",
      "   learning_rate: 0.0001\n",
      "   action_space_range: 0.05\n",
      "   lambda_risk: 1.0\n",
      "   ent_coef: 0.02\n",
      "   improvement_bonus_weight: 0.5\n",
      "\n",
      "Training for 40,000 timesteps...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete (18.4s)\n",
      "Evaluating on validation set...\n",
      "\n",
      "Validation Results:\n",
      "   MAE: 70.2949 (LLM baseline: 58.9895)\n",
      "   MAPE: 15.11%\n",
      "   RMSE: 218.8971\n",
      "   Avg Reward: -18.1408\n",
      "   Improvement: -19.17%\n",
      "\n",
      "================================================================================\n",
      "CONFIG 4/8: High Exploration\n",
      "================================================================================\n",
      "Parameters:\n",
      "   learning_rate: 5e-05\n",
      "   action_space_range: 0.02\n",
      "   lambda_risk: 5.0\n",
      "   ent_coef: 0.05\n",
      "   improvement_bonus_weight: 0.5\n",
      "\n",
      "Training for 40,000 timesteps...\n",
      "\n",
      "Validation Results:\n",
      "   MAE: 70.2949 (LLM baseline: 58.9895)\n",
      "   MAPE: 15.11%\n",
      "   RMSE: 218.8971\n",
      "   Avg Reward: -18.1408\n",
      "   Improvement: -19.17%\n",
      "\n",
      "================================================================================\n",
      "CONFIG 4/8: High Exploration\n",
      "================================================================================\n",
      "Parameters:\n",
      "   learning_rate: 5e-05\n",
      "   action_space_range: 0.02\n",
      "   lambda_risk: 5.0\n",
      "   ent_coef: 0.05\n",
      "   improvement_bonus_weight: 0.5\n",
      "\n",
      "Training for 40,000 timesteps...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete (17.7s)\n",
      "Evaluating on validation set...\n",
      "\n",
      "Validation Results:\n",
      "   MAE: 64.1931 (LLM baseline: 58.9895)\n",
      "   MAPE: 14.25%\n",
      "   RMSE: 216.8581\n",
      "   Avg Reward: -25.1607\n",
      "   Improvement: -8.82%\n",
      "\n",
      "================================================================================\n",
      "CONFIG 5/8: Bonus Focused\n",
      "================================================================================\n",
      "Parameters:\n",
      "   learning_rate: 5e-05\n",
      "   action_space_range: 0.02\n",
      "   lambda_risk: 2.0\n",
      "   ent_coef: 0.01\n",
      "   improvement_bonus_weight: 2.0\n",
      "\n",
      "Training for 40,000 timesteps...\n",
      "\n",
      "Validation Results:\n",
      "   MAE: 64.1931 (LLM baseline: 58.9895)\n",
      "   MAPE: 14.25%\n",
      "   RMSE: 216.8581\n",
      "   Avg Reward: -25.1607\n",
      "   Improvement: -8.82%\n",
      "\n",
      "================================================================================\n",
      "CONFIG 5/8: Bonus Focused\n",
      "================================================================================\n",
      "Parameters:\n",
      "   learning_rate: 5e-05\n",
      "   action_space_range: 0.02\n",
      "   lambda_risk: 2.0\n",
      "   ent_coef: 0.01\n",
      "   improvement_bonus_weight: 2.0\n",
      "\n",
      "Training for 40,000 timesteps...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete (17.4s)\n",
      "Evaluating on validation set...\n",
      "\n",
      "Validation Results:\n",
      "   MAE: 57.3115 (LLM baseline: 58.9895)\n",
      "   MAPE: 12.94%\n",
      "   RMSE: 214.8602\n",
      "   Avg Reward: -16.3490\n",
      "   Improvement: +2.84%\n",
      "\n",
      "================================================================================\n",
      "CONFIG 6/8: Risk Averse\n",
      "================================================================================\n",
      "Parameters:\n",
      "   learning_rate: 5e-05\n",
      "   action_space_range: 0.01\n",
      "   lambda_risk: 15.0\n",
      "   ent_coef: 0.0\n",
      "   improvement_bonus_weight: 0.5\n",
      "\n",
      "Training for 40,000 timesteps...\n",
      "\n",
      "Validation Results:\n",
      "   MAE: 57.3115 (LLM baseline: 58.9895)\n",
      "   MAPE: 12.94%\n",
      "   RMSE: 214.8602\n",
      "   Avg Reward: -16.3490\n",
      "   Improvement: +2.84%\n",
      "\n",
      "================================================================================\n",
      "CONFIG 6/8: Risk Averse\n",
      "================================================================================\n",
      "Parameters:\n",
      "   learning_rate: 5e-05\n",
      "   action_space_range: 0.01\n",
      "   lambda_risk: 15.0\n",
      "   ent_coef: 0.0\n",
      "   improvement_bonus_weight: 0.5\n",
      "\n",
      "Training for 40,000 timesteps...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete (17.4s)\n",
      "Evaluating on validation set...\n",
      "\n",
      "Validation Results:\n",
      "   MAE: 58.9147 (LLM baseline: 58.9895)\n",
      "   MAPE: 13.29%\n",
      "   RMSE: 215.3470\n",
      "   Avg Reward: -44.5186\n",
      "   Improvement: +0.13%\n",
      "\n",
      "================================================================================\n",
      "CONFIG 7/8: Balanced\n",
      "================================================================================\n",
      "Parameters:\n",
      "   learning_rate: 5e-05\n",
      "   action_space_range: 0.03\n",
      "   lambda_risk: 5.0\n",
      "   ent_coef: 0.015\n",
      "   improvement_bonus_weight: 1.0\n",
      "\n",
      "Training for 40,000 timesteps...\n",
      "\n",
      "Validation Results:\n",
      "   MAE: 58.9147 (LLM baseline: 58.9895)\n",
      "   MAPE: 13.29%\n",
      "   RMSE: 215.3470\n",
      "   Avg Reward: -44.5186\n",
      "   Improvement: +0.13%\n",
      "\n",
      "================================================================================\n",
      "CONFIG 7/8: Balanced\n",
      "================================================================================\n",
      "Parameters:\n",
      "   learning_rate: 5e-05\n",
      "   action_space_range: 0.03\n",
      "   lambda_risk: 5.0\n",
      "   ent_coef: 0.015\n",
      "   improvement_bonus_weight: 1.0\n",
      "\n",
      "Training for 40,000 timesteps...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete (17.5s)\n",
      "Evaluating on validation set...\n",
      "\n",
      "Validation Results:\n",
      "   MAE: 62.8834 (LLM baseline: 58.9895)\n",
      "   MAPE: 13.88%\n",
      "   RMSE: 216.3342\n",
      "   Avg Reward: -24.8811\n",
      "   Improvement: -6.60%\n",
      "\n",
      "================================================================================\n",
      "CONFIG 8/8: Fast Learner\n",
      "================================================================================\n",
      "Parameters:\n",
      "   learning_rate: 0.0001\n",
      "   action_space_range: 0.02\n",
      "   lambda_risk: 5.0\n",
      "   ent_coef: 0.02\n",
      "   improvement_bonus_weight: 1.5\n",
      "\n",
      "Training for 40,000 timesteps...\n",
      "\n",
      "Validation Results:\n",
      "   MAE: 62.8834 (LLM baseline: 58.9895)\n",
      "   MAPE: 13.88%\n",
      "   RMSE: 216.3342\n",
      "   Avg Reward: -24.8811\n",
      "   Improvement: -6.60%\n",
      "\n",
      "================================================================================\n",
      "CONFIG 8/8: Fast Learner\n",
      "================================================================================\n",
      "Parameters:\n",
      "   learning_rate: 0.0001\n",
      "   action_space_range: 0.02\n",
      "   lambda_risk: 5.0\n",
      "   ent_coef: 0.02\n",
      "   improvement_bonus_weight: 1.5\n",
      "\n",
      "Training for 40,000 timesteps...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete (17.4s)\n",
      "Evaluating on validation set...\n",
      "\n",
      "Validation Results:\n",
      "   MAE: 60.2841 (LLM baseline: 58.9895)\n",
      "   MAPE: 13.48%\n",
      "   RMSE: 215.6415\n",
      "   Avg Reward: -24.1490\n",
      "   Improvement: -2.19%\n",
      "\n",
      "================================================================================\n",
      "HYPERPARAMETER SEARCH COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Validation Results:\n",
      "   MAE: 60.2841 (LLM baseline: 58.9895)\n",
      "   MAPE: 13.48%\n",
      "   RMSE: 215.6415\n",
      "   Avg Reward: -24.1490\n",
      "   Improvement: -2.19%\n",
      "\n",
      "================================================================================\n",
      "HYPERPARAMETER SEARCH COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Run hyperparameter search\n",
    "for config_idx, config in enumerate(test_configs):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"CONFIG {config_idx + 1}/{len(test_configs)}: {config['name']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    print(f\"Parameters:\")\n",
    "    for key, value in config.items():\n",
    "        if key != 'name': print(f\"   {key}: {value}\")\n",
    "    \n",
    "    try:\n",
    "        train_env = CustomStockEnv(train_df_ppo, window_size=5, action_range=config['action_space_range'], lambda_risk=config['lambda_risk'], improvement_bonus_weight=config['improvement_bonus_weight'])\n",
    "        ppo_model = PPO(\"MlpPolicy\", train_env, learning_rate=config['learning_rate'], n_steps=2048, batch_size=64, n_epochs=10, gamma=0.99, clip_range=0.2, ent_coef=config['ent_coef'], vf_coef=0.5, verbose=0, max_grad_norm=0.5)\n",
    "        \n",
    "        print(f\"\\nTraining for 40,000 timesteps...\")\n",
    "        start_time = datetime.now()\n",
    "        ppo_model.learn(total_timesteps=40000, progress_bar=True)\n",
    "        training_time = (datetime.now() - start_time).total_seconds()\n",
    "        \n",
    "        print(f\"Training complete ({training_time:.1f}s)\")\n",
    "        print(f\"Evaluating on validation set...\")\n",
    "        \n",
    "        val_env = CustomStockEnv(val_df_ppo, window_size=5, action_range=config['action_space_range'], lambda_risk=config['lambda_risk'], improvement_bonus_weight=config['improvement_bonus_weight'])\n",
    "        obs, _ = val_env.reset()\n",
    "        predictions, actuals, rewards = [], [], []\n",
    "        \n",
    "        for idx in range(len(val_df_ppo)):\n",
    "            if idx < 5:\n",
    "                predictions.append(val_df_ppo.iloc[idx]['llm_prediction'])\n",
    "                actuals.append(val_df_ppo.iloc[idx]['actual_price'])\n",
    "                continue\n",
    "            \n",
    "            action, _ = ppo_model.predict(obs, deterministic=True)\n",
    "            llm_pred = val_df_ppo.iloc[idx]['llm_prediction']\n",
    "            adjusted_pred = llm_pred * (1 + action[0])\n",
    "            predictions.append(adjusted_pred)\n",
    "            actuals.append(val_df_ppo.iloc[idx]['actual_price'])\n",
    "            \n",
    "            if idx < len(val_df_ppo) - 1:\n",
    "                obs, reward, terminated, _, _ = val_env.step(action)\n",
    "                rewards.append(reward)\n",
    "                if terminated: break\n",
    "        \n",
    "        predictions, actuals = np.array(predictions), np.array(actuals)\n",
    "        val_mae = np.mean(np.abs(predictions - actuals))\n",
    "        val_mape = np.mean(np.abs((predictions - actuals) / actuals)) * 100\n",
    "        val_rmse = np.sqrt(np.mean((predictions - actuals) ** 2))\n",
    "        avg_reward = np.mean(rewards) if rewards else 0.0\n",
    "        improvement_pct = ((llm_val_mae_baseline - val_mae) / llm_val_mae_baseline) * 100\n",
    "        \n",
    "        search_results.append({'config_name': config['name'], 'config': config.copy(), 'val_mae': val_mae, 'val_mape': val_mape, 'val_rmse': val_rmse, 'avg_reward': avg_reward, 'improvement_pct': improvement_pct, 'training_time': training_time, 'model': ppo_model})\n",
    "        \n",
    "        print(f\"\\nValidation Results:\")\n",
    "        print(f\"   MAE: {val_mae:.4f} (LLM baseline: {llm_val_mae_baseline:.4f})\")\n",
    "        print(f\"   MAPE: {val_mape:.2f}%\")\n",
    "        print(f\"   RMSE: {val_rmse:.4f}\")\n",
    "        print(f\"   Avg Reward: {avg_reward:.4f}\")\n",
    "        print(f\"   Improvement: {improvement_pct:+.2f}%\")\n",
    "        \n",
    "        train_env.close()\n",
    "        val_env.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError with config {config['name']}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        continue\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"HYPERPARAMETER SEARCH COMPLETE\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8cf103",
   "metadata": {},
   "source": [
    "## 8. Analyze Search Results\n",
    "This section summarizes the outcomes of the hyperparameter search, identifies the best-performing configuration, and saves the corresponding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3c4e576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "HYPERPARAMETER SEARCH SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Top 3 Configurations by Validation MAE:\n",
      "       Config   Val MAE  Improvement %  Val MAPE\n",
      "Bonus Focused 57.311510       2.844514 12.941502\n",
      " Conservative 58.914703       0.126753 13.287133\n",
      "  Risk Averse 58.914703       0.126753 13.287133\n",
      "\n",
      "BEST CONFIGURATION: Bonus Focused\n",
      "   Validation MAE: 57.3115\n",
      "   Improvement: +2.84%\n",
      "\n",
      "Best model saved to ../results/ppo_best_model_from_search.zip\n"
     ]
    }
   ],
   "source": [
    "# Analyze and visualize search results\n",
    "if search_results:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"HYPERPARAMETER SEARCH SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    summary_data = [{'Config': r['config_name'], 'Val MAE': r['val_mae'], 'Improvement %': r['improvement_pct'], 'Val MAPE': r['val_mape'], 'Avg Reward': r['avg_reward'], 'Training Time (s)': r['training_time'], 'LR': r['config']['learning_rate'], 'Action Range': r['config']['action_space_range'], 'Lambda Risk': r['config']['lambda_risk'], 'Entropy': r['config']['ent_coef'], 'Bonus Weight': r['config']['improvement_bonus_weight']} for r in search_results]\n",
    "    summary_df = pd.DataFrame(summary_data).sort_values('Val MAE', ascending=True)\n",
    "    \n",
    "    print(f\"\\nTop 3 Configurations by Validation MAE:\")\n",
    "    print(summary_df[['Config', 'Val MAE', 'Improvement %', 'Val MAPE']].head(3).to_string(index=False))\n",
    "    \n",
    "    best_result = min(search_results, key=lambda x: x['val_mae'])\n",
    "    print(f\"\\nBEST CONFIGURATION: {best_result['config_name']}\")\n",
    "    print(f\"   Validation MAE: {best_result['val_mae']:.4f}\")\n",
    "    print(f\"   Improvement: {best_result['improvement_pct']:+.2f}%\")\n",
    "    \n",
    "    # Save the best model\n",
    "    best_model = best_result['model']\n",
    "    best_model_path = '../results/ppo_best_model_from_search.zip'\n",
    "    best_model.save(best_model_path)\n",
    "    print(f\"\\nBest model saved to {best_model_path}\")\n",
    "\n",
    "else:\n",
    "    print(\"No search results available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a664b8",
   "metadata": {},
   "source": [
    "## 9. Train Final Model\n",
    "Using the best hyperparameters identified in the search, this section trains the final PPO model on the full training dataset for an extended number of timesteps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "600ee39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAINING FINAL PPO MODEL\n",
      "================================================================================\n",
      "Using best hyperparameters from search:\n",
      "   learning_rate: 5e-05\n",
      "   action_space_range: 0.02\n",
      "   lambda_risk: 2.0\n",
      "   ent_coef: 0.01\n",
      "   improvement_bonus_weight: 2.0\n",
      "\n",
      "Training for 80,000 timesteps...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FINAL MODEL TRAINING COMPLETE\n",
      "Model saved to: ../results/ppo_final_model.zip\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Train final model with best hyperparameters\n",
    "if 'best_result' in locals() and best_result:\n",
    "    best_params = best_result['config']\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TRAINING FINAL PPO MODEL\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"Using best hyperparameters from search:\")\n",
    "    for key, value in best_params.items():\n",
    "        if key != 'name': print(f\"   {key}: {value}\")\n",
    "        \n",
    "    # Create environment with best parameters\n",
    "    final_env = CustomStockEnv(\n",
    "        train_df_ppo, \n",
    "        window_size=5,\n",
    "        action_range=best_params['action_space_range'],\n",
    "        lambda_risk=best_params['lambda_risk'],\n",
    "        improvement_bonus_weight=best_params['improvement_bonus_weight']\n",
    "    )\n",
    "    \n",
    "    # Initialize PPO model\n",
    "    final_model = PPO(\n",
    "        \"MlpPolicy\",\n",
    "        final_env,\n",
    "        learning_rate=best_params['learning_rate'],\n",
    "        n_steps=2048,\n",
    "        batch_size=64,\n",
    "        n_epochs=10,\n",
    "        gamma=0.99,\n",
    "        clip_range=0.2,\n",
    "        ent_coef=best_params['ent_coef'],\n",
    "        vf_coef=0.5,\n",
    "        verbose=0,\n",
    "        max_grad_norm=0.5\n",
    "    )\n",
    "    \n",
    "    # Train for more timesteps\n",
    "    print(\"\\nTraining for 80,000 timesteps...\")\n",
    "    final_model.learn(total_timesteps=80000, progress_bar=True)\n",
    "    \n",
    "    # Save the final model\n",
    "    final_model_path = '../results/ppo_final_model.zip'\n",
    "    final_model.save(final_model_path)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"FINAL MODEL TRAINING COMPLETE\")\n",
    "    print(f\"Model saved to: {final_model_path}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nSkipping final model training because best hyperparameters are not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b815c2da",
   "metadata": {},
   "source": [
    "## 10. Evaluate Final Model\n",
    "This section evaluates the fully trained PPO model on the held-out test set to assess its generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a3971f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EVALUATING FINAL MODEL ON TEST SET\n",
      "================================================================================\n",
      "Test Set Performance:\n",
      "   PPO-Adjusted MAE:  64.5999\n",
      "   LLM-Only MAE:        62.1152\n",
      "   Improvement vs LLM:  -4.00%\n",
      "   PPO-Adjusted MAPE: 7.32%\n",
      "   PPO-Adjusted RMSE: 314.2232\n",
      "================================================================================\n",
      "Test predictions saved to ../results/test_predictions_with_ppo.csv\n",
      "Test Set Performance:\n",
      "   PPO-Adjusted MAE:  64.5999\n",
      "   LLM-Only MAE:        62.1152\n",
      "   Improvement vs LLM:  -4.00%\n",
      "   PPO-Adjusted MAPE: 7.32%\n",
      "   PPO-Adjusted RMSE: 314.2232\n",
      "================================================================================\n",
      "Test predictions saved to ../results/test_predictions_with_ppo.csv\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the final model on the test set\n",
    "if 'final_model' in locals() and final_model:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EVALUATING FINAL MODEL ON TEST SET\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Create test environment\n",
    "    test_env_final = CustomStockEnv(\n",
    "        test_df,\n",
    "        window_size=5,\n",
    "        action_range=best_params['action_space_range'],\n",
    "        lambda_risk=best_params['lambda_risk'],\n",
    "        improvement_bonus_weight=best_params['improvement_bonus_weight']\n",
    "    )\n",
    "    \n",
    "    obs, _ = test_env_final.reset()\n",
    "    test_predictions, test_actuals = [], []\n",
    "\n",
    "    for idx in range(len(test_df)):\n",
    "        if idx < 5:\n",
    "            test_predictions.append(test_df.iloc[idx]['llm_prediction'])\n",
    "            test_actuals.append(test_df.iloc[idx]['actual_price'])\n",
    "            continue\n",
    "        \n",
    "        action, _ = final_model.predict(obs, deterministic=True)\n",
    "        llm_pred = test_df.iloc[idx]['llm_prediction']\n",
    "        adjusted_pred = llm_pred * (1 + action[0])\n",
    "        test_predictions.append(adjusted_pred)\n",
    "        test_actuals.append(test_df.iloc[idx]['actual_price'])\n",
    "        \n",
    "        if idx < len(test_df) - 1:\n",
    "            obs, _, terminated, _, _ = test_env_final.step(action)\n",
    "            if terminated:\n",
    "                break\n",
    "    \n",
    "    test_predictions = np.array(test_predictions)\n",
    "    test_actuals = np.array(test_actuals)\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    test_mae = np.mean(np.abs(test_predictions - test_actuals))\n",
    "    test_mape = np.mean(np.abs((test_predictions - test_actuals) / test_actuals)) * 100\n",
    "    test_rmse = np.sqrt(np.mean((test_predictions - test_actuals) ** 2))\n",
    "    \n",
    "    # Compare with LLM-only baseline on test set\n",
    "    llm_test_mae = np.mean(np.abs(test_df['llm_prediction'] - test_df['actual_price']))\n",
    "    test_improvement_pct = ((llm_test_mae - test_mae) / llm_test_mae) * 100\n",
    "    \n",
    "    print(f\"Test Set Performance:\")\n",
    "    print(f\"   PPO-Adjusted MAE:  {test_mae:.4f}\")\n",
    "    print(f\"   LLM-Only MAE:        {llm_test_mae:.4f}\")\n",
    "    print(f\"   Improvement vs LLM:  {test_improvement_pct:+.2f}%\")\n",
    "    print(f\"   PPO-Adjusted MAPE: {test_mape:.2f}%\")\n",
    "    print(f\"   PPO-Adjusted RMSE: {test_rmse:.4f}\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    # Save test predictions\n",
    "    test_df['ppo_adjusted_prediction'] = test_predictions\n",
    "    test_predictions_path = '../results/test_predictions_with_ppo.csv'\n",
    "    test_df.to_csv(test_predictions_path, index=False)\n",
    "    print(f\"Test predictions saved to {test_predictions_path}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nSkipping final evaluation because the final model is not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dc8098",
   "metadata": {},
   "source": [
    "## 11. How to Load the Saved Model\n",
    "\n",
    "You can now load the trained PPO model in any other notebook to make predictions. The best model from hyperparameter search was saved to `../results/ppo_final_model.zip`.\n",
    "\n",
    "\n",
    "Here's how to load it:\n",
    "\n",
    "\n",
    "```python\n",
    "from stable_baselines3 import PPO\n",
    "import gymnasium as gym\n",
    "\n",
    "# You will need to have your custom environment class available\n",
    "# For example, you can copy the CustomStockEnv class into your new notebook\n",
    "\n",
    "# Load the model\n",
    "model = PPO.load(\"../results/ppo_final_model.zip\")\n",
    "\n",
    "# Now you can use the model to predict actions\n",
    "# obs = ... # get an observation from your environment\n",
    "# action, _ = model.predict(obs, deterministic=True)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
