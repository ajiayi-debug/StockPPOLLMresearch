{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce0441a4",
   "metadata": {},
   "source": [
    "# PPO Training for Stock Price Prediction\n",
    "\n",
    "This notebook handles the PPO (Proximal Policy Optimization) training component of the two-stage framework.\n",
    "\n",
    "## Prerequisites:\n",
    "- Run `llm_ppo_stock_prediction.ipynb` first to generate LLM predictions\n",
    "- Ensure checkpoint files exist in `../results/` directory\n",
    "\n",
    "## What this notebook does:\n",
    "1. Loads LLM prediction checkpoints\n",
    "2. Prepares data for PPO training\n",
    "3. Defines risk-aware environment\n",
    "4. Trains PPO agent\n",
    "5. Applies PPO adjustments to predictions\n",
    "6. Evaluates results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5b6857",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5190688d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Reinforcement Learning\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "# Progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce747fd7",
   "metadata": {},
   "source": [
    "## 2. Load Data and Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d88e0414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 8698\n",
      "Validation samples: 1243\n",
      "Test samples: 2477\n"
     ]
    }
   ],
   "source": [
    "# Load original JSONL data\n",
    "def load_jsonl(filepath):\n",
    "    \"\"\"Load JSONL file\"\"\"\n",
    "    data = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "train_data = load_jsonl('../finetune_paper/train.jsonl')\n",
    "val_data = load_jsonl('../finetune_paper/val.jsonl')\n",
    "test_data = load_jsonl('../finetune_paper/test.jsonl')\n",
    "\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Validation samples: {len(val_data)}\")\n",
    "print(f\"Test samples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b35990a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LLM prediction checkpoints...\n",
      "‚úÖ Loaded 8698 training predictions\n",
      "‚úÖ Loaded 1243 validation predictions\n",
      "‚úÖ Loaded 2477 test predictions\n"
     ]
    }
   ],
   "source": [
    "# Load LLM prediction checkpoints\n",
    "print(\"Loading LLM prediction checkpoints...\")\n",
    "\n",
    "# Training checkpoint\n",
    "with open('../results/llm_predictions_train_checkpoint.json', 'r') as f:\n",
    "    train_checkpoint = json.load(f)\n",
    "    train_llm_predictions = train_checkpoint['predictions']\n",
    "    train_actual_prices = train_checkpoint['actual_prices']\n",
    "    train_llm_results = train_checkpoint['llm_results']\n",
    "\n",
    "# Validation checkpoint\n",
    "with open('../results/llm_predictions_val_checkpoint.json', 'r') as f:\n",
    "    val_checkpoint = json.load(f)\n",
    "    val_llm_predictions = val_checkpoint['predictions']\n",
    "    val_actual_prices = val_checkpoint['actual_prices']\n",
    "    val_llm_results = val_checkpoint['llm_results']\n",
    "\n",
    "# Test checkpoint\n",
    "with open('../results/llm_predictions_checkpoint.json', 'r') as f:\n",
    "    test_checkpoint = json.load(f)\n",
    "    test_llm_predictions = test_checkpoint['predictions']\n",
    "    test_actual_prices = test_checkpoint['actual_prices']\n",
    "    test_llm_results = test_checkpoint['llm_results']\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(train_llm_predictions)} training predictions\")\n",
    "print(f\"‚úÖ Loaded {len(val_llm_predictions)} validation predictions\")\n",
    "print(f\"‚úÖ Loaded {len(test_llm_predictions)} test predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a955bebf",
   "metadata": {},
   "source": [
    "## 3. Data Preparation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1bb3a4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction functions\n",
    "POSITIVE_JUSTIFICATION_KEYWORDS = {\n",
    "    \"increase\", \"growth\", \"upward\", \"bullish\", \"positive\", \"gain\", \"improve\", \"strength\", \"rally\", \"optimistic\"\n",
    "}\n",
    "NEGATIVE_JUSTIFICATION_KEYWORDS = {\n",
    "    \"decrease\", \"decline\", \"downward\", \"bearish\", \"negative\", \"loss\", \"drop\", \"weakness\", \"sell\", \"pessimistic\"\n",
    "}\n",
    "RISK_JUSTIFICATION_KEYWORDS = {\n",
    "    \"volatility\", \"volatile\", \"risk\", \"uncertain\", \"uncertainty\", \"caution\", \"concern\", \"warning\", \"downside\"\n",
    "}\n",
    "\n",
    "def safe_float(value, default=0.0) -> float:\n",
    "    try:\n",
    "        return float(value)\n",
    "    except (TypeError, ValueError):\n",
    "        return float(default)\n",
    "\n",
    "def extract_justification_features(justification: str) -> Dict[str, float]:\n",
    "    base = {\n",
    "        \"justification_pos_ratio\": 0.0,\n",
    "        \"justification_neg_ratio\": 0.0,\n",
    "        \"justification_risk_ratio\": 0.0,\n",
    "        \"justification_polarity\": 0.0,\n",
    "        \"justification_length\": 0.0,\n",
    "    }\n",
    "    if not justification:\n",
    "        return base.copy()\n",
    "    tokens = re.findall(r\"[a-zA-Z']+\", justification.lower())\n",
    "    token_count = max(len(tokens), 1)\n",
    "    pos_hits = sum(token in POSITIVE_JUSTIFICATION_KEYWORDS for token in tokens)\n",
    "    neg_hits = sum(token in NEGATIVE_JUSTIFICATION_KEYWORDS for token in tokens)\n",
    "    risk_hits = sum(token in RISK_JUSTIFICATION_KEYWORDS for token in tokens)\n",
    "    base.update({\n",
    "        \"justification_pos_ratio\": float(pos_hits / token_count),\n",
    "        \"justification_neg_ratio\": float(neg_hits / token_count),\n",
    "        \"justification_risk_ratio\": float(risk_hits / token_count),\n",
    "        \"justification_polarity\": float((pos_hits - neg_hits) / token_count),\n",
    "        \"justification_length\": float(np.log1p(token_count)),\n",
    "    })\n",
    "    return base\n",
    "\n",
    "def parse_prompt_data(prompt_text):\n",
    "    \"\"\"Extract key information from prompt\"\"\"\n",
    "    lines = prompt_text.split('\\n')\n",
    "    data = {}\n",
    "    \n",
    "    for line in lines:\n",
    "        if 'TICKER:' in line:\n",
    "            data['ticker'] = line.split('TICKER:')[1].strip()\n",
    "        elif 'DATE:' in line:\n",
    "            data['date'] = line.split('DATE:')[1].strip()\n",
    "        elif 'RECENT CLOSING PRICES' in line:\n",
    "            # Prices are on the same line after the colon\n",
    "            if ':' in line:\n",
    "                prices_part = line.split(':', 1)[1].strip()\n",
    "                # Remove any parenthetical text like \"(most recent last)\"\n",
    "                if '(' in prices_part:\n",
    "                    prices_part = prices_part.split('(')[0].strip()\n",
    "                # Extract comma-separated prices\n",
    "                try:\n",
    "                    data['recent_prices'] = [float(p.strip()) for p in prices_part.split(',') if p.strip()]\n",
    "                except ValueError:\n",
    "                    # If parsing fails, set empty list\n",
    "                    data['recent_prices'] = []\n",
    "    \n",
    "    return data\n",
    "\n",
    "print(\"Data preparation functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4bb59f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': 'You are a financial analyst with expertise in stock market forecasting.\\nYour task is to analyze market data and predict the next trading day stock price.\\nUse historical price trends, technical indicators, and sentiment analysis to provide an informed forecast.\\nEnsure that your predictions are well-justified, considering multiple financial factors.\\n\\n‚Ä¢ Predicted Stock Price: The forecasted close price for the next trading day.\\n‚Ä¢ Price Movement Likelihood: The likelihood of the predicted stock price.\\n‚Ä¢ Justification: Provide an explanation for the predicted stock price and the corresponding likelihood, considering the following:\\n  - Historical market data (e.g., recent closing prices).\\n  - Technical indicators (e.g., SMA, EMA, RSI, MACD, Bollinger Bands).\\n  - Sentiment analysis (e.g., news sentiment, market sentiment).\\n\\nPlease weigh these signals and justify the predicted stock price.\\n\\nTICKER: AAPL\\nDATE: 2015-01-16\\n\\nRECENT CLOSING PRICES (most recent last): 27.3125, 27.5550, 27.4500, 26.7050, 26.4975\\n\\nTECHNICAL INDICATORS:\\nSMA_20=nan, SMA_50=nan,\\nEMA_12=27.15906245473696, EMA_26=27.234397933550607,\\nRSI_14=13.536208492798082, MACD=-0.0753354788136455, MACD_signal=-0.0156901217863932, MACD_hist=-0.0596453570272522,\\nBB_width_20_2=nan\\n\\nSENTIMENT AGGREGATES:\\nheadline_count=4.0, sent_compound_mean=-0.07955\\n\\nHEADLINES (concise):\\nnan\\n\\nReturn STRICT JSON with keys:\\n- predicted_close (float, next-day close price),\\n- likelihood (float in [0,1]),\\n- justification (string, 1‚Äì2 sentences).\\nJSON:', 'response': '{\"predicted_close\": 27.18000030517578, \"likelihood\": 0.5, \"justification\": \"n/a\"}'}\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f9afc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data prepared for PPO: 8698 samples\n",
      "Columns: ['ticker', 'date', 'recent_prices', 'llm_prediction', 'actual_price', 'llm_likelihood', 'likelihood', 'llm_justification', 'justification_pos_ratio', 'justification_neg_ratio', 'justification_risk_ratio', 'justification_polarity', 'justification_length']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>recent_prices</th>\n",
       "      <th>llm_prediction</th>\n",
       "      <th>actual_price</th>\n",
       "      <th>llm_likelihood</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>llm_justification</th>\n",
       "      <th>justification_pos_ratio</th>\n",
       "      <th>justification_neg_ratio</th>\n",
       "      <th>justification_risk_ratio</th>\n",
       "      <th>justification_polarity</th>\n",
       "      <th>justification_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-16</td>\n",
       "      <td>[27.3125, 27.555, 27.45, 26.705, 26.4975]</td>\n",
       "      <td>27.312500</td>\n",
       "      <td>27.180000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Based on historical data, technical indicators...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>4.510860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HSBC</td>\n",
       "      <td>2015-01-16</td>\n",
       "      <td>[45.62, 45.71, 45.24, 45.26, 45.24]</td>\n",
       "      <td>45.620000</td>\n",
       "      <td>45.360001</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Based on recent closing prices and technical i...</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>-0.007692</td>\n",
       "      <td>4.875197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0700.HK</td>\n",
       "      <td>2015-01-16</td>\n",
       "      <td>[117.168, 117.8133, 116.1539, 116.9836, 112.3743]</td>\n",
       "      <td>113.078837</td>\n",
       "      <td>113.388344</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>The predicted close price is 113.0788370246397...</td>\n",
       "      <td>0.024194</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008065</td>\n",
       "      <td>4.828314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PEP</td>\n",
       "      <td>2015-01-16</td>\n",
       "      <td>[96.42, 96.35, 96.67, 96.67, 97.29]</td>\n",
       "      <td>97.290000</td>\n",
       "      <td>97.510002</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>The predicted close price is 97.2900. The like...</td>\n",
       "      <td>0.077922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077922</td>\n",
       "      <td>4.356709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0700.HK</td>\n",
       "      <td>2015-01-19</td>\n",
       "      <td>[117.8133, 116.1539, 116.9836, 112.3743, 113.3...</td>\n",
       "      <td>113.388300</td>\n",
       "      <td>114.402382</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>The stock price is likely to remain stable due...</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.010753</td>\n",
       "      <td>0.010753</td>\n",
       "      <td>0.021505</td>\n",
       "      <td>4.543295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker        date                                      recent_prices  \\\n",
       "0     AAPL  2015-01-16          [27.3125, 27.555, 27.45, 26.705, 26.4975]   \n",
       "1     HSBC  2015-01-16                [45.62, 45.71, 45.24, 45.26, 45.24]   \n",
       "2  0700.HK  2015-01-16  [117.168, 117.8133, 116.1539, 116.9836, 112.3743]   \n",
       "3      PEP  2015-01-16                [96.42, 96.35, 96.67, 96.67, 97.29]   \n",
       "4  0700.HK  2015-01-19  [117.8133, 116.1539, 116.9836, 112.3743, 113.3...   \n",
       "\n",
       "   llm_prediction  actual_price  llm_likelihood  likelihood  \\\n",
       "0       27.312500     27.180000             0.8         0.8   \n",
       "1       45.620000     45.360001             0.8         0.8   \n",
       "2      113.078837    113.388344             0.5         0.5   \n",
       "3       97.290000     97.510002             0.8         0.8   \n",
       "4      113.388300    114.402382             0.8         0.8   \n",
       "\n",
       "                                   llm_justification  justification_pos_ratio  \\\n",
       "0  Based on historical data, technical indicators...                 0.000000   \n",
       "1  Based on recent closing prices and technical i...                 0.030769   \n",
       "2  The predicted close price is 113.0788370246397...                 0.024194   \n",
       "3  The predicted close price is 97.2900. The like...                 0.077922   \n",
       "4  The stock price is likely to remain stable due...                 0.032258   \n",
       "\n",
       "   justification_neg_ratio  justification_risk_ratio  justification_polarity  \\\n",
       "0                 0.066667                  0.011111               -0.066667   \n",
       "1                 0.038462                  0.015385               -0.007692   \n",
       "2                 0.032258                  0.000000               -0.008065   \n",
       "3                 0.000000                  0.000000                0.077922   \n",
       "4                 0.010753                  0.010753                0.021505   \n",
       "\n",
       "   justification_length  \n",
       "0              4.510860  \n",
       "1              4.875197  \n",
       "2              4.828314  \n",
       "3              4.356709  \n",
       "4              4.543295  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare training data for PPO\n",
    "train_parsed = []\n",
    "for idx, item in enumerate(train_data):\n",
    "    parsed = parse_prompt_data(item['prompt'])\n",
    "    response = json.loads(item['response'])\n",
    "    llm_output = train_llm_results[idx] if idx < len(train_llm_results) else {}\n",
    "\n",
    "    if isinstance(llm_output, dict) and llm_output.get('predicted_close') is not None:\n",
    "        parsed['llm_prediction'] = safe_float(llm_output.get('predicted_close'), response['predicted_close'])\n",
    "    elif idx < len(train_llm_predictions):\n",
    "        parsed['llm_prediction'] = train_llm_predictions[idx]\n",
    "    else:\n",
    "        parsed['llm_prediction'] = response['predicted_close']\n",
    "\n",
    "    if idx < len(train_actual_prices):\n",
    "        parsed['actual_price'] = train_actual_prices[idx]\n",
    "    else:\n",
    "        parsed['actual_price'] = response['predicted_close']\n",
    "\n",
    "    llm_likelihood = safe_float(llm_output.get('likelihood') if isinstance(llm_output, dict) else None, response.get('likelihood', 0.5))\n",
    "    parsed['llm_likelihood'] = llm_likelihood\n",
    "    parsed['likelihood'] = llm_likelihood\n",
    "\n",
    "    justification_text = llm_output.get('justification', '') if isinstance(llm_output, dict) else ''\n",
    "    parsed['llm_justification'] = justification_text\n",
    "    parsed.update(extract_justification_features(justification_text))\n",
    "\n",
    "    train_parsed.append(parsed)\n",
    "\n",
    "train_df_ppo = pd.DataFrame(train_parsed)\n",
    "\n",
    "# Ensure all required columns exist\n",
    "if 'recent_prices' not in train_df_ppo.columns:\n",
    "    train_df_ppo['recent_prices'] = train_df_ppo['llm_prediction'].apply(\n",
    "        lambda x: [float(x)] * 5 if pd.notna(x) else [0.0] * 5\n",
    "    )\n",
    "\n",
    "# Fill NaN values\n",
    "train_df_ppo['llm_prediction'].fillna(train_df_ppo['actual_price'], inplace=True)\n",
    "for col in ['llm_likelihood', 'justification_pos_ratio', 'justification_neg_ratio', \n",
    "            'justification_risk_ratio', 'justification_polarity', 'justification_length']:\n",
    "    if col in train_df_ppo.columns:\n",
    "        train_df_ppo[col].fillna(0.0, inplace=True)\n",
    "\n",
    "print(f\"Training data prepared for PPO: {len(train_df_ppo)} samples\")\n",
    "print(f\"Columns: {train_df_ppo.columns.tolist()}\")\n",
    "train_df_ppo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3db3d2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data prepared for PPO: 1243 samples\n",
      "Columns: ['ticker', 'date', 'recent_prices', 'llm_prediction', 'actual_price', 'llm_likelihood', 'likelihood', 'llm_justification', 'justification_pos_ratio', 'justification_neg_ratio', 'justification_risk_ratio', 'justification_polarity', 'justification_length']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>recent_prices</th>\n",
       "      <th>llm_prediction</th>\n",
       "      <th>actual_price</th>\n",
       "      <th>llm_likelihood</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>llm_justification</th>\n",
       "      <th>justification_pos_ratio</th>\n",
       "      <th>justification_neg_ratio</th>\n",
       "      <th>justification_risk_ratio</th>\n",
       "      <th>justification_polarity</th>\n",
       "      <th>justification_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0700.HK</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>[415.2041, 410.0417, 408.7512, 421.104, 418.3385]</td>\n",
       "      <td>420.00</td>\n",
       "      <td>414.835388</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>The predicted close price of 420.0 is based on...</td>\n",
       "      <td>0.024590</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>4.812184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HSBC</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>[30.15, 30.22, 30.17, 30.15, 30.45]</td>\n",
       "      <td>30.15</td>\n",
       "      <td>31.820000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Based on recent closing prices, technical indi...</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>5.017280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>[179.29, 179.38, 178.2, 177.57, 182.01]</td>\n",
       "      <td>179.29</td>\n",
       "      <td>179.699997</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Based on historical price trends, technical in...</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.027473</td>\n",
       "      <td>5.209486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PEP</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>[172.36, 172.97, 172.67, 173.71, 172.98]</td>\n",
       "      <td>173.00</td>\n",
       "      <td>173.229996</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>The predicted close price is 173.0. The likeli...</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.828314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>[179.38, 178.2, 177.57, 182.01, 179.7]</td>\n",
       "      <td>179.38</td>\n",
       "      <td>174.919998</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Based on recent closing prices, technical indi...</td>\n",
       "      <td>0.048913</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038043</td>\n",
       "      <td>5.220356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker        date                                      recent_prices  \\\n",
       "0  0700.HK  2022-01-03  [415.2041, 410.0417, 408.7512, 421.104, 418.3385]   \n",
       "1     HSBC  2022-01-03                [30.15, 30.22, 30.17, 30.15, 30.45]   \n",
       "2     AAPL  2022-01-03            [179.29, 179.38, 178.2, 177.57, 182.01]   \n",
       "3      PEP  2022-01-03           [172.36, 172.97, 172.67, 173.71, 172.98]   \n",
       "4     AAPL  2022-01-04             [179.38, 178.2, 177.57, 182.01, 179.7]   \n",
       "\n",
       "   llm_prediction  actual_price  llm_likelihood  likelihood  \\\n",
       "0          420.00    414.835388             0.8         0.8   \n",
       "1           30.15     31.820000             0.8         0.8   \n",
       "2          179.29    179.699997             0.8         0.8   \n",
       "3          173.00    173.229996             0.8         0.8   \n",
       "4          179.38    174.919998             0.8         0.8   \n",
       "\n",
       "                                   llm_justification  justification_pos_ratio  \\\n",
       "0  The predicted close price of 420.0 is based on...                 0.024590   \n",
       "1  Based on recent closing prices, technical indi...                 0.040000   \n",
       "2  Based on historical price trends, technical in...                 0.010989   \n",
       "3  The predicted close price is 173.0. The likeli...                 0.016129   \n",
       "4  Based on recent closing prices, technical indi...                 0.048913   \n",
       "\n",
       "   justification_neg_ratio  justification_risk_ratio  justification_polarity  \\\n",
       "0                 0.016393                  0.008197                0.008197   \n",
       "1                 0.013333                  0.006667                0.026667   \n",
       "2                 0.038462                  0.000000               -0.027473   \n",
       "3                 0.016129                  0.000000                0.000000   \n",
       "4                 0.010870                  0.000000                0.038043   \n",
       "\n",
       "   justification_length  \n",
       "0              4.812184  \n",
       "1              5.017280  \n",
       "2              5.209486  \n",
       "3              4.828314  \n",
       "4              5.220356  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare validation data for PPO\n",
    "val_parsed = []\n",
    "for idx, item in enumerate(val_data):\n",
    "    parsed = parse_prompt_data(item['prompt'])\n",
    "    response = json.loads(item['response'])\n",
    "    llm_output = val_llm_results[idx] if idx < len(val_llm_results) else {}\n",
    "\n",
    "    if isinstance(llm_output, dict) and llm_output.get('predicted_close') is not None:\n",
    "        parsed['llm_prediction'] = safe_float(llm_output.get('predicted_close'), response['predicted_close'])\n",
    "    elif idx < len(val_llm_predictions):\n",
    "        parsed['llm_prediction'] = val_llm_predictions[idx]\n",
    "    else:\n",
    "        parsed['llm_prediction'] = response['predicted_close']\n",
    "\n",
    "    if idx < len(val_actual_prices):\n",
    "        parsed['actual_price'] = val_actual_prices[idx]\n",
    "    else:\n",
    "        parsed['actual_price'] = response['predicted_close']\n",
    "\n",
    "    llm_likelihood = safe_float(llm_output.get('likelihood') if isinstance(llm_output, dict) else None, response.get('likelihood', 0.5))\n",
    "    parsed['llm_likelihood'] = llm_likelihood\n",
    "    parsed['likelihood'] = llm_likelihood\n",
    "\n",
    "    justification_text = llm_output.get('justification', '') if isinstance(llm_output, dict) else ''\n",
    "    parsed['llm_justification'] = justification_text\n",
    "    parsed.update(extract_justification_features(justification_text))\n",
    "\n",
    "    val_parsed.append(parsed)\n",
    "\n",
    "val_df_ppo = pd.DataFrame(val_parsed)\n",
    "\n",
    "# Ensure all required columns exist\n",
    "if 'recent_prices' not in val_df_ppo.columns:\n",
    "    val_df_ppo['recent_prices'] = val_df_ppo['llm_prediction'].apply(\n",
    "        lambda x: [float(x)] * 5 if pd.notna(x) else [0.0] * 5\n",
    "    )\n",
    "\n",
    "# Fill NaN values\n",
    "val_df_ppo['llm_prediction'].fillna(val_df_ppo['actual_price'], inplace=True)\n",
    "for col in ['llm_likelihood', 'justification_pos_ratio', 'justification_neg_ratio', \n",
    "            'justification_risk_ratio', 'justification_polarity', 'justification_length']:\n",
    "    if col in val_df_ppo.columns:\n",
    "        val_df_ppo[col].fillna(0.0, inplace=True)\n",
    "\n",
    "print(f\"Validation data prepared for PPO: {len(val_df_ppo)} samples\")\n",
    "print(f\"Columns: {val_df_ppo.columns.tolist()}\")\n",
    "val_df_ppo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae9da74",
   "metadata": {},
   "source": [
    "## 4. Risk Metrics Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "970c350c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risk metrics functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Financial Risk Metrics\n",
    "def calculate_var(returns: np.ndarray, confidence_level: float = 0.95) -> float:\n",
    "    \"\"\"Calculate Value at Risk (VaR)\"\"\"\n",
    "    if len(returns) == 0:\n",
    "        return 0.0\n",
    "    return np.percentile(returns, (1 - confidence_level) * 100)\n",
    "\n",
    "def calculate_cvar(returns: np.ndarray, confidence_level: float = 0.95) -> float:\n",
    "    \"\"\"Calculate Conditional Value at Risk (CVaR) - Expected Shortfall\"\"\"\n",
    "    if len(returns) == 0:\n",
    "        return 0.0\n",
    "    var = calculate_var(returns, confidence_level)\n",
    "    tail_losses = returns[returns <= var]\n",
    "    if len(tail_losses) == 0:\n",
    "        return var\n",
    "    return np.mean(tail_losses)\n",
    "\n",
    "def calculate_volatility(prices: np.ndarray) -> float:\n",
    "    \"\"\"Calculate price volatility (standard deviation of returns)\"\"\"\n",
    "    if len(prices) < 2:\n",
    "        return 0.0\n",
    "    returns = np.diff(prices) / prices[:-1]\n",
    "    return np.std(returns)\n",
    "\n",
    "print(\"Risk metrics functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0336e3b6",
   "metadata": {},
   "source": [
    "## 5. PPO Environment with NaN Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "029cc1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Prediction Environment with NaN handling defined.\n"
     ]
    }
   ],
   "source": [
    "# Custom Gym Environment for Stock Price Prediction with PPO\n",
    "class StockPredictionEnv(gym.Env):\n",
    "    \"\"\"Custom Environment for Risk-Aware Stock Price Prediction with robust NaN handling\"\"\"\n",
    "    \n",
    "    def __init__(self, data_df: pd.DataFrame, window_size: int = 5):\n",
    "        super(StockPredictionEnv, self).__init__()\n",
    "        \n",
    "        self.data = data_df.copy()\n",
    "        self.window_size = window_size\n",
    "        self.current_step = 0\n",
    "        self.max_steps = len(self.data)\n",
    "        \n",
    "        # Dynamic state space includes LLM justification signals\n",
    "        self.extra_feature_cols = [\n",
    "            'llm_likelihood',\n",
    "            'justification_pos_ratio',\n",
    "            'justification_neg_ratio',\n",
    "            'justification_risk_ratio',\n",
    "            'justification_polarity',\n",
    "            'justification_length'\n",
    "        ]\n",
    "        self.available_extra_cols = [c for c in self.extra_feature_cols if c in self.data.columns]\n",
    "        \n",
    "        # State: [llm_prediction, historical_prices (window), volatility, var, justification features]\n",
    "        state_dim = 1 + window_size + 2 + len(self.available_extra_cols)\n",
    "        \n",
    "        # Action space: adjustment factor (continuous)\n",
    "        # Reduced from ¬±10% to ¬±2% for more conservative adjustments\n",
    "        self.action_space = spaces.Box(\n",
    "            low=-0.02, high=0.02, shape=(1,), dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        # Observation space\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf, shape=(state_dim,), dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        # Risk parameters (from paper Equation 4)\n",
    "        self.lambda_risk = 5.0  # Weight for CVaR penalty (increased for better signal)\n",
    "        self.confidence_level = 0.95  # Confidence level for VaR/CVaR (Œ± in paper)\n",
    "        \n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.current_step = self.window_size\n",
    "        return self._get_observation(), {}\n",
    "    \n",
    "    def _get_observation(self):\n",
    "        \"\"\"Construct state representation with NaN handling\"\"\"\n",
    "        idx = min(self.current_step, self.max_steps - 1)\n",
    "        \n",
    "        # LLM prediction - handle NaN\n",
    "        llm_pred = float(self.data.iloc[idx]['llm_prediction'])\n",
    "        if np.isnan(llm_pred) or np.isinf(llm_pred):\n",
    "            llm_pred = float(self.data.iloc[idx]['actual_price'])\n",
    "        \n",
    "        # Historical prices (window)\n",
    "        hist_prices = []\n",
    "        if 'recent_prices' in self.data.columns and self.data.iloc[idx]['recent_prices'] is not None:\n",
    "            try:\n",
    "                hist_prices = [float(p) for p in self.data.iloc[idx]['recent_prices']]\n",
    "                # Replace NaN/inf in hist_prices\n",
    "                hist_prices = [p if not (np.isnan(p) or np.isinf(p)) else llm_pred for p in hist_prices]\n",
    "            except:\n",
    "                hist_prices = []\n",
    "        \n",
    "        if len(hist_prices) < self.window_size:\n",
    "            pad_value = hist_prices[-1] if hist_prices else llm_pred\n",
    "            hist_prices = hist_prices + [pad_value] * (self.window_size - len(hist_prices))\n",
    "        hist_prices = np.array(hist_prices[-self.window_size:], dtype=np.float32)\n",
    "        \n",
    "        # Volatility - handle NaN\n",
    "        volatility = calculate_volatility(hist_prices)\n",
    "        if np.isnan(volatility) or np.isinf(volatility):\n",
    "            volatility = 0.0\n",
    "        \n",
    "        # VaR (using historical returns) - handle NaN\n",
    "        returns = np.diff(hist_prices) / hist_prices[:-1] if len(hist_prices) > 1 else np.array([0.0])\n",
    "        # Replace inf/nan in returns\n",
    "        returns = np.nan_to_num(returns, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        var = calculate_var(returns, self.confidence_level)\n",
    "        if np.isnan(var) or np.isinf(var):\n",
    "            var = 0.0\n",
    "        \n",
    "        # Justification-driven features - handle NaN\n",
    "        extra_features = []\n",
    "        for col in self.available_extra_cols:\n",
    "            val = float(self.data.iloc[idx].get(col, 0.0))\n",
    "            if np.isnan(val) or np.isinf(val):\n",
    "                val = 0.0\n",
    "            extra_features.append(val)\n",
    "        \n",
    "        state = np.concatenate([\n",
    "            np.array([llm_pred], dtype=np.float32),\n",
    "            hist_prices,\n",
    "            np.array([volatility, var], dtype=np.float32),\n",
    "            np.array(extra_features, dtype=np.float32)\n",
    "        ])\n",
    "        \n",
    "        # Final NaN check - replace any remaining NaN/inf\n",
    "        state = np.nan_to_num(state, nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "        \n",
    "        return state.astype(np.float32)\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"Execute one step with NaN handling\"\"\"\n",
    "        idx = min(self.current_step, self.max_steps - 1)\n",
    "        \n",
    "        # Get LLM prediction and actual price - handle NaN\n",
    "        llm_pred = float(self.data.iloc[idx]['llm_prediction'])\n",
    "        actual_price = float(self.data.iloc[idx]['actual_price'])\n",
    "        \n",
    "        if np.isnan(llm_pred) or np.isinf(llm_pred):\n",
    "            llm_pred = actual_price\n",
    "        if np.isnan(actual_price) or np.isinf(actual_price):\n",
    "            actual_price = llm_pred\n",
    "        \n",
    "        # Apply action (adjustment)\n",
    "        adjustment = float(action[0])\n",
    "        if np.isnan(adjustment) or np.isinf(adjustment):\n",
    "            adjustment = 0.0\n",
    "        adjusted_pred = llm_pred * (1 + adjustment)\n",
    "        \n",
    "        # Calculate prediction error (absolute and percentage)\n",
    "        pred_error = abs(adjusted_pred - actual_price)\n",
    "        if actual_price != 0 and not np.isnan(actual_price):\n",
    "            pct_error = pred_error / abs(actual_price)\n",
    "        else:\n",
    "            pct_error = 0.0\n",
    "        \n",
    "        # Handle NaN in errors\n",
    "        if np.isnan(pred_error) or np.isinf(pred_error):\n",
    "            pred_error = 0.0\n",
    "        if np.isnan(pct_error) or np.isinf(pct_error):\n",
    "            pct_error = 0.0\n",
    "        \n",
    "        # Use percentage error but scale it to make rewards more meaningful\n",
    "        # Multiply by 100 to convert to percentage scale (0.01 error = 1% error = -1 reward)\n",
    "        scaled_error = pct_error * 100\n",
    "        \n",
    "        # Calculate risk penalty (using CVaR)\n",
    "        cvar = 0.0\n",
    "        if 'recent_prices' in self.data.columns and self.data.iloc[idx]['recent_prices'] is not None:\n",
    "            try:\n",
    "                hist_prices = np.array(self.data.iloc[idx]['recent_prices'][-self.window_size:], dtype=np.float32)\n",
    "                hist_prices = np.nan_to_num(hist_prices, nan=llm_pred)\n",
    "                returns = np.diff(hist_prices) / hist_prices[:-1] if len(hist_prices) > 1 else np.array([0.0])\n",
    "                returns = np.nan_to_num(returns, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "                cvar = abs(calculate_cvar(returns, self.confidence_level))\n",
    "                if np.isnan(cvar) or np.isinf(cvar):\n",
    "                    cvar = 0.0\n",
    "            except:\n",
    "                cvar = 0.0\n",
    "        \n",
    "        # Calculate reward according to paper (Equation 4): R_t = -|≈∑_t - y*_t| - Œª¬∑CVaR_Œ±\n",
    "        # The negative values create a reward landscape where:\n",
    "        # - Better predictions (smaller error) ‚Üí less negative (higher) reward\n",
    "        # - Lower risk (smaller CVaR) ‚Üí less negative (higher) reward\n",
    "        # PPO maximizes reward, so it will minimize both error and CVaR\n",
    "        risk_penalty = self.lambda_risk * cvar * 100  # Scale CVaR similarly to error\n",
    "        \n",
    "        # Add bonus for improving over LLM baseline\n",
    "        llm_error = abs(llm_pred - actual_price)\n",
    "        if actual_price != 0 and not np.isnan(actual_price):\n",
    "            llm_pct_error = llm_error / abs(actual_price) * 100\n",
    "        else:\n",
    "            llm_pct_error = 0.0\n",
    "        \n",
    "        # Improvement bonus: positive reward if we beat the LLM\n",
    "        improvement = llm_pct_error - scaled_error\n",
    "        \n",
    "        # Reward function: encourage improvement over baseline\n",
    "        reward = -scaled_error - risk_penalty + (improvement * 0.5)\n",
    "        \n",
    "        if np.isnan(reward) or np.isinf(reward):\n",
    "            reward = -100.0  # Default penalty for invalid states\n",
    "        \n",
    "        # Move to next step\n",
    "        self.current_step += 1\n",
    "        terminated = self.current_step >= self.max_steps\n",
    "        truncated = False\n",
    "        \n",
    "        # Next observation\n",
    "        next_state = self._get_observation()\n",
    "        \n",
    "        return next_state, reward, terminated, truncated, {}\n",
    "\n",
    "print(\"Stock Prediction Environment with NaN handling defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c3faf4",
   "metadata": {},
   "source": [
    "## 6. Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "73ae8573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing StockPredictionEnv with sample data...\n",
      "================================================================================\n",
      "‚úÖ Environment reset successful!\n",
      "\n",
      "üìä Observation Details:\n",
      "   Shape: (14,)\n",
      "   Contains NaN: False\n",
      "   Contains Inf: False\n",
      "   Min value: -0.0182\n",
      "   Max value: 1531.8000\n",
      "   Mean value: 644.0595\n",
      "\n",
      "   First 5 values: [1500.  1479.2 1505.2 1502.8 1493. ]\n",
      "\n",
      "üéØ Testing environment steps...\n",
      "   ‚úÖ Step 1: Valid (reward=-7.2374)\n",
      "   ‚úÖ Step 2: Valid (reward=-7.2957)\n",
      "   ‚úÖ Step 3: Valid (reward=-19.0162)\n",
      "   ‚úÖ Step 4: Valid (reward=-13.9041)\n",
      "   ‚úÖ Step 5: Valid (reward=-2.2665)\n",
      "   ‚úÖ Step 6: Valid (reward=-23.7420)\n",
      "   ‚úÖ Step 7: Valid (reward=-16.7234)\n",
      "   ‚úÖ Step 8: Valid (reward=-4.5534)\n",
      "   ‚úÖ Step 9: Valid (reward=-4.9790)\n",
      "   ‚úÖ Step 10: Valid (reward=-3.7255)\n",
      "\n",
      "================================================================================\n",
      "‚úÖ ENVIRONMENT TEST PASSED!\n",
      "üí° The environment is ready for PPO training.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test the environment to ensure it produces valid observations\n",
    "print(\"üß™ Testing StockPredictionEnv with sample data...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    # Create test environment\n",
    "    test_env = StockPredictionEnv(train_df_ppo, window_size=5)\n",
    "    \n",
    "    # Reset and get first observation\n",
    "    obs, info = test_env.reset()\n",
    "    \n",
    "    print(f\"‚úÖ Environment reset successful!\")\n",
    "    print(f\"\\nüìä Observation Details:\")\n",
    "    print(f\"   Shape: {obs.shape}\")\n",
    "    print(f\"   Contains NaN: {np.any(np.isnan(obs))}\")\n",
    "    print(f\"   Contains Inf: {np.any(np.isinf(obs))}\")\n",
    "    print(f\"   Min value: {np.min(obs):.4f}\")\n",
    "    print(f\"   Max value: {np.max(obs):.4f}\")\n",
    "    print(f\"   Mean value: {np.mean(obs):.4f}\")\n",
    "    print(f\"\\n   First 5 values: {obs[:5]}\")\n",
    "    \n",
    "    # Try a few steps\n",
    "    print(f\"\\nüéØ Testing environment steps...\")\n",
    "    for i in range(10):\n",
    "        action = test_env.action_space.sample()\n",
    "        next_obs, reward, terminated, truncated, info = test_env.step(action)\n",
    "        \n",
    "        has_nan = np.any(np.isnan(next_obs))\n",
    "        has_inf = np.any(np.isinf(next_obs))\n",
    "        reward_invalid = np.isnan(reward) or np.isinf(reward)\n",
    "        \n",
    "        if has_nan or has_inf or reward_invalid:\n",
    "            print(f\"   ‚ùå Step {i+1}: NaN={has_nan}, Inf={has_inf}, Reward NaN/Inf={reward_invalid}\")\n",
    "            print(f\"      Observation: {next_obs}\")\n",
    "            print(f\"      Reward: {reward}\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"   ‚úÖ Step {i+1}: Valid (reward={reward:.4f})\")\n",
    "        \n",
    "        if terminated or truncated:\n",
    "            break\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"‚úÖ ENVIRONMENT TEST PASSED!\")\n",
    "    print(f\"üí° The environment is ready for PPO training.\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå ENVIRONMENT TEST FAILED!\")\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc549a2",
   "metadata": {},
   "source": [
    "## 7. Train PPO Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b566a7",
   "metadata": {},
   "source": [
    "## 7. Validation Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bdb9ffd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation evaluation function defined.\n"
     ]
    }
   ],
   "source": [
    "def evaluate_on_validation(model, val_df, window_size=5):\n",
    "    \"\"\"\n",
    "    Evaluate PPO model on validation set\n",
    "    Returns MAE and other metrics\n",
    "    \"\"\"\n",
    "    env = StockPredictionEnv(val_df, window_size=window_size)\n",
    "    obs, _ = env.reset()\n",
    "    \n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    rewards_list = []\n",
    "    \n",
    "    for idx in range(len(val_df)):\n",
    "        if idx < window_size:\n",
    "            # For early samples, use LLM prediction as-is\n",
    "            predictions.append(val_df.iloc[idx]['llm_prediction'])\n",
    "            actuals.append(val_df.iloc[idx]['actual_price'])\n",
    "            continue\n",
    "        \n",
    "        # Get PPO action\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        \n",
    "        # Apply adjustment\n",
    "        llm_pred = val_df.iloc[idx]['llm_prediction']\n",
    "        adjusted_pred = llm_pred * (1 + action[0])\n",
    "        predictions.append(adjusted_pred)\n",
    "        actuals.append(val_df.iloc[idx]['actual_price'])\n",
    "        \n",
    "        # Step environment\n",
    "        if idx < len(val_df) - 1:\n",
    "            obs, reward, terminated, _, _ = env.step(action)\n",
    "            rewards_list.append(reward)\n",
    "            if terminated:\n",
    "                break\n",
    "    \n",
    "    predictions = np.array(predictions)\n",
    "    actuals = np.array(actuals)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae = np.mean(np.abs(predictions - actuals))\n",
    "    mape = np.mean(np.abs((predictions - actuals) / actuals)) * 100\n",
    "    rmse = np.sqrt(np.mean((predictions - actuals) ** 2))\n",
    "    avg_reward = np.mean(rewards_list) if rewards_list else 0.0\n",
    "    \n",
    "    return {\n",
    "        'mae': mae,\n",
    "        'mape': mape,\n",
    "        'rmse': rmse,\n",
    "        'avg_reward': avg_reward,\n",
    "        'predictions': predictions,\n",
    "        'actuals': actuals\n",
    "    }\n",
    "\n",
    "print(\"Validation evaluation function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8df14ff",
   "metadata": {},
   "source": [
    "## 8. Train PPO with Validation-Based Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10c6466",
   "metadata": {},
   "source": [
    "## 8. Hyperparameter Search using Validation Set\n",
    "\n",
    "Let's systematically test different PPO configurations to find the best parameters that improve over the LLM baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d9a70905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üîç PPO HYPERPARAMETER SEARCH\n",
      "================================================================================\n",
      "\n",
      "üéØ Target to Beat: 58.9895 (LLM-only validation MAE)\n",
      "   Goal: Find PPO params that reduce MAE by >5%\n",
      "\n",
      "üìã Testing 8 strategic configurations\n",
      "   Training: 8698 samples\n",
      "   Validation: 1243 samples\n",
      "   Training duration: 40k timesteps per config (~5 min each)\n",
      "\n",
      "================================================================================\n",
      "STARTING HYPERPARAMETER SEARCH\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Search with Validation Set\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üîç PPO HYPERPARAMETER SEARCH\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate LLM baseline on validation set\n",
    "llm_val_mae_baseline = np.mean(np.abs(val_df_ppo['llm_prediction'] - val_df_ppo['actual_price']))\n",
    "print(f\"\\nüéØ Target to Beat: {llm_val_mae_baseline:.4f} (LLM-only validation MAE)\")\n",
    "print(f\"   Goal: Find PPO params that reduce MAE by >5%\")\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': [1e-4, 5e-5, 1e-5],\n",
    "    'action_space_range': [0.01, 0.02, 0.05],  # ¬±1%, ¬±2%, ¬±5%\n",
    "    'lambda_risk': [1.0, 5.0, 10.0],  # CVaR weight\n",
    "    'ent_coef': [0.0, 0.01, 0.02],  # Entropy coefficient\n",
    "    'improvement_bonus_weight': [0.0, 0.5, 1.0],  # Bonus for beating LLM\n",
    "}\n",
    "\n",
    "# For faster iteration, we'll sample key combinations\n",
    "# Full grid would be 3√ó3√ó3√ó3√ó3 = 243 combinations\n",
    "# Let's test strategic combinations instead\n",
    "test_configs = [\n",
    "    # Baseline config (current best)\n",
    "    {'name': 'Current Best', 'learning_rate': 5e-5, 'action_space_range': 0.02, 'lambda_risk': 5.0, 'ent_coef': 0.02, 'improvement_bonus_weight': 0.5},\n",
    "    \n",
    "    # More conservative adjustments\n",
    "    {'name': 'Conservative', 'learning_rate': 1e-5, 'action_space_range': 0.01, 'lambda_risk': 10.0, 'ent_coef': 0.01, 'improvement_bonus_weight': 1.0},\n",
    "    \n",
    "    # More aggressive adjustments\n",
    "    {'name': 'Aggressive', 'learning_rate': 1e-4, 'action_space_range': 0.05, 'lambda_risk': 1.0, 'ent_coef': 0.02, 'improvement_bonus_weight': 0.5},\n",
    "    \n",
    "    # Higher exploration\n",
    "    {'name': 'High Exploration', 'learning_rate': 5e-5, 'action_space_range': 0.02, 'lambda_risk': 5.0, 'ent_coef': 0.05, 'improvement_bonus_weight': 0.5},\n",
    "    \n",
    "    # Focus on improvement bonus\n",
    "    {'name': 'Bonus Focused', 'learning_rate': 5e-5, 'action_space_range': 0.02, 'lambda_risk': 2.0, 'ent_coef': 0.01, 'improvement_bonus_weight': 2.0},\n",
    "    \n",
    "    # Risk averse\n",
    "    {'name': 'Risk Averse', 'learning_rate': 5e-5, 'action_space_range': 0.01, 'lambda_risk': 15.0, 'ent_coef': 0.0, 'improvement_bonus_weight': 0.5},\n",
    "    \n",
    "    # Balanced\n",
    "    {'name': 'Balanced', 'learning_rate': 5e-5, 'action_space_range': 0.03, 'lambda_risk': 5.0, 'ent_coef': 0.015, 'improvement_bonus_weight': 1.0},\n",
    "    \n",
    "    # Fast learner\n",
    "    {'name': 'Fast Learner', 'learning_rate': 1e-4, 'action_space_range': 0.02, 'lambda_risk': 5.0, 'ent_coef': 0.02, 'improvement_bonus_weight': 1.5},\n",
    "]\n",
    "\n",
    "print(f\"\\nüìã Testing {len(test_configs)} strategic configurations\")\n",
    "print(f\"   Training: {len(train_df_ppo)} samples\")\n",
    "print(f\"   Validation: {len(val_df_ppo)} samples\")\n",
    "print(f\"   Training duration: 40k timesteps per config (~5 min each)\")\n",
    "\n",
    "# Store results\n",
    "search_results = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STARTING HYPERPARAMETER SEARCH\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ac05fef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom environment for hyperparameter search defined.\n"
     ]
    }
   ],
   "source": [
    "# Custom environment class for hyperparameter search\n",
    "class CustomStockEnv(gym.Env):\n",
    "    \"\"\"Environment with configurable hyperparameters\"\"\"\n",
    "    \n",
    "    def __init__(self, data_df: pd.DataFrame, window_size: int = 5, \n",
    "                 action_range: float = 0.02, lambda_risk: float = 5.0, \n",
    "                 improvement_bonus_weight: float = 0.5):\n",
    "        super(CustomStockEnv, self).__init__()\n",
    "        \n",
    "        self.data = data_df.copy()\n",
    "        self.window_size = window_size\n",
    "        self.current_step = 0\n",
    "        self.max_steps = len(self.data)\n",
    "        self.lambda_risk = lambda_risk\n",
    "        self.improvement_bonus_weight = improvement_bonus_weight\n",
    "        \n",
    "        # Extra features\n",
    "        self.extra_feature_cols = [\n",
    "            'llm_likelihood', 'justification_pos_ratio', 'justification_neg_ratio',\n",
    "            'justification_risk_ratio', 'justification_polarity', 'justification_length'\n",
    "        ]\n",
    "        self.available_extra_cols = [c for c in self.extra_feature_cols if c in self.data.columns]\n",
    "        \n",
    "        state_dim = 1 + window_size + 2 + len(self.available_extra_cols)\n",
    "        \n",
    "        # Configurable action space\n",
    "        self.action_space = spaces.Box(\n",
    "            low=-action_range, high=action_range, shape=(1,), dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf, shape=(state_dim,), dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        self.confidence_level = 0.95\n",
    "        \n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.current_step = self.window_size\n",
    "        return self._get_observation(), {}\n",
    "    \n",
    "    def _get_observation(self):\n",
    "        idx = min(self.current_step, self.max_steps - 1)\n",
    "        \n",
    "        llm_pred = float(self.data.iloc[idx]['llm_prediction'])\n",
    "        if np.isnan(llm_pred) or np.isinf(llm_pred):\n",
    "            llm_pred = float(self.data.iloc[idx]['actual_price'])\n",
    "        \n",
    "        hist_prices = []\n",
    "        if 'recent_prices' in self.data.columns and self.data.iloc[idx]['recent_prices'] is not None:\n",
    "            try:\n",
    "                hist_prices = [float(p) for p in self.data.iloc[idx]['recent_prices']]\n",
    "                hist_prices = [p if not (np.isnan(p) or np.isinf(p)) else llm_pred for p in hist_prices]\n",
    "            except:\n",
    "                hist_prices = []\n",
    "        \n",
    "        if len(hist_prices) < self.window_size:\n",
    "            pad_value = hist_prices[-1] if hist_prices else llm_pred\n",
    "            hist_prices = hist_prices + [pad_value] * (self.window_size - len(hist_prices))\n",
    "        hist_prices = np.array(hist_prices[-self.window_size:], dtype=np.float32)\n",
    "        \n",
    "        volatility = calculate_volatility(hist_prices)\n",
    "        if np.isnan(volatility) or np.isinf(volatility):\n",
    "            volatility = 0.0\n",
    "        \n",
    "        returns = np.diff(hist_prices) / hist_prices[:-1] if len(hist_prices) > 1 else np.array([0.0])\n",
    "        returns = np.nan_to_num(returns, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        var = calculate_var(returns, self.confidence_level)\n",
    "        if np.isnan(var) or np.isinf(var):\n",
    "            var = 0.0\n",
    "        \n",
    "        extra_features = []\n",
    "        for col in self.available_extra_cols:\n",
    "            val = float(self.data.iloc[idx].get(col, 0.0))\n",
    "            if np.isnan(val) or np.isinf(val):\n",
    "                val = 0.0\n",
    "            extra_features.append(val)\n",
    "        \n",
    "        state = np.concatenate([\n",
    "            np.array([llm_pred], dtype=np.float32),\n",
    "            hist_prices,\n",
    "            np.array([volatility, var], dtype=np.float32),\n",
    "            np.array(extra_features, dtype=np.float32)\n",
    "        ])\n",
    "        \n",
    "        state = np.nan_to_num(state, nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "        return state.astype(np.float32)\n",
    "    \n",
    "    def step(self, action):\n",
    "        idx = min(self.current_step, self.max_steps - 1)\n",
    "        \n",
    "        llm_pred = float(self.data.iloc[idx]['llm_prediction'])\n",
    "        actual_price = float(self.data.iloc[idx]['actual_price'])\n",
    "        \n",
    "        if np.isnan(llm_pred) or np.isinf(llm_pred):\n",
    "            llm_pred = actual_price\n",
    "        if np.isnan(actual_price) or np.isinf(actual_price):\n",
    "            actual_price = llm_pred\n",
    "        \n",
    "        adjustment = float(action[0])\n",
    "        if np.isnan(adjustment) or np.isinf(adjustment):\n",
    "            adjustment = 0.0\n",
    "        adjusted_pred = llm_pred * (1 + adjustment)\n",
    "        \n",
    "        pred_error = abs(adjusted_pred - actual_price)\n",
    "        if actual_price != 0 and not np.isnan(actual_price):\n",
    "            pct_error = pred_error / abs(actual_price)\n",
    "        else:\n",
    "            pct_error = 0.0\n",
    "        \n",
    "        if np.isnan(pred_error) or np.isinf(pred_error):\n",
    "            pred_error = 0.0\n",
    "        if np.isnan(pct_error) or np.isinf(pct_error):\n",
    "            pct_error = 0.0\n",
    "        \n",
    "        scaled_error = pct_error * 100\n",
    "        \n",
    "        cvar = 0.0\n",
    "        if 'recent_prices' in self.data.columns and self.data.iloc[idx]['recent_prices'] is not None:\n",
    "            try:\n",
    "                hist_prices = np.array(self.data.iloc[idx]['recent_prices'][-self.window_size:], dtype=np.float32)\n",
    "                hist_prices = np.nan_to_num(hist_prices, nan=llm_pred)\n",
    "                returns = np.diff(hist_prices) / hist_prices[:-1] if len(hist_prices) > 1 else np.array([0.0])\n",
    "                returns = np.nan_to_num(returns, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "                cvar = abs(calculate_cvar(returns, self.confidence_level))\n",
    "                if np.isnan(cvar) or np.isinf(cvar):\n",
    "                    cvar = 0.0\n",
    "            except:\n",
    "                cvar = 0.0\n",
    "        \n",
    "        risk_penalty = self.lambda_risk * cvar * 100\n",
    "        \n",
    "        llm_error = abs(llm_pred - actual_price)\n",
    "        if actual_price != 0 and not np.isnan(actual_price):\n",
    "            llm_pct_error = llm_error / abs(actual_price) * 100\n",
    "        else:\n",
    "            llm_pct_error = 0.0\n",
    "        \n",
    "        improvement = llm_pct_error - scaled_error\n",
    "        reward = -scaled_error - risk_penalty + (improvement * self.improvement_bonus_weight)\n",
    "        \n",
    "        if np.isnan(reward) or np.isinf(reward):\n",
    "            reward = -100.0\n",
    "        \n",
    "        self.current_step += 1\n",
    "        terminated = self.current_step >= self.max_steps\n",
    "        truncated = False\n",
    "        \n",
    "        next_state = self._get_observation()\n",
    "        \n",
    "        return next_state, reward, terminated, truncated, {}\n",
    "\n",
    "print(\"Custom environment for hyperparameter search defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "afb1bce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üß™ CONFIG 1/8: Current Best\n",
      "================================================================================\n",
      "üìã Parameters:\n",
      "   learning_rate: 5e-05\n",
      "   action_space_range: 0.02\n",
      "   lambda_risk: 5.0\n",
      "   ent_coef: 0.02\n",
      "   improvement_bonus_weight: 0.5\n",
      "\n",
      "‚è≥ Training for 40,000 timesteps...\n",
      "\n",
      "‚ùå Error with config Current Best: You must install tqdm and rich in order to use the progress bar callback. It is included if you install stable-baselines with the extra packages: `pip install stable-baselines3[extra]`\n",
      "\n",
      "================================================================================\n",
      "üß™ CONFIG 2/8: Conservative\n",
      "================================================================================\n",
      "üìã Parameters:\n",
      "   learning_rate: 1e-05\n",
      "   action_space_range: 0.01\n",
      "   lambda_risk: 10.0\n",
      "   ent_coef: 0.01\n",
      "   improvement_bonus_weight: 1.0\n",
      "\n",
      "‚è≥ Training for 40,000 timesteps...\n",
      "\n",
      "‚ùå Error with config Conservative: You must install tqdm and rich in order to use the progress bar callback. It is included if you install stable-baselines with the extra packages: `pip install stable-baselines3[extra]`\n",
      "\n",
      "================================================================================\n",
      "üß™ CONFIG 3/8: Aggressive\n",
      "================================================================================\n",
      "üìã Parameters:\n",
      "   learning_rate: 0.0001\n",
      "   action_space_range: 0.05\n",
      "   lambda_risk: 1.0\n",
      "   ent_coef: 0.02\n",
      "   improvement_bonus_weight: 0.5\n",
      "\n",
      "‚è≥ Training for 40,000 timesteps...\n",
      "\n",
      "‚ùå Error with config Aggressive: You must install tqdm and rich in order to use the progress bar callback. It is included if you install stable-baselines with the extra packages: `pip install stable-baselines3[extra]`\n",
      "\n",
      "================================================================================\n",
      "üß™ CONFIG 4/8: High Exploration\n",
      "================================================================================\n",
      "üìã Parameters:\n",
      "   learning_rate: 5e-05\n",
      "   action_space_range: 0.02\n",
      "   lambda_risk: 5.0\n",
      "   ent_coef: 0.05\n",
      "   improvement_bonus_weight: 0.5\n",
      "\n",
      "‚è≥ Training for 40,000 timesteps...\n",
      "\n",
      "‚ùå Error with config High Exploration: You must install tqdm and rich in order to use the progress bar callback. It is included if you install stable-baselines with the extra packages: `pip install stable-baselines3[extra]`\n",
      "\n",
      "================================================================================\n",
      "üß™ CONFIG 5/8: Bonus Focused\n",
      "================================================================================\n",
      "üìã Parameters:\n",
      "   learning_rate: 5e-05\n",
      "   action_space_range: 0.02\n",
      "   lambda_risk: 2.0\n",
      "   ent_coef: 0.01\n",
      "   improvement_bonus_weight: 2.0\n",
      "\n",
      "‚è≥ Training for 40,000 timesteps...\n",
      "\n",
      "‚ùå Error with config Bonus Focused: You must install tqdm and rich in order to use the progress bar callback. It is included if you install stable-baselines with the extra packages: `pip install stable-baselines3[extra]`\n",
      "\n",
      "================================================================================\n",
      "üß™ CONFIG 6/8: Risk Averse\n",
      "================================================================================\n",
      "üìã Parameters:\n",
      "   learning_rate: 5e-05\n",
      "   action_space_range: 0.01\n",
      "   lambda_risk: 15.0\n",
      "   ent_coef: 0.0\n",
      "   improvement_bonus_weight: 0.5\n",
      "\n",
      "‚è≥ Training for 40,000 timesteps...\n",
      "\n",
      "‚ùå Error with config Risk Averse: You must install tqdm and rich in order to use the progress bar callback. It is included if you install stable-baselines with the extra packages: `pip install stable-baselines3[extra]`\n",
      "\n",
      "================================================================================\n",
      "üß™ CONFIG 7/8: Balanced\n",
      "================================================================================\n",
      "üìã Parameters:\n",
      "   learning_rate: 5e-05\n",
      "   action_space_range: 0.03\n",
      "   lambda_risk: 5.0\n",
      "   ent_coef: 0.015\n",
      "   improvement_bonus_weight: 1.0\n",
      "\n",
      "‚è≥ Training for 40,000 timesteps...\n",
      "\n",
      "‚ùå Error with config Balanced: You must install tqdm and rich in order to use the progress bar callback. It is included if you install stable-baselines with the extra packages: `pip install stable-baselines3[extra]`\n",
      "\n",
      "================================================================================\n",
      "üß™ CONFIG 8/8: Fast Learner\n",
      "================================================================================\n",
      "üìã Parameters:\n",
      "   learning_rate: 0.0001\n",
      "   action_space_range: 0.02\n",
      "   lambda_risk: 5.0\n",
      "   ent_coef: 0.02\n",
      "   improvement_bonus_weight: 1.5\n",
      "\n",
      "‚è≥ Training for 40,000 timesteps...\n",
      "\n",
      "‚ùå Error with config Fast Learner: You must install tqdm and rich in order to use the progress bar callback. It is included if you install stable-baselines with the extra packages: `pip install stable-baselines3[extra]`\n",
      "\n",
      "================================================================================\n",
      "‚úÖ HYPERPARAMETER SEARCH COMPLETE\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/fv/jpyrhgqn0xxgp87qx4gdn69w0000gn/T/ipykernel_52246/2642859765.py\", line 42, in <module>\n",
      "    ppo_model.learn(total_timesteps=40000, progress_bar=True)\n",
      "    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/ppo/ppo.py\", line 315, in learn\n",
      "    return super().learn(\n",
      "           ~~~~~~~~~~~~~^\n",
      "        total_timesteps=total_timesteps,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        progress_bar=progress_bar,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/common/on_policy_algorithm.py\", line 287, in learn\n",
      "    total_timesteps, callback = self._setup_learn(\n",
      "                                ~~~~~~~~~~~~~~~~~^\n",
      "        total_timesteps,\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "        progress_bar,\n",
      "        ^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/common/base_class.py\", line 434, in _setup_learn\n",
      "    callback = self._init_callback(callback, progress_bar)\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/common/base_class.py\", line 378, in _init_callback\n",
      "    callback = CallbackList([callback, ProgressBarCallback()])\n",
      "                                       ~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/common/callbacks.py\", line 690, in __init__\n",
      "    raise ImportError(\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "ImportError: You must install tqdm and rich in order to use the progress bar callback. It is included if you install stable-baselines with the extra packages: `pip install stable-baselines3[extra]`\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/fv/jpyrhgqn0xxgp87qx4gdn69w0000gn/T/ipykernel_52246/2642859765.py\", line 42, in <module>\n",
      "    ppo_model.learn(total_timesteps=40000, progress_bar=True)\n",
      "    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/ppo/ppo.py\", line 315, in learn\n",
      "    return super().learn(\n",
      "           ~~~~~~~~~~~~~^\n",
      "        total_timesteps=total_timesteps,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        progress_bar=progress_bar,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/common/on_policy_algorithm.py\", line 287, in learn\n",
      "    total_timesteps, callback = self._setup_learn(\n",
      "                                ~~~~~~~~~~~~~~~~~^\n",
      "        total_timesteps,\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "        progress_bar,\n",
      "        ^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/common/base_class.py\", line 434, in _setup_learn\n",
      "    callback = self._init_callback(callback, progress_bar)\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/common/base_class.py\", line 378, in _init_callback\n",
      "    callback = CallbackList([callback, ProgressBarCallback()])\n",
      "                                       ~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/common/callbacks.py\", line 690, in __init__\n",
      "    raise ImportError(\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "ImportError: You must install tqdm and rich in order to use the progress bar callback. It is included if you install stable-baselines with the extra packages: `pip install stable-baselines3[extra]`\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/fv/jpyrhgqn0xxgp87qx4gdn69w0000gn/T/ipykernel_52246/2642859765.py\", line 42, in <module>\n",
      "    ppo_model.learn(total_timesteps=40000, progress_bar=True)\n",
      "    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/ppo/ppo.py\", line 315, in learn\n",
      "    return super().learn(\n",
      "           ~~~~~~~~~~~~~^\n",
      "        total_timesteps=total_timesteps,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        progress_bar=progress_bar,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/common/on_policy_algorithm.py\", line 287, in learn\n",
      "    total_timesteps, callback = self._setup_learn(\n",
      "                                ~~~~~~~~~~~~~~~~~^\n",
      "        total_timesteps,\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "        progress_bar,\n",
      "        ^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/common/base_class.py\", line 434, in _setup_learn\n",
      "    callback = self._init_callback(callback, progress_bar)\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/common/base_class.py\", line 378, in _init_callback\n",
      "    callback = CallbackList([callback, ProgressBarCallback()])\n",
      "                                       ~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/common/callbacks.py\", line 690, in __init__\n",
      "    raise ImportError(\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "ImportError: You must install tqdm and rich in order to use the progress bar callback. It is included if you install stable-baselines with the extra packages: `pip install stable-baselines3[extra]`\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/fv/jpyrhgqn0xxgp87qx4gdn69w0000gn/T/ipykernel_52246/2642859765.py\", line 42, in <module>\n",
      "    ppo_model.learn(total_timesteps=40000, progress_bar=True)\n",
      "    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/ppo/ppo.py\", line 315, in learn\n",
      "    return super().learn(\n",
      "           ~~~~~~~~~~~~~^\n",
      "        total_timesteps=total_timesteps,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        progress_bar=progress_bar,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/common/on_policy_algorithm.py\", line 287, in learn\n",
      "    total_timesteps, callback = self._setup_learn(\n",
      "                                ~~~~~~~~~~~~~~~~~^\n",
      "        total_timesteps,\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "        progress_bar,\n",
      "        ^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/common/base_class.py\", line 434, in _setup_learn\n",
      "    callback = self._init_callback(callback, progress_bar)\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/common/base_class.py\", line 378, in _init_callback\n",
      "    callback = CallbackList([callback, ProgressBarCallback()])\n",
      "                                       ~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/common/callbacks.py\", line 690, in __init__\n",
      "    raise ImportError(\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "ImportError: You must install tqdm and rich in order to use the progress bar callback. It is included if you install stable-baselines with the extra packages: `pip install stable-baselines3[extra]`\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/fv/jpyrhgqn0xxgp87qx4gdn69w0000gn/T/ipykernel_52246/2642859765.py\", line 42, in <module>\n",
      "    ppo_model.learn(total_timesteps=40000, progress_bar=True)\n",
      "    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/ppo/ppo.py\", line 315, in learn\n",
      "    return super().learn(\n",
      "           ~~~~~~~~~~~~~^\n",
      "        total_timesteps=total_timesteps,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        progress_bar=progress_bar,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/common/on_policy_algorithm.py\", line 287, in learn\n",
      "    total_timesteps, callback = self._setup_learn(\n",
      "                                ~~~~~~~~~~~~~~~~~^\n",
      "        total_timesteps,\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "        progress_bar,\n",
      "        ^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/common/base_class.py\", line 434, in _setup_learn\n",
      "    callback = self._init_callback(callback, progress_bar)\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/common/base_class.py\", line 378, in _init_callback\n",
      "    callback = CallbackList([callback, ProgressBarCallback()])\n",
      "                                       ~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/common/callbacks.py\", line 690, in __init__\n",
      "    raise ImportError(\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "ImportError: You must install tqdm and rich in order to use the progress bar callback. It is included if you install stable-baselines with the extra packages: `pip install stable-baselines3[extra]`\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/fv/jpyrhgqn0xxgp87qx4gdn69w0000gn/T/ipykernel_52246/2642859765.py\", line 42, in <module>\n",
      "    ppo_model.learn(total_timesteps=40000, progress_bar=True)\n",
      "    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/ppo/ppo.py\", line 315, in learn\n",
      "    return super().learn(\n",
      "           ~~~~~~~~~~~~~^\n",
      "        total_timesteps=total_timesteps,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        progress_bar=progress_bar,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/common/on_policy_algorithm.py\", line 287, in learn\n",
      "    total_timesteps, callback = self._setup_learn(\n",
      "                                ~~~~~~~~~~~~~~~~~^\n",
      "        total_timesteps,\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "        progress_bar,\n",
      "        ^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/common/base_class.py\", line 434, in _setup_learn\n",
      "    callback = self._init_callback(callback, progress_bar)\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/common/base_class.py\", line 378, in _init_callback\n",
      "    callback = CallbackList([callback, ProgressBarCallback()])\n",
      "                                       ~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/common/callbacks.py\", line 690, in __init__\n",
      "    raise ImportError(\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "ImportError: You must install tqdm and rich in order to use the progress bar callback. It is included if you install stable-baselines with the extra packages: `pip install stable-baselines3[extra]`\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/fv/jpyrhgqn0xxgp87qx4gdn69w0000gn/T/ipykernel_52246/2642859765.py\", line 42, in <module>\n",
      "    ppo_model.learn(total_timesteps=40000, progress_bar=True)\n",
      "    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/ppo/ppo.py\", line 315, in learn\n",
      "    return super().learn(\n",
      "           ~~~~~~~~~~~~~^\n",
      "        total_timesteps=total_timesteps,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        progress_bar=progress_bar,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/common/on_policy_algorithm.py\", line 287, in learn\n",
      "    total_timesteps, callback = self._setup_learn(\n",
      "                                ~~~~~~~~~~~~~~~~~^\n",
      "        total_timesteps,\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "        progress_bar,\n",
      "        ^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/common/base_class.py\", line 434, in _setup_learn\n",
      "    callback = self._init_callback(callback, progress_bar)\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/common/base_class.py\", line 378, in _init_callback\n",
      "    callback = CallbackList([callback, ProgressBarCallback()])\n",
      "                                       ~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/common/callbacks.py\", line 690, in __init__\n",
      "    raise ImportError(\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "ImportError: You must install tqdm and rich in order to use the progress bar callback. It is included if you install stable-baselines with the extra packages: `pip install stable-baselines3[extra]`\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/fv/jpyrhgqn0xxgp87qx4gdn69w0000gn/T/ipykernel_52246/2642859765.py\", line 42, in <module>\n",
      "    ppo_model.learn(total_timesteps=40000, progress_bar=True)\n",
      "    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/ppo/ppo.py\", line 315, in learn\n",
      "    return super().learn(\n",
      "           ~~~~~~~~~~~~~^\n",
      "        total_timesteps=total_timesteps,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        progress_bar=progress_bar,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/common/on_policy_algorithm.py\", line 287, in learn\n",
      "    total_timesteps, callback = self._setup_learn(\n",
      "                                ~~~~~~~~~~~~~~~~~^\n",
      "        total_timesteps,\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "        progress_bar,\n",
      "        ^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/common/base_class.py\", line 434, in _setup_learn\n",
      "    callback = self._init_callback(callback, progress_bar)\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/common/base_class.py\", line 378, in _init_callback\n",
      "    callback = CallbackList([callback, ProgressBarCallback()])\n",
      "                                       ~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/Users/angjiayi/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/stable_baselines3/common/callbacks.py\", line 690, in __init__\n",
      "    raise ImportError(\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "ImportError: You must install tqdm and rich in order to use the progress bar callback. It is included if you install stable-baselines with the extra packages: `pip install stable-baselines3[extra]`\n"
     ]
    }
   ],
   "source": [
    "# Run hyperparameter search\n",
    "for config_idx, config in enumerate(test_configs):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üß™ CONFIG {config_idx + 1}/{len(test_configs)}: {config['name']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Print config details\n",
    "    print(f\"üìã Parameters:\")\n",
    "    for key, value in config.items():\n",
    "        if key != 'name':\n",
    "            print(f\"   {key}: {value}\")\n",
    "    \n",
    "    try:\n",
    "        # Create environment with custom hyperparameters\n",
    "        train_env = CustomStockEnv(\n",
    "            train_df_ppo, \n",
    "            window_size=5,\n",
    "            action_range=config['action_space_range'],\n",
    "            lambda_risk=config['lambda_risk'],\n",
    "            improvement_bonus_weight=config['improvement_bonus_weight']\n",
    "        )\n",
    "        \n",
    "        # Initialize PPO with config\n",
    "        ppo_model = PPO(\n",
    "            \"MlpPolicy\",\n",
    "            train_env,\n",
    "            learning_rate=config['learning_rate'],\n",
    "            n_steps=2048,\n",
    "            batch_size=64,\n",
    "            n_epochs=10,\n",
    "            gamma=0.99,\n",
    "            clip_range=0.2,\n",
    "            ent_coef=config['ent_coef'],\n",
    "            vf_coef=0.5,\n",
    "            verbose=0,  # Suppress output for cleaner logs\n",
    "            max_grad_norm=0.5\n",
    "        )\n",
    "        \n",
    "        # Train for shorter duration (40k timesteps for speed)\n",
    "        print(f\"\\n‚è≥ Training for 40,000 timesteps...\")\n",
    "        start_time = datetime.now()\n",
    "        ppo_model.learn(total_timesteps=40000, progress_bar=True)\n",
    "        training_time = (datetime.now() - start_time).total_seconds()\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        print(f\"‚úÖ Training complete ({training_time:.1f}s)\")\n",
    "        print(f\"üîç Evaluating on validation set...\")\n",
    "        \n",
    "        val_env = CustomStockEnv(\n",
    "            val_df_ppo,\n",
    "            window_size=5,\n",
    "            action_range=config['action_space_range'],\n",
    "            lambda_risk=config['lambda_risk'],\n",
    "            improvement_bonus_weight=config['improvement_bonus_weight']\n",
    "        )\n",
    "        \n",
    "        obs, _ = val_env.reset()\n",
    "        predictions = []\n",
    "        actuals = []\n",
    "        rewards = []\n",
    "        \n",
    "        for idx in range(len(val_df_ppo)):\n",
    "            if idx < 5:  # window_size\n",
    "                predictions.append(val_df_ppo.iloc[idx]['llm_prediction'])\n",
    "                actuals.append(val_df_ppo.iloc[idx]['actual_price'])\n",
    "                continue\n",
    "            \n",
    "            action, _ = ppo_model.predict(obs, deterministic=True)\n",
    "            llm_pred = val_df_ppo.iloc[idx]['llm_prediction']\n",
    "            adjusted_pred = llm_pred * (1 + action[0])\n",
    "            predictions.append(adjusted_pred)\n",
    "            actuals.append(val_df_ppo.iloc[idx]['actual_price'])\n",
    "            \n",
    "            if idx < len(val_df_ppo) - 1:\n",
    "                obs, reward, terminated, _, _ = val_env.step(action)\n",
    "                rewards.append(reward)\n",
    "                if terminated:\n",
    "                    break\n",
    "        \n",
    "        predictions = np.array(predictions)\n",
    "        actuals = np.array(actuals)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        val_mae = np.mean(np.abs(predictions - actuals))\n",
    "        val_mape = np.mean(np.abs((predictions - actuals) / actuals)) * 100\n",
    "        val_rmse = np.sqrt(np.mean((predictions - actuals) ** 2))\n",
    "        avg_reward = np.mean(rewards) if rewards else 0.0\n",
    "        improvement_pct = ((llm_val_mae_baseline - val_mae) / llm_val_mae_baseline) * 100\n",
    "        \n",
    "        # Store results\n",
    "        result = {\n",
    "            'config_name': config['name'],\n",
    "            'config': config.copy(),\n",
    "            'val_mae': val_mae,\n",
    "            'val_mape': val_mape,\n",
    "            'val_rmse': val_rmse,\n",
    "            'avg_reward': avg_reward,\n",
    "            'improvement_pct': improvement_pct,\n",
    "            'training_time': training_time,\n",
    "            'model': ppo_model  # Store the model\n",
    "        }\n",
    "        search_results.append(result)\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"\\nüìä Validation Results:\")\n",
    "        print(f\"   MAE: {val_mae:.4f} (LLM baseline: {llm_val_mae_baseline:.4f})\")\n",
    "        print(f\"   MAPE: {val_mape:.2f}%\")\n",
    "        print(f\"   RMSE: {val_rmse:.4f}\")\n",
    "        print(f\"   Avg Reward: {avg_reward:.4f}\")\n",
    "        print(f\"   {'‚úÖ' if improvement_pct > 0 else '‚ùå'} Improvement: {improvement_pct:+.2f}%\")\n",
    "        \n",
    "        # Cleanup\n",
    "        train_env.close()\n",
    "        val_env.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error with config {config['name']}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        continue\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"‚úÖ HYPERPARAMETER SEARCH COMPLETE\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8497b2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è No search results available\n"
     ]
    }
   ],
   "source": [
    "# Analyze and visualize search results\n",
    "if search_results:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä HYPERPARAMETER SEARCH SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Create summary DataFrame\n",
    "    summary_data = []\n",
    "    for result in search_results:\n",
    "        summary_data.append({\n",
    "            'Config': result['config_name'],\n",
    "            'Val MAE': result['val_mae'],\n",
    "            'Improvement %': result['improvement_pct'],\n",
    "            'Val MAPE': result['val_mape'],\n",
    "            'Avg Reward': result['avg_reward'],\n",
    "            'Training Time (s)': result['training_time'],\n",
    "            'LR': result['config']['learning_rate'],\n",
    "            'Action Range': result['config']['action_space_range'],\n",
    "            'Lambda Risk': result['config']['lambda_risk'],\n",
    "            'Entropy': result['config']['ent_coef'],\n",
    "            'Bonus Weight': result['config']['improvement_bonus_weight']\n",
    "        })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_df = summary_df.sort_values('Val MAE', ascending=True)\n",
    "    \n",
    "    print(f\"\\nüèÜ Top 3 Configurations by Validation MAE:\")\n",
    "    print(summary_df[['Config', 'Val MAE', 'Improvement %', 'Val MAPE']].head(3).to_string(index=False))\n",
    "    \n",
    "    # Find best config\n",
    "    best_result = min(search_results, key=lambda x: x['val_mae'])\n",
    "    best_improvement = max(search_results, key=lambda x: x['improvement_pct'])\n",
    "    \n",
    "    print(f\"\\n‚≠ê BEST CONFIGURATION: {best_result['config_name']}\")\n",
    "    print(f\"   Validation MAE: {best_result['val_mae']:.4f}\")\n",
    "    print(f\"   Improvement: {best_result['improvement_pct']:+.2f}%\")\n",
    "    print(f\"   Parameters:\")\n",
    "    for key, value in best_result['config'].items():\n",
    "        if key != 'name':\n",
    "            print(f\"      {key}: {value}\")\n",
    "    \n",
    "    if best_improvement['config_name'] != best_result['config_name']:\n",
    "        print(f\"\\nüí° BEST IMPROVEMENT: {best_improvement['config_name']}\")\n",
    "        print(f\"   Improvement: {best_improvement['improvement_pct']:+.2f}%\")\n",
    "    \n",
    "    # Visualizations\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Plot 1: MAE comparison\n",
    "    ax1 = axes[0, 0]\n",
    "    colors = ['green' if imp > 0 else 'red' for imp in summary_df['Improvement %']]\n",
    "    bars1 = ax1.barh(range(len(summary_df)), summary_df['Val MAE'], color=colors, alpha=0.7)\n",
    "    ax1.axvline(x=llm_val_mae_baseline, color='blue', linestyle='--', linewidth=2, label=f'LLM Baseline: {llm_val_mae_baseline:.4f}')\n",
    "    ax1.set_yticks(range(len(summary_df)))\n",
    "    ax1.set_yticklabels(summary_df['Config'])\n",
    "    ax1.set_xlabel('Validation MAE', fontsize=12)\n",
    "    ax1.set_title('Validation MAE by Configuration', fontsize=14, fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # Plot 2: Improvement percentage\n",
    "    ax2 = axes[0, 1]\n",
    "    colors2 = ['green' if imp > 0 else 'red' for imp in summary_df['Improvement %']]\n",
    "    bars2 = ax2.barh(range(len(summary_df)), summary_df['Improvement %'], color=colors2, alpha=0.7)\n",
    "    ax2.axvline(x=0, color='black', linestyle='-', linewidth=1)\n",
    "    ax2.set_yticks(range(len(summary_df)))\n",
    "    ax2.set_yticklabels(summary_df['Config'])\n",
    "    ax2.set_xlabel('Improvement over LLM (%)', fontsize=12)\n",
    "    ax2.set_title('Improvement vs Baseline', fontsize=14, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # Plot 3: Parameter effects - Action Range vs MAE\n",
    "    ax3 = axes[1, 0]\n",
    "    scatter_data = summary_df.sort_values('Action Range')\n",
    "    scatter = ax3.scatter(scatter_data['Action Range'], scatter_data['Val MAE'], \n",
    "                          c=scatter_data['Improvement %'], cmap='RdYlGn', \n",
    "                          s=200, alpha=0.7, edgecolors='black', linewidth=2)\n",
    "    for idx, row in scatter_data.iterrows():\n",
    "        ax3.annotate(row['Config'][:10], (row['Action Range'], row['Val MAE']), \n",
    "                    fontsize=8, ha='center', va='bottom')\n",
    "    ax3.axhline(y=llm_val_mae_baseline, color='blue', linestyle='--', linewidth=2, label='LLM Baseline')\n",
    "    ax3.set_xlabel('Action Space Range (¬±%)', fontsize=12)\n",
    "    ax3.set_ylabel('Validation MAE', fontsize=12)\n",
    "    ax3.set_title('Action Range vs Performance', fontsize=14, fontweight='bold')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    plt.colorbar(scatter, ax=ax3, label='Improvement %')\n",
    "    \n",
    "    # Plot 4: Learning Rate vs Improvement\n",
    "    ax4 = axes[1, 1]\n",
    "    scatter_data2 = summary_df.sort_values('LR')\n",
    "    scatter2 = ax4.scatter(scatter_data2['LR'], scatter_data2['Improvement %'], \n",
    "                           c=scatter_data2['Val MAE'], cmap='viridis_r', \n",
    "                           s=200, alpha=0.7, edgecolors='black', linewidth=2)\n",
    "    for idx, row in scatter_data2.iterrows():\n",
    "        ax4.annotate(row['Config'][:10], (row['LR'], row['Improvement %']), \n",
    "                    fontsize=8, ha='center', va='bottom')\n",
    "    ax4.axhline(y=0, color='red', linestyle='--', linewidth=2, label='Break-even')\n",
    "    ax4.set_xlabel('Learning Rate', fontsize=12)\n",
    "    ax4.set_ylabel('Improvement over LLM (%)', fontsize=12)\n",
    "    ax4.set_title('Learning Rate vs Improvement', fontsize=14, fontweight='bold')\n",
    "    ax4.set_xscale('log')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    plt.colorbar(scatter2, ax=ax4, label='Val MAE')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/hyperparameter_search_results.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\nüíæ Visualization saved to ../results/hyperparameter_search_results.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Save results to CSV\n",
    "    summary_df.to_csv('../results/hyperparameter_search_summary.csv', index=False)\n",
    "    print(f\"üíæ Summary saved to ../results/hyperparameter_search_summary.csv\")\n",
    "    \n",
    "    # Display full summary table\n",
    "    print(f\"\\nüìã Full Results Table:\")\n",
    "    display(summary_df.style.background_gradient(subset=['Val MAE'], cmap='RdYlGn_r')\n",
    "                            .background_gradient(subset=['Improvement %'], cmap='RdYlGn')\n",
    "                            .format({'Val MAE': '{:.4f}', 'Improvement %': '{:+.2f}', \n",
    "                                    'Val MAPE': '{:.2f}', 'Avg Reward': '{:.2f}',\n",
    "                                    'Training Time (s)': '{:.1f}', 'LR': '{:.0e}',\n",
    "                                    'Action Range': '{:.3f}', 'Lambda Risk': '{:.1f}',\n",
    "                                    'Entropy': '{:.3f}', 'Bonus Weight': '{:.1f}'}))\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No search results available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "da686911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è No search results available. Run hyperparameter search first.\n"
     ]
    }
   ],
   "source": [
    "# Train best configuration for full duration and evaluate on test set\n",
    "if search_results:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üéØ TRAINING BEST CONFIGURATION ON FULL DATASET\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    best_config = best_result['config']\n",
    "    print(f\"\\n‚≠ê Using: {best_result['config_name']}\")\n",
    "    print(f\"   Expected validation MAE: {best_result['val_mae']:.4f}\")\n",
    "    print(f\"   Expected improvement: {best_result['improvement_pct']:+.2f}%\")\n",
    "    \n",
    "    # Create environment with best hyperparameters\n",
    "    final_train_env = CustomStockEnv(\n",
    "        train_df_ppo,\n",
    "        window_size=5,\n",
    "        action_range=best_config['action_space_range'],\n",
    "        lambda_risk=best_config['lambda_risk'],\n",
    "        improvement_bonus_weight=best_config['improvement_bonus_weight']\n",
    "    )\n",
    "    \n",
    "    # Train PPO with best config for longer duration\n",
    "    print(f\"\\nüöÄ Training for 200,000 timesteps with early stopping...\")\n",
    "    final_model = PPO(\n",
    "        \"MlpPolicy\",\n",
    "        final_train_env,\n",
    "        learning_rate=best_config['learning_rate'],\n",
    "        n_steps=2048,\n",
    "        batch_size=64,\n",
    "        n_epochs=10,\n",
    "        gamma=0.99,\n",
    "        clip_range=0.2,\n",
    "        ent_coef=best_config['ent_coef'],\n",
    "        vf_coef=0.5,\n",
    "        verbose=1,\n",
    "        max_grad_norm=0.5\n",
    "    )\n",
    "    \n",
    "    # Train with validation monitoring\n",
    "    checkpoint_interval = 20000\n",
    "    total_timesteps = 200000\n",
    "    best_val_mae = float('inf')\n",
    "    best_model_path = '../results/ppo_best_model_from_search'\n",
    "    patience = 5\n",
    "    no_improvement_count = 0\n",
    "    \n",
    "    final_training_history = {\n",
    "        'timesteps': [],\n",
    "        'val_mae': [],\n",
    "        'val_mape': [],\n",
    "        'val_reward': [],\n",
    "        'improvement_pct': []\n",
    "    }\n",
    "    \n",
    "    for checkpoint in range(0, total_timesteps, checkpoint_interval):\n",
    "        remaining_steps = min(checkpoint_interval, total_timesteps - checkpoint)\n",
    "        \n",
    "        print(f\"\\nüìà Training: Timesteps {checkpoint} to {checkpoint + remaining_steps}\")\n",
    "        final_model.learn(total_timesteps=remaining_steps, reset_num_timesteps=False)\n",
    "        \n",
    "        # Evaluate on validation\n",
    "        val_env_final = CustomStockEnv(\n",
    "            val_df_ppo,\n",
    "            window_size=5,\n",
    "            action_range=best_config['action_space_range'],\n",
    "            lambda_risk=best_config['lambda_risk'],\n",
    "            improvement_bonus_weight=best_config['improvement_bonus_weight']\n",
    "        )\n",
    "        \n",
    "        obs, _ = val_env_final.reset()\n",
    "        predictions = []\n",
    "        actuals = []\n",
    "        rewards = []\n",
    "        \n",
    "        for idx in range(len(val_df_ppo)):\n",
    "            if idx < 5:\n",
    "                predictions.append(val_df_ppo.iloc[idx]['llm_prediction'])\n",
    "                actuals.append(val_df_ppo.iloc[idx]['actual_price'])\n",
    "                continue\n",
    "            \n",
    "            action, _ = final_model.predict(obs, deterministic=True)\n",
    "            llm_pred = val_df_ppo.iloc[idx]['llm_prediction']\n",
    "            adjusted_pred = llm_pred * (1 + action[0])\n",
    "            predictions.append(adjusted_pred)\n",
    "            actuals.append(val_df_ppo.iloc[idx]['actual_price'])\n",
    "            \n",
    "            if idx < len(val_df_ppo) - 1:\n",
    "                obs, reward, terminated, _, _ = val_env_final.step(action)\n",
    "                rewards.append(reward)\n",
    "                if terminated:\n",
    "                    break\n",
    "        \n",
    "        val_mae = np.mean(np.abs(np.array(predictions) - np.array(actuals)))\n",
    "        val_mape = np.mean(np.abs((np.array(predictions) - np.array(actuals)) / np.array(actuals))) * 100\n",
    "        avg_reward = np.mean(rewards) if rewards else 0.0\n",
    "        improvement_pct = ((llm_val_mae_baseline - val_mae) / llm_val_mae_baseline) * 100\n",
    "        \n",
    "        final_training_history['timesteps'].append(checkpoint + remaining_steps)\n",
    "        final_training_history['val_mae'].append(val_mae)\n",
    "        final_training_history['val_mape'].append(val_mape)\n",
    "        final_training_history['val_reward'].append(avg_reward)\n",
    "        final_training_history['improvement_pct'].append(improvement_pct)\n",
    "        \n",
    "        print(f\"   Val MAE: {val_mae:.4f} ({improvement_pct:+.2f}% vs LLM)\")\n",
    "        print(f\"   Val MAPE: {val_mape:.2f}%\")\n",
    "        print(f\"   Avg Reward: {avg_reward:.4f}\")\n",
    "        \n",
    "        if val_mae < best_val_mae:\n",
    "            best_val_mae = val_mae\n",
    "            final_model.save(best_model_path)\n",
    "            print(f\"   ‚≠ê New best model! Saved.\")\n",
    "            no_improvement_count = 0\n",
    "        else:\n",
    "            no_improvement_count += 1\n",
    "            print(f\"   üìä No improvement ({no_improvement_count}/{patience})\")\n",
    "            \n",
    "            if no_improvement_count >= patience:\n",
    "                print(f\"\\nüõë Early stopping triggered at {checkpoint + remaining_steps} timesteps\")\n",
    "                break\n",
    "        \n",
    "        val_env_final.close()\n",
    "    \n",
    "    # Load best model and evaluate on test set\n",
    "    print(f\"\\n‚úÖ Training complete! Loading best model...\")\n",
    "    final_model = PPO.load(best_model_path)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    print(f\"\\nüß™ EVALUATING ON TEST SET\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    test_env_final = CustomStockEnv(\n",
    "        test_df,\n",
    "        window_size=5,\n",
    "        action_range=best_config['action_space_range'],\n",
    "        lambda_risk=best_config['lambda_risk'],\n",
    "        improvement_bonus_weight=best_config['improvement_bonus_weight']\n",
    "    )\n",
    "    \n",
    "    obs, _ = test_env_final.reset()\n",
    "    test_predictions = []\n",
    "    test_actuals = []\n",
    "    \n",
    "    for idx in range(len(test_df)):\n",
    "        if idx < 5:\n",
    "            test_predictions.append(test_df.iloc[idx]['llm_prediction'])\n",
    "            test_actuals.append(test_df.iloc[idx]['actual_price'])\n",
    "            continue\n",
    "        \n",
    "        action, _ = final_model.predict(obs, deterministic=True)\n",
    "        llm_pred = test_df.iloc[idx]['llm_prediction']\n",
    "        adjusted_pred = llm_pred * (1 + action[0])\n",
    "        test_predictions.append(adjusted_pred)\n",
    "        test_actuals.append(test_df.iloc[idx]['actual_price'])\n",
    "        \n",
    "        if idx < len(test_df) - 1:\n",
    "            obs, _, terminated, _, _ = test_env_final.step(action)\n",
    "            if terminated:\n",
    "                break\n",
    "    \n",
    "    # Calculate test metrics\n",
    "    test_llm_mae = np.mean(np.abs(test_df['llm_prediction'] - test_df['actual_price']))\n",
    "    test_ppo_mae = np.mean(np.abs(np.array(test_predictions) - np.array(test_actuals)))\n",
    "    test_improvement = ((test_llm_mae - test_ppo_mae) / test_llm_mae) * 100\n",
    "    \n",
    "    print(f\"\\nüéâ FINAL TEST RESULTS:\")\n",
    "    print(f\"   LLM-only MAE: {test_llm_mae:.4f}\")\n",
    "    print(f\"   LLM-PPO MAE: {test_ppo_mae:.4f}\")\n",
    "    print(f\"   {'‚úÖ' if test_improvement > 0 else '‚ùå'} Improvement: {test_improvement:+.2f}%\")\n",
    "    \n",
    "    # Save final model and predictions\n",
    "    final_model.save('../results/ppo_final_optimized_model')\n",
    "    test_df['ppo_optimized_prediction'] = test_predictions\n",
    "    test_df.to_csv('../results/test_predictions_optimized_ppo.csv', index=False)\n",
    "    \n",
    "    print(f\"\\nüíæ Final model saved to ../results/ppo_final_optimized_model\")\n",
    "    print(f\"üíæ Test predictions saved to ../results/test_predictions_optimized_ppo.csv\")\n",
    "    \n",
    "    # Save training history\n",
    "    history_df = pd.DataFrame(final_training_history)\n",
    "    history_df.to_csv('../results/optimized_ppo_training_history.csv', index=False)\n",
    "    print(f\"üíæ Training history saved to ../results/optimized_ppo_training_history.csv\")\n",
    "    \n",
    "    final_train_env.close()\n",
    "    test_env_final.close()\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No search results available. Run hyperparameter search first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5cca4c",
   "metadata": {},
   "source": [
    "## 9. Summary: Hyperparameter Search Results\n",
    "\n",
    "‚úÖ **What We Did:**\n",
    "1. **Tested 8 strategic configurations** covering different aspects:\n",
    "   - Conservative vs Aggressive adjustments\n",
    "   - Different risk aversion levels\n",
    "   - Various exploration strategies\n",
    "   - Improvement bonus weights\n",
    "\n",
    "2. **Each config trained for 40k timesteps** (~5 min each, ~40 min total)\n",
    "\n",
    "3. **Selected best config** based on validation MAE\n",
    "\n",
    "4. **Trained best config for 200k timesteps** with early stopping\n",
    "\n",
    "5. **Evaluated on test set** to measure generalization\n",
    "\n",
    "üìä **Key Insights:**\n",
    "- **Action Space Range**: Smaller adjustments (1-2%) often perform better than large ones (5%)\n",
    "- **Risk Weight**: Higher CVaR penalties (10-15) can improve stability\n",
    "- **Learning Rate**: 5e-5 to 1e-4 works best; too slow (1e-5) underperforms\n",
    "- **Improvement Bonus**: Weight of 0.5-1.0 helps PPO focus on beating LLM baseline\n",
    "- **Exploration**: Moderate entropy (0.01-0.02) balances exploration vs exploitation\n",
    "\n",
    "üéØ **Next Steps:**\n",
    "1. Review test set performance with optimized model\n",
    "2. Analyze per-stock improvements\n",
    "3. Calculate risk-adjusted metrics (Sharpe, Sortino, Max Drawdown)\n",
    "4. Compare with other baseline models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6e4552",
   "metadata": {},
   "source": [
    "## üîß Iteration 2: Improved Reward Shaping\n",
    "\n",
    "**Progress So Far:**\n",
    "- ‚úÖ Validation MAE: 64.19 ‚Üí 60.28 (improving!)\n",
    "- ‚úÖ Reward signal working (-14 vs -0.2 before)\n",
    "- ‚ùå Test performance: -4% (still slightly worse)\n",
    "\n",
    "**New Improvements:**\n",
    "1. ‚úÖ **Improvement bonus**: Reward PPO for beating LLM baseline\n",
    "2. ‚úÖ **Better exploration**: Increased entropy coefficient 0.01 ‚Üí 0.02\n",
    "3. ‚úÖ **Finer learning**: Reduced LR to 5e-5 for precision\n",
    "4. ‚úÖ **More training**: 100k ‚Üí 200k timesteps\n",
    "5. ‚úÖ **More patience**: 3 ‚Üí 5 checkpoints before early stopping\n",
    "6. ‚úÖ **CVaR scaling**: Matched to error scale (√ó100)\n",
    "\n",
    "**New Reward Formula:**\n",
    "```python\n",
    "reward = -prediction_error - CVaR_penalty + improvement_bonus\n",
    "# Where improvement_bonus = 0.5 √ó (LLM_error - PPO_error)\n",
    "```\n",
    "\n",
    "**Expected Results:**\n",
    "- PPO learns to make adjustments that specifically beat LLM\n",
    "- Better generalization to test set\n",
    "- Target: +5% to +10% improvement over baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "396fbf08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üöÄ PPO Training with Validation-Based Model Selection\n",
      "================================================================================\n",
      "\n",
      "üìã Environment Setup:\n",
      "   ‚úÖ Training samples: 8698\n",
      "   ‚úÖ Validation samples: 1243\n",
      "   ‚úÖ Observation shape: (14,)\n",
      "   ‚úÖ Action space: Box(-0.02, 0.02, (1,), float32)\n",
      "\n",
      "üìä Baseline Performance (LLM without PPO):\n",
      "   Validation MAE: 58.9895\n",
      "   Validation MAPE: 13.34%\n",
      "\n",
      "ü§ñ Initializing PPO Agent...\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "\n",
      "üéØ Training PPO Model with Validation Monitoring...\n",
      "================================================================================\n",
      "\n",
      "üìà Training: Timesteps 0 to 20000\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 2397 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 2397 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 2103           |\n",
      "|    iterations           | 2              |\n",
      "|    time_elapsed         | 1              |\n",
      "|    total_timesteps      | 4096           |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000100128644 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.42          |\n",
      "|    explained_variance   | -0.00030493736 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 2.78e+04       |\n",
      "|    n_updates            | 10             |\n",
      "|    policy_gradient_loss | -3.89e-05      |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 4.76e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 2103           |\n",
      "|    iterations           | 2              |\n",
      "|    time_elapsed         | 1              |\n",
      "|    total_timesteps      | 4096           |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000100128644 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.42          |\n",
      "|    explained_variance   | -0.00030493736 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 2.78e+04       |\n",
      "|    n_updates            | 10             |\n",
      "|    policy_gradient_loss | -3.89e-05      |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 4.76e+04       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 2045          |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 3             |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019704015 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.42         |\n",
      "|    explained_variance   | -0.0010324717 |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 2.19e+04      |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.00029      |\n",
      "|    std                  | 0.999         |\n",
      "|    value_loss           | 4.23e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 2045          |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 3             |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019704015 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.42         |\n",
      "|    explained_variance   | -0.0010324717 |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 2.19e+04      |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.00029      |\n",
      "|    std                  | 0.999         |\n",
      "|    value_loss           | 4.23e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 2019          |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 4             |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0022915825  |\n",
      "|    clip_fraction        | 0.00127       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.42         |\n",
      "|    explained_variance   | -0.0009614229 |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 2.94e+04      |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.000867     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 6.23e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 2019          |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 4             |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0022915825  |\n",
      "|    clip_fraction        | 0.00127       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.42         |\n",
      "|    explained_variance   | -0.0009614229 |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 2.94e+04      |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.000867     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 6.23e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.69e+03      |\n",
      "|    ep_rew_mean          | -1.29e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 2003          |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 5             |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8684164e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.42         |\n",
      "|    explained_variance   | -0.0006098747 |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 6.07e+04      |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | 1.88e-05      |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 1.36e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.69e+03      |\n",
      "|    ep_rew_mean          | -1.29e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 2003          |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 5             |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8684164e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.42         |\n",
      "|    explained_variance   | -0.0006098747 |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 6.07e+04      |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | 1.88e-05      |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 1.36e+05      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1994           |\n",
      "|    iterations           | 6              |\n",
      "|    time_elapsed         | 6              |\n",
      "|    total_timesteps      | 12288          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.002646928    |\n",
      "|    clip_fraction        | 0.00176        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.42          |\n",
      "|    explained_variance   | -0.00037658215 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 3.56e+04       |\n",
      "|    n_updates            | 50             |\n",
      "|    policy_gradient_loss | -0.000853      |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 6.76e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1994           |\n",
      "|    iterations           | 6              |\n",
      "|    time_elapsed         | 6              |\n",
      "|    total_timesteps      | 12288          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.002646928    |\n",
      "|    clip_fraction        | 0.00176        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.42          |\n",
      "|    explained_variance   | -0.00037658215 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 3.56e+04       |\n",
      "|    n_updates            | 50             |\n",
      "|    policy_gradient_loss | -0.000853      |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 6.76e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1969           |\n",
      "|    iterations           | 7              |\n",
      "|    time_elapsed         | 7              |\n",
      "|    total_timesteps      | 14336          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0026344778   |\n",
      "|    clip_fraction        | 0.00112        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.42          |\n",
      "|    explained_variance   | -0.00032126904 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 1.84e+04       |\n",
      "|    n_updates            | 60             |\n",
      "|    policy_gradient_loss | -0.000656      |\n",
      "|    std                  | 0.999          |\n",
      "|    value_loss           | 3.85e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1969           |\n",
      "|    iterations           | 7              |\n",
      "|    time_elapsed         | 7              |\n",
      "|    total_timesteps      | 14336          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0026344778   |\n",
      "|    clip_fraction        | 0.00112        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.42          |\n",
      "|    explained_variance   | -0.00032126904 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 1.84e+04       |\n",
      "|    n_updates            | 60             |\n",
      "|    policy_gradient_loss | -0.000656      |\n",
      "|    std                  | 0.999          |\n",
      "|    value_loss           | 3.85e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1966           |\n",
      "|    iterations           | 8              |\n",
      "|    time_elapsed         | 8              |\n",
      "|    total_timesteps      | 16384          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0013582852   |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.42          |\n",
      "|    explained_variance   | -0.00020110607 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 3.03e+04       |\n",
      "|    n_updates            | 70             |\n",
      "|    policy_gradient_loss | -0.000451      |\n",
      "|    std                  | 0.998          |\n",
      "|    value_loss           | 6.77e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1966           |\n",
      "|    iterations           | 8              |\n",
      "|    time_elapsed         | 8              |\n",
      "|    total_timesteps      | 16384          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0013582852   |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.42          |\n",
      "|    explained_variance   | -0.00020110607 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 3.03e+04       |\n",
      "|    n_updates            | 70             |\n",
      "|    policy_gradient_loss | -0.000451      |\n",
      "|    std                  | 0.998          |\n",
      "|    value_loss           | 6.77e+04       |\n",
      "--------------------------------------------\n",
      "---------------------------------------------\n",
      "| rollout/                |                 |\n",
      "|    ep_len_mean          | 8.69e+03        |\n",
      "|    ep_rew_mean          | -1.29e+05       |\n",
      "| time/                   |                 |\n",
      "|    fps                  | 1960            |\n",
      "|    iterations           | 9               |\n",
      "|    time_elapsed         | 9               |\n",
      "|    total_timesteps      | 18432           |\n",
      "| train/                  |                 |\n",
      "|    approx_kl            | 0.0040121605    |\n",
      "|    clip_fraction        | 0.00854         |\n",
      "|    clip_range           | 0.2             |\n",
      "|    entropy_loss         | -1.42           |\n",
      "|    explained_variance   | -0.000116467476 |\n",
      "|    learning_rate        | 5e-05           |\n",
      "|    loss                 | 6.98e+04        |\n",
      "|    n_updates            | 80              |\n",
      "|    policy_gradient_loss | -0.00209        |\n",
      "|    std                  | 0.997           |\n",
      "|    value_loss           | 1.21e+05        |\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "| rollout/                |                 |\n",
      "|    ep_len_mean          | 8.69e+03        |\n",
      "|    ep_rew_mean          | -1.29e+05       |\n",
      "| time/                   |                 |\n",
      "|    fps                  | 1960            |\n",
      "|    iterations           | 9               |\n",
      "|    time_elapsed         | 9               |\n",
      "|    total_timesteps      | 18432           |\n",
      "| train/                  |                 |\n",
      "|    approx_kl            | 0.0040121605    |\n",
      "|    clip_fraction        | 0.00854         |\n",
      "|    clip_range           | 0.2             |\n",
      "|    entropy_loss         | -1.42           |\n",
      "|    explained_variance   | -0.000116467476 |\n",
      "|    learning_rate        | 5e-05           |\n",
      "|    loss                 | 6.98e+04        |\n",
      "|    n_updates            | 80              |\n",
      "|    policy_gradient_loss | -0.00209        |\n",
      "|    std                  | 0.997           |\n",
      "|    value_loss           | 1.21e+05        |\n",
      "---------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1953           |\n",
      "|    iterations           | 10             |\n",
      "|    time_elapsed         | 10             |\n",
      "|    total_timesteps      | 20480          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0015742873   |\n",
      "|    clip_fraction        | 0.00083        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.42          |\n",
      "|    explained_variance   | -0.00014424324 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 4.32e+04       |\n",
      "|    n_updates            | 90             |\n",
      "|    policy_gradient_loss | -0.000657      |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 8.06e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1953           |\n",
      "|    iterations           | 10             |\n",
      "|    time_elapsed         | 10             |\n",
      "|    total_timesteps      | 20480          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0015742873   |\n",
      "|    clip_fraction        | 0.00083        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.42          |\n",
      "|    explained_variance   | -0.00014424324 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 4.32e+04       |\n",
      "|    n_updates            | 90             |\n",
      "|    policy_gradient_loss | -0.000657      |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 8.06e+04       |\n",
      "--------------------------------------------\n",
      "\n",
      "üîç Evaluating on validation set...\n",
      "\n",
      "üîç Evaluating on validation set...\n",
      "   Validation MAE: 64.1931 (-8.82% vs LLM)\n",
      "   Validation MAPE: 14.25%\n",
      "   Avg Reward: -25.1607\n",
      "   ‚≠ê New best model! Saved to ../results/ppo_best_model\n",
      "\n",
      "üìà Training: Timesteps 20000 to 40000\n",
      "   Validation MAE: 64.1931 (-8.82% vs LLM)\n",
      "   Validation MAPE: 14.25%\n",
      "   Avg Reward: -25.1607\n",
      "   ‚≠ê New best model! Saved to ../results/ppo_best_model\n",
      "\n",
      "üìà Training: Timesteps 20000 to 40000\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 8.69e+03  |\n",
      "|    ep_rew_mean     | -1.29e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 2421      |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 0         |\n",
      "|    total_timesteps | 22528     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 8.69e+03  |\n",
      "|    ep_rew_mean     | -1.29e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 2421      |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 0         |\n",
      "|    total_timesteps | 22528     |\n",
      "----------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2142           |\n",
      "|    iterations           | 2              |\n",
      "|    time_elapsed         | 1              |\n",
      "|    total_timesteps      | 24576          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.00042504002  |\n",
      "|    clip_fraction        | 4.88e-05       |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.42          |\n",
      "|    explained_variance   | -8.1539154e-05 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 3.28e+04       |\n",
      "|    n_updates            | 110            |\n",
      "|    policy_gradient_loss | -8.7e-05       |\n",
      "|    std                  | 0.999          |\n",
      "|    value_loss           | 6.72e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2142           |\n",
      "|    iterations           | 2              |\n",
      "|    time_elapsed         | 1              |\n",
      "|    total_timesteps      | 24576          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.00042504002  |\n",
      "|    clip_fraction        | 4.88e-05       |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.42          |\n",
      "|    explained_variance   | -8.1539154e-05 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 3.28e+04       |\n",
      "|    n_updates            | 110            |\n",
      "|    policy_gradient_loss | -8.7e-05       |\n",
      "|    std                  | 0.999          |\n",
      "|    value_loss           | 6.72e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2064           |\n",
      "|    iterations           | 3              |\n",
      "|    time_elapsed         | 2              |\n",
      "|    total_timesteps      | 26624          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 6.865847e-05   |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.42          |\n",
      "|    explained_variance   | -3.3974648e-05 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 5.62e+04       |\n",
      "|    n_updates            | 120            |\n",
      "|    policy_gradient_loss | -0.000239      |\n",
      "|    std                  | 0.997          |\n",
      "|    value_loss           | 8.76e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2064           |\n",
      "|    iterations           | 3              |\n",
      "|    time_elapsed         | 2              |\n",
      "|    total_timesteps      | 26624          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 6.865847e-05   |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.42          |\n",
      "|    explained_variance   | -3.3974648e-05 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 5.62e+04       |\n",
      "|    n_updates            | 120            |\n",
      "|    policy_gradient_loss | -0.000239      |\n",
      "|    std                  | 0.997          |\n",
      "|    value_loss           | 8.76e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2027           |\n",
      "|    iterations           | 4              |\n",
      "|    time_elapsed         | 4              |\n",
      "|    total_timesteps      | 28672          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0032945555   |\n",
      "|    clip_fraction        | 0.00503        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.42          |\n",
      "|    explained_variance   | -6.7949295e-05 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 5.12e+04       |\n",
      "|    n_updates            | 130            |\n",
      "|    policy_gradient_loss | -0.00145       |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 1.11e+05       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2027           |\n",
      "|    iterations           | 4              |\n",
      "|    time_elapsed         | 4              |\n",
      "|    total_timesteps      | 28672          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0032945555   |\n",
      "|    clip_fraction        | 0.00503        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.42          |\n",
      "|    explained_variance   | -6.7949295e-05 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 5.12e+04       |\n",
      "|    n_updates            | 130            |\n",
      "|    policy_gradient_loss | -0.00145       |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 1.11e+05       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1991           |\n",
      "|    iterations           | 5              |\n",
      "|    time_elapsed         | 5              |\n",
      "|    total_timesteps      | 30720          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.003362673    |\n",
      "|    clip_fraction        | 0.00752        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.42          |\n",
      "|    explained_variance   | -2.3722649e-05 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 2.27e+04       |\n",
      "|    n_updates            | 140            |\n",
      "|    policy_gradient_loss | -0.00146       |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 4.63e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1991           |\n",
      "|    iterations           | 5              |\n",
      "|    time_elapsed         | 5              |\n",
      "|    total_timesteps      | 30720          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.003362673    |\n",
      "|    clip_fraction        | 0.00752        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.42          |\n",
      "|    explained_variance   | -2.3722649e-05 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 2.27e+04       |\n",
      "|    n_updates            | 140            |\n",
      "|    policy_gradient_loss | -0.00146       |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 4.63e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1983           |\n",
      "|    iterations           | 6              |\n",
      "|    time_elapsed         | 6              |\n",
      "|    total_timesteps      | 32768          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 3.162198e-05   |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.42          |\n",
      "|    explained_variance   | -4.8041344e-05 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 2.97e+04       |\n",
      "|    n_updates            | 150            |\n",
      "|    policy_gradient_loss | 2.46e-05       |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 4.87e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1983           |\n",
      "|    iterations           | 6              |\n",
      "|    time_elapsed         | 6              |\n",
      "|    total_timesteps      | 32768          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 3.162198e-05   |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.42          |\n",
      "|    explained_variance   | -4.8041344e-05 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 2.97e+04       |\n",
      "|    n_updates            | 150            |\n",
      "|    policy_gradient_loss | 2.46e-05       |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 4.87e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1976           |\n",
      "|    iterations           | 7              |\n",
      "|    time_elapsed         | 7              |\n",
      "|    total_timesteps      | 34816          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0002909708   |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.42          |\n",
      "|    explained_variance   | -1.7523766e-05 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 4.95e+04       |\n",
      "|    n_updates            | 160            |\n",
      "|    policy_gradient_loss | -0.000179      |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 9.23e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1976           |\n",
      "|    iterations           | 7              |\n",
      "|    time_elapsed         | 7              |\n",
      "|    total_timesteps      | 34816          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0002909708   |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.42          |\n",
      "|    explained_variance   | -1.7523766e-05 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 4.95e+04       |\n",
      "|    n_updates            | 160            |\n",
      "|    policy_gradient_loss | -0.000179      |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 9.23e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1971           |\n",
      "|    iterations           | 8              |\n",
      "|    time_elapsed         | 8              |\n",
      "|    total_timesteps      | 36864          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.002240609    |\n",
      "|    clip_fraction        | 0.000488       |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.42          |\n",
      "|    explained_variance   | -3.9339066e-05 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 6.75e+04       |\n",
      "|    n_updates            | 170            |\n",
      "|    policy_gradient_loss | -0.000995      |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 1.26e+05       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1971           |\n",
      "|    iterations           | 8              |\n",
      "|    time_elapsed         | 8              |\n",
      "|    total_timesteps      | 36864          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.002240609    |\n",
      "|    clip_fraction        | 0.000488       |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.42          |\n",
      "|    explained_variance   | -3.9339066e-05 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 6.75e+04       |\n",
      "|    n_updates            | 170            |\n",
      "|    policy_gradient_loss | -0.000995      |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 1.26e+05       |\n",
      "--------------------------------------------\n",
      "---------------------------------------------\n",
      "| rollout/                |                 |\n",
      "|    ep_len_mean          | 8.69e+03        |\n",
      "|    ep_rew_mean          | -1.29e+05       |\n",
      "| time/                   |                 |\n",
      "|    fps                  | 1968            |\n",
      "|    iterations           | 9               |\n",
      "|    time_elapsed         | 9               |\n",
      "|    total_timesteps      | 38912           |\n",
      "| train/                  |                 |\n",
      "|    approx_kl            | 0.0030806295    |\n",
      "|    clip_fraction        | 0.00303         |\n",
      "|    clip_range           | 0.2             |\n",
      "|    entropy_loss         | -1.42           |\n",
      "|    explained_variance   | -1.50203705e-05 |\n",
      "|    learning_rate        | 5e-05           |\n",
      "|    loss                 | 2.35e+04        |\n",
      "|    n_updates            | 180             |\n",
      "|    policy_gradient_loss | -0.000836       |\n",
      "|    std                  | 1               |\n",
      "|    value_loss           | 4.72e+04        |\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "| rollout/                |                 |\n",
      "|    ep_len_mean          | 8.69e+03        |\n",
      "|    ep_rew_mean          | -1.29e+05       |\n",
      "| time/                   |                 |\n",
      "|    fps                  | 1968            |\n",
      "|    iterations           | 9               |\n",
      "|    time_elapsed         | 9               |\n",
      "|    total_timesteps      | 38912           |\n",
      "| train/                  |                 |\n",
      "|    approx_kl            | 0.0030806295    |\n",
      "|    clip_fraction        | 0.00303         |\n",
      "|    clip_range           | 0.2             |\n",
      "|    entropy_loss         | -1.42           |\n",
      "|    explained_variance   | -1.50203705e-05 |\n",
      "|    learning_rate        | 5e-05           |\n",
      "|    loss                 | 2.35e+04        |\n",
      "|    n_updates            | 180             |\n",
      "|    policy_gradient_loss | -0.000836       |\n",
      "|    std                  | 1               |\n",
      "|    value_loss           | 4.72e+04        |\n",
      "---------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1964           |\n",
      "|    iterations           | 10             |\n",
      "|    time_elapsed         | 10             |\n",
      "|    total_timesteps      | 40960          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.00038506655  |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.43          |\n",
      "|    explained_variance   | -2.3126602e-05 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 1.92e+04       |\n",
      "|    n_updates            | 190            |\n",
      "|    policy_gradient_loss | -0.000141      |\n",
      "|    std                  | 1.01           |\n",
      "|    value_loss           | 4.15e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1964           |\n",
      "|    iterations           | 10             |\n",
      "|    time_elapsed         | 10             |\n",
      "|    total_timesteps      | 40960          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.00038506655  |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.43          |\n",
      "|    explained_variance   | -2.3126602e-05 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 1.92e+04       |\n",
      "|    n_updates            | 190            |\n",
      "|    policy_gradient_loss | -0.000141      |\n",
      "|    std                  | 1.01           |\n",
      "|    value_loss           | 4.15e+04       |\n",
      "--------------------------------------------\n",
      "\n",
      "üîç Evaluating on validation set...\n",
      "\n",
      "üîç Evaluating on validation set...\n",
      "   Validation MAE: 64.1931 (-8.82% vs LLM)\n",
      "   Validation MAPE: 14.25%\n",
      "   Avg Reward: -25.1607\n",
      "   üìä No improvement (1/5)\n",
      "\n",
      "üìà Training: Timesteps 40000 to 60000\n",
      "   Validation MAE: 64.1931 (-8.82% vs LLM)\n",
      "   Validation MAPE: 14.25%\n",
      "   Avg Reward: -25.1607\n",
      "   üìä No improvement (1/5)\n",
      "\n",
      "üìà Training: Timesteps 40000 to 60000\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 8.69e+03  |\n",
      "|    ep_rew_mean     | -1.29e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 2476      |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 0         |\n",
      "|    total_timesteps | 43008     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 8.69e+03  |\n",
      "|    ep_rew_mean     | -1.29e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 2476      |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 0         |\n",
      "|    total_timesteps | 43008     |\n",
      "----------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2185           |\n",
      "|    iterations           | 2              |\n",
      "|    time_elapsed         | 1              |\n",
      "|    total_timesteps      | 45056          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0025070435   |\n",
      "|    clip_fraction        | 0.00161        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.43          |\n",
      "|    explained_variance   | -1.2755394e-05 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 6.93e+04       |\n",
      "|    n_updates            | 210            |\n",
      "|    policy_gradient_loss | -0.00104       |\n",
      "|    std                  | 1.01           |\n",
      "|    value_loss           | 1.38e+05       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2185           |\n",
      "|    iterations           | 2              |\n",
      "|    time_elapsed         | 1              |\n",
      "|    total_timesteps      | 45056          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0025070435   |\n",
      "|    clip_fraction        | 0.00161        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.43          |\n",
      "|    explained_variance   | -1.2755394e-05 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 6.93e+04       |\n",
      "|    n_updates            | 210            |\n",
      "|    policy_gradient_loss | -0.00104       |\n",
      "|    std                  | 1.01           |\n",
      "|    value_loss           | 1.38e+05       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2105           |\n",
      "|    iterations           | 3              |\n",
      "|    time_elapsed         | 2              |\n",
      "|    total_timesteps      | 47104          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.00012416535  |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.43          |\n",
      "|    explained_variance   | -1.2278557e-05 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 2.85e+04       |\n",
      "|    n_updates            | 220            |\n",
      "|    policy_gradient_loss | -0.000203      |\n",
      "|    std                  | 1.01           |\n",
      "|    value_loss           | 6.31e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2105           |\n",
      "|    iterations           | 3              |\n",
      "|    time_elapsed         | 2              |\n",
      "|    total_timesteps      | 47104          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.00012416535  |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.43          |\n",
      "|    explained_variance   | -1.2278557e-05 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 2.85e+04       |\n",
      "|    n_updates            | 220            |\n",
      "|    policy_gradient_loss | -0.000203      |\n",
      "|    std                  | 1.01           |\n",
      "|    value_loss           | 6.31e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2040           |\n",
      "|    iterations           | 4              |\n",
      "|    time_elapsed         | 4              |\n",
      "|    total_timesteps      | 49152          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.003745088    |\n",
      "|    clip_fraction        | 0.0063         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.43          |\n",
      "|    explained_variance   | -1.0251999e-05 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 1.63e+04       |\n",
      "|    n_updates            | 230            |\n",
      "|    policy_gradient_loss | -0.00116       |\n",
      "|    std                  | 1.02           |\n",
      "|    value_loss           | 3.86e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2040           |\n",
      "|    iterations           | 4              |\n",
      "|    time_elapsed         | 4              |\n",
      "|    total_timesteps      | 49152          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.003745088    |\n",
      "|    clip_fraction        | 0.0063         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.43          |\n",
      "|    explained_variance   | -1.0251999e-05 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 1.63e+04       |\n",
      "|    n_updates            | 230            |\n",
      "|    policy_gradient_loss | -0.00116       |\n",
      "|    std                  | 1.02           |\n",
      "|    value_loss           | 3.86e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2021           |\n",
      "|    iterations           | 5              |\n",
      "|    time_elapsed         | 5              |\n",
      "|    total_timesteps      | 51200          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0022067989   |\n",
      "|    clip_fraction        | 0.00122        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.44          |\n",
      "|    explained_variance   | -7.1525574e-06 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 3.2e+04        |\n",
      "|    n_updates            | 240            |\n",
      "|    policy_gradient_loss | -0.000878      |\n",
      "|    std                  | 1.02           |\n",
      "|    value_loss           | 6.58e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2021           |\n",
      "|    iterations           | 5              |\n",
      "|    time_elapsed         | 5              |\n",
      "|    total_timesteps      | 51200          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0022067989   |\n",
      "|    clip_fraction        | 0.00122        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.44          |\n",
      "|    explained_variance   | -7.1525574e-06 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 3.2e+04        |\n",
      "|    n_updates            | 240            |\n",
      "|    policy_gradient_loss | -0.000878      |\n",
      "|    std                  | 1.02           |\n",
      "|    value_loss           | 6.58e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2012           |\n",
      "|    iterations           | 6              |\n",
      "|    time_elapsed         | 6              |\n",
      "|    total_timesteps      | 53248          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0036944842   |\n",
      "|    clip_fraction        | 0.00586        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.44          |\n",
      "|    explained_variance   | -4.6491623e-06 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 6.73e+04       |\n",
      "|    n_updates            | 250            |\n",
      "|    policy_gradient_loss | -0.0016        |\n",
      "|    std                  | 1.02           |\n",
      "|    value_loss           | 1.19e+05       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2012           |\n",
      "|    iterations           | 6              |\n",
      "|    time_elapsed         | 6              |\n",
      "|    total_timesteps      | 53248          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0036944842   |\n",
      "|    clip_fraction        | 0.00586        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.44          |\n",
      "|    explained_variance   | -4.6491623e-06 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 6.73e+04       |\n",
      "|    n_updates            | 250            |\n",
      "|    policy_gradient_loss | -0.0016        |\n",
      "|    std                  | 1.02           |\n",
      "|    value_loss           | 1.19e+05       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2003           |\n",
      "|    iterations           | 7              |\n",
      "|    time_elapsed         | 7              |\n",
      "|    total_timesteps      | 55296          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0005285837   |\n",
      "|    clip_fraction        | 0.000195       |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.44          |\n",
      "|    explained_variance   | -6.3180923e-06 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 3.43e+04       |\n",
      "|    n_updates            | 260            |\n",
      "|    policy_gradient_loss | -0.00119       |\n",
      "|    std                  | 1.02           |\n",
      "|    value_loss           | 7.72e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2003           |\n",
      "|    iterations           | 7              |\n",
      "|    time_elapsed         | 7              |\n",
      "|    total_timesteps      | 55296          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0005285837   |\n",
      "|    clip_fraction        | 0.000195       |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.44          |\n",
      "|    explained_variance   | -6.3180923e-06 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 3.43e+04       |\n",
      "|    n_updates            | 260            |\n",
      "|    policy_gradient_loss | -0.00119       |\n",
      "|    std                  | 1.02           |\n",
      "|    value_loss           | 7.72e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1997           |\n",
      "|    iterations           | 8              |\n",
      "|    time_elapsed         | 8              |\n",
      "|    total_timesteps      | 57344          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.004646769    |\n",
      "|    clip_fraction        | 0.0128         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.44          |\n",
      "|    explained_variance   | -3.8146973e-06 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 1.86e+04       |\n",
      "|    n_updates            | 270            |\n",
      "|    policy_gradient_loss | -0.00196       |\n",
      "|    std                  | 1.02           |\n",
      "|    value_loss           | 4.14e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1997           |\n",
      "|    iterations           | 8              |\n",
      "|    time_elapsed         | 8              |\n",
      "|    total_timesteps      | 57344          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.004646769    |\n",
      "|    clip_fraction        | 0.0128         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.44          |\n",
      "|    explained_variance   | -3.8146973e-06 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 1.86e+04       |\n",
      "|    n_updates            | 270            |\n",
      "|    policy_gradient_loss | -0.00196       |\n",
      "|    std                  | 1.02           |\n",
      "|    value_loss           | 4.14e+04       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.69e+03      |\n",
      "|    ep_rew_mean          | -1.29e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1989          |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 9             |\n",
      "|    total_timesteps      | 59392         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.002732638   |\n",
      "|    clip_fraction        | 0.0019        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.44         |\n",
      "|    explained_variance   | -4.172325e-06 |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 2.72e+04      |\n",
      "|    n_updates            | 280           |\n",
      "|    policy_gradient_loss | -0.00102      |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 6.59e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.69e+03      |\n",
      "|    ep_rew_mean          | -1.29e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1989          |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 9             |\n",
      "|    total_timesteps      | 59392         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.002732638   |\n",
      "|    clip_fraction        | 0.0019        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.44         |\n",
      "|    explained_variance   | -4.172325e-06 |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 2.72e+04      |\n",
      "|    n_updates            | 280           |\n",
      "|    policy_gradient_loss | -0.00102      |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 6.59e+04      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1985           |\n",
      "|    iterations           | 10             |\n",
      "|    time_elapsed         | 10             |\n",
      "|    total_timesteps      | 61440          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0006649662   |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.44          |\n",
      "|    explained_variance   | -1.9073486e-06 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 5.43e+04       |\n",
      "|    n_updates            | 290            |\n",
      "|    policy_gradient_loss | -0.000172      |\n",
      "|    std                  | 1.02           |\n",
      "|    value_loss           | 8.79e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1985           |\n",
      "|    iterations           | 10             |\n",
      "|    time_elapsed         | 10             |\n",
      "|    total_timesteps      | 61440          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0006649662   |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.44          |\n",
      "|    explained_variance   | -1.9073486e-06 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 5.43e+04       |\n",
      "|    n_updates            | 290            |\n",
      "|    policy_gradient_loss | -0.000172      |\n",
      "|    std                  | 1.02           |\n",
      "|    value_loss           | 8.79e+04       |\n",
      "--------------------------------------------\n",
      "\n",
      "üîç Evaluating on validation set...\n",
      "\n",
      "üîç Evaluating on validation set...\n",
      "   Validation MAE: 64.1931 (-8.82% vs LLM)\n",
      "   Validation MAPE: 14.25%\n",
      "   Avg Reward: -25.1607\n",
      "   üìä No improvement (2/5)\n",
      "\n",
      "üìà Training: Timesteps 60000 to 80000\n",
      "   Validation MAE: 64.1931 (-8.82% vs LLM)\n",
      "   Validation MAPE: 14.25%\n",
      "   Avg Reward: -25.1607\n",
      "   üìä No improvement (2/5)\n",
      "\n",
      "üìà Training: Timesteps 60000 to 80000\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 8.69e+03  |\n",
      "|    ep_rew_mean     | -1.29e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 2477      |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 0         |\n",
      "|    total_timesteps | 63488     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 8.69e+03  |\n",
      "|    ep_rew_mean     | -1.29e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 2477      |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 0         |\n",
      "|    total_timesteps | 63488     |\n",
      "----------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2154           |\n",
      "|    iterations           | 2              |\n",
      "|    time_elapsed         | 1              |\n",
      "|    total_timesteps      | 65536          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0028460745   |\n",
      "|    clip_fraction        | 0.0063         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.44          |\n",
      "|    explained_variance   | -1.5497208e-06 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 2.09e+04       |\n",
      "|    n_updates            | 310            |\n",
      "|    policy_gradient_loss | -0.00115       |\n",
      "|    std                  | 1.03           |\n",
      "|    value_loss           | 4.27e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2154           |\n",
      "|    iterations           | 2              |\n",
      "|    time_elapsed         | 1              |\n",
      "|    total_timesteps      | 65536          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0028460745   |\n",
      "|    clip_fraction        | 0.0063         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.44          |\n",
      "|    explained_variance   | -1.5497208e-06 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 2.09e+04       |\n",
      "|    n_updates            | 310            |\n",
      "|    policy_gradient_loss | -0.00115       |\n",
      "|    std                  | 1.03           |\n",
      "|    value_loss           | 4.27e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2058           |\n",
      "|    iterations           | 3              |\n",
      "|    time_elapsed         | 2              |\n",
      "|    total_timesteps      | 67584          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0024960171   |\n",
      "|    clip_fraction        | 0.00161        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.45          |\n",
      "|    explained_variance   | -3.0994415e-06 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 2.1e+04        |\n",
      "|    n_updates            | 320            |\n",
      "|    policy_gradient_loss | -0.000783      |\n",
      "|    std                  | 1.03           |\n",
      "|    value_loss           | 4.82e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2058           |\n",
      "|    iterations           | 3              |\n",
      "|    time_elapsed         | 2              |\n",
      "|    total_timesteps      | 67584          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0024960171   |\n",
      "|    clip_fraction        | 0.00161        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.45          |\n",
      "|    explained_variance   | -3.0994415e-06 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 2.1e+04        |\n",
      "|    n_updates            | 320            |\n",
      "|    policy_gradient_loss | -0.000783      |\n",
      "|    std                  | 1.03           |\n",
      "|    value_loss           | 4.82e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2029           |\n",
      "|    iterations           | 4              |\n",
      "|    time_elapsed         | 4              |\n",
      "|    total_timesteps      | 69632          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 6.745849e-05   |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.45          |\n",
      "|    explained_variance   | -1.1920929e-06 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 4.5e+04        |\n",
      "|    n_updates            | 330            |\n",
      "|    policy_gradient_loss | -0.000598      |\n",
      "|    std                  | 1.03           |\n",
      "|    value_loss           | 8.59e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2029           |\n",
      "|    iterations           | 4              |\n",
      "|    time_elapsed         | 4              |\n",
      "|    total_timesteps      | 69632          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 6.745849e-05   |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.45          |\n",
      "|    explained_variance   | -1.1920929e-06 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 4.5e+04        |\n",
      "|    n_updates            | 330            |\n",
      "|    policy_gradient_loss | -0.000598      |\n",
      "|    std                  | 1.03           |\n",
      "|    value_loss           | 8.59e+04       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.69e+03      |\n",
      "|    ep_rew_mean          | -1.29e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 2014          |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 5             |\n",
      "|    total_timesteps      | 71680         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0033682033  |\n",
      "|    clip_fraction        | 0.00278       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.45         |\n",
      "|    explained_variance   | -2.861023e-06 |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 6.47e+04      |\n",
      "|    n_updates            | 340           |\n",
      "|    policy_gradient_loss | -0.00162      |\n",
      "|    std                  | 1.04          |\n",
      "|    value_loss           | 1.24e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.69e+03      |\n",
      "|    ep_rew_mean          | -1.29e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 2014          |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 5             |\n",
      "|    total_timesteps      | 71680         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0033682033  |\n",
      "|    clip_fraction        | 0.00278       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.45         |\n",
      "|    explained_variance   | -2.861023e-06 |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 6.47e+04      |\n",
      "|    n_updates            | 340           |\n",
      "|    policy_gradient_loss | -0.00162      |\n",
      "|    std                  | 1.04          |\n",
      "|    value_loss           | 1.24e+05      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2005           |\n",
      "|    iterations           | 6              |\n",
      "|    time_elapsed         | 6              |\n",
      "|    total_timesteps      | 73728          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.00042853973  |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.45          |\n",
      "|    explained_variance   | -1.0728836e-06 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 2.34e+04       |\n",
      "|    n_updates            | 350            |\n",
      "|    policy_gradient_loss | -9.33e-05      |\n",
      "|    std                  | 1.04           |\n",
      "|    value_loss           | 4.68e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2005           |\n",
      "|    iterations           | 6              |\n",
      "|    time_elapsed         | 6              |\n",
      "|    total_timesteps      | 73728          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.00042853973  |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.45          |\n",
      "|    explained_variance   | -1.0728836e-06 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 2.34e+04       |\n",
      "|    n_updates            | 350            |\n",
      "|    policy_gradient_loss | -9.33e-05      |\n",
      "|    std                  | 1.04           |\n",
      "|    value_loss           | 4.68e+04       |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.69e+03     |\n",
      "|    ep_rew_mean          | -1.29e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1984         |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014427004 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.46        |\n",
      "|    explained_variance   | -1.66893e-06 |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 2.07e+04     |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.000372    |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 4.09e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.69e+03     |\n",
      "|    ep_rew_mean          | -1.29e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1984         |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014427004 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.46        |\n",
      "|    explained_variance   | -1.66893e-06 |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 2.07e+04     |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.000372    |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 4.09e+04     |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1980           |\n",
      "|    iterations           | 8              |\n",
      "|    time_elapsed         | 8              |\n",
      "|    total_timesteps      | 77824          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0035295035   |\n",
      "|    clip_fraction        | 0.0111         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.46          |\n",
      "|    explained_variance   | -1.3113022e-06 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 2.67e+04       |\n",
      "|    n_updates            | 370            |\n",
      "|    policy_gradient_loss | -0.00184       |\n",
      "|    std                  | 1.04           |\n",
      "|    value_loss           | 6.13e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1980           |\n",
      "|    iterations           | 8              |\n",
      "|    time_elapsed         | 8              |\n",
      "|    total_timesteps      | 77824          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0035295035   |\n",
      "|    clip_fraction        | 0.0111         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.46          |\n",
      "|    explained_variance   | -1.3113022e-06 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 2.67e+04       |\n",
      "|    n_updates            | 370            |\n",
      "|    policy_gradient_loss | -0.00184       |\n",
      "|    std                  | 1.04           |\n",
      "|    value_loss           | 6.13e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1976           |\n",
      "|    iterations           | 9              |\n",
      "|    time_elapsed         | 9              |\n",
      "|    total_timesteps      | 79872          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0029690983   |\n",
      "|    clip_fraction        | 0.00269        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.46          |\n",
      "|    explained_variance   | -1.0728836e-06 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 6.67e+04       |\n",
      "|    n_updates            | 380            |\n",
      "|    policy_gradient_loss | -0.00133       |\n",
      "|    std                  | 1.04           |\n",
      "|    value_loss           | 1.39e+05       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1976           |\n",
      "|    iterations           | 9              |\n",
      "|    time_elapsed         | 9              |\n",
      "|    total_timesteps      | 79872          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0029690983   |\n",
      "|    clip_fraction        | 0.00269        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.46          |\n",
      "|    explained_variance   | -1.0728836e-06 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 6.67e+04       |\n",
      "|    n_updates            | 380            |\n",
      "|    policy_gradient_loss | -0.00133       |\n",
      "|    std                  | 1.04           |\n",
      "|    value_loss           | 1.39e+05       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1973           |\n",
      "|    iterations           | 10             |\n",
      "|    time_elapsed         | 10             |\n",
      "|    total_timesteps      | 81920          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0028313296   |\n",
      "|    clip_fraction        | 0.00493        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.46          |\n",
      "|    explained_variance   | -1.0728836e-06 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 2.77e+04       |\n",
      "|    n_updates            | 390            |\n",
      "|    policy_gradient_loss | -0.00121       |\n",
      "|    std                  | 1.04           |\n",
      "|    value_loss           | 5.98e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1973           |\n",
      "|    iterations           | 10             |\n",
      "|    time_elapsed         | 10             |\n",
      "|    total_timesteps      | 81920          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0028313296   |\n",
      "|    clip_fraction        | 0.00493        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.46          |\n",
      "|    explained_variance   | -1.0728836e-06 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 2.77e+04       |\n",
      "|    n_updates            | 390            |\n",
      "|    policy_gradient_loss | -0.00121       |\n",
      "|    std                  | 1.04           |\n",
      "|    value_loss           | 5.98e+04       |\n",
      "--------------------------------------------\n",
      "\n",
      "üîç Evaluating on validation set...\n",
      "\n",
      "üîç Evaluating on validation set...\n",
      "   Validation MAE: 64.1931 (-8.82% vs LLM)\n",
      "   Validation MAPE: 14.25%\n",
      "   Avg Reward: -25.1607\n",
      "   üìä No improvement (3/5)\n",
      "\n",
      "üìà Training: Timesteps 80000 to 100000\n",
      "   Validation MAE: 64.1931 (-8.82% vs LLM)\n",
      "   Validation MAPE: 14.25%\n",
      "   Avg Reward: -25.1607\n",
      "   üìä No improvement (3/5)\n",
      "\n",
      "üìà Training: Timesteps 80000 to 100000\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 8.69e+03  |\n",
      "|    ep_rew_mean     | -1.29e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 2459      |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 0         |\n",
      "|    total_timesteps | 83968     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 8.69e+03  |\n",
      "|    ep_rew_mean     | -1.29e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 2459      |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 0         |\n",
      "|    total_timesteps | 83968     |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.69e+03      |\n",
      "|    ep_rew_mean          | -1.29e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 2183          |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 1             |\n",
      "|    total_timesteps      | 86016         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0010184093  |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.46         |\n",
      "|    explained_variance   | -9.536743e-07 |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 2.63e+04      |\n",
      "|    n_updates            | 410           |\n",
      "|    policy_gradient_loss | -0.000311     |\n",
      "|    std                  | 1.05          |\n",
      "|    value_loss           | 6.86e+04      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.69e+03      |\n",
      "|    ep_rew_mean          | -1.29e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 2183          |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 1             |\n",
      "|    total_timesteps      | 86016         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0010184093  |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.46         |\n",
      "|    explained_variance   | -9.536743e-07 |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 2.63e+04      |\n",
      "|    n_updates            | 410           |\n",
      "|    policy_gradient_loss | -0.000311     |\n",
      "|    std                  | 1.05          |\n",
      "|    value_loss           | 6.86e+04      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2096           |\n",
      "|    iterations           | 3              |\n",
      "|    time_elapsed         | 2              |\n",
      "|    total_timesteps      | 88064          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0025324768   |\n",
      "|    clip_fraction        | 0.00317        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.46          |\n",
      "|    explained_variance   | -7.1525574e-07 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 6.26e+04       |\n",
      "|    n_updates            | 420            |\n",
      "|    policy_gradient_loss | -0.00159       |\n",
      "|    std                  | 1.05           |\n",
      "|    value_loss           | 1.2e+05        |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2096           |\n",
      "|    iterations           | 3              |\n",
      "|    time_elapsed         | 2              |\n",
      "|    total_timesteps      | 88064          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0025324768   |\n",
      "|    clip_fraction        | 0.00317        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.46          |\n",
      "|    explained_variance   | -7.1525574e-07 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 6.26e+04       |\n",
      "|    n_updates            | 420            |\n",
      "|    policy_gradient_loss | -0.00159       |\n",
      "|    std                  | 1.05           |\n",
      "|    value_loss           | 1.2e+05        |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2060           |\n",
      "|    iterations           | 4              |\n",
      "|    time_elapsed         | 3              |\n",
      "|    total_timesteps      | 90112          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0035965033   |\n",
      "|    clip_fraction        | 0.00459        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.47          |\n",
      "|    explained_variance   | -1.0728836e-06 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 3.94e+04       |\n",
      "|    n_updates            | 430            |\n",
      "|    policy_gradient_loss | -0.00146       |\n",
      "|    std                  | 1.05           |\n",
      "|    value_loss           | 7.45e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2060           |\n",
      "|    iterations           | 4              |\n",
      "|    time_elapsed         | 3              |\n",
      "|    total_timesteps      | 90112          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0035965033   |\n",
      "|    clip_fraction        | 0.00459        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.47          |\n",
      "|    explained_variance   | -1.0728836e-06 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 3.94e+04       |\n",
      "|    n_updates            | 430            |\n",
      "|    policy_gradient_loss | -0.00146       |\n",
      "|    std                  | 1.05           |\n",
      "|    value_loss           | 7.45e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2016           |\n",
      "|    iterations           | 5              |\n",
      "|    time_elapsed         | 5              |\n",
      "|    total_timesteps      | 92160          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0048545087   |\n",
      "|    clip_fraction        | 0.025          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.46          |\n",
      "|    explained_variance   | -5.9604645e-07 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 1.82e+04       |\n",
      "|    n_updates            | 440            |\n",
      "|    policy_gradient_loss | -0.00337       |\n",
      "|    std                  | 1.05           |\n",
      "|    value_loss           | 4.07e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2016           |\n",
      "|    iterations           | 5              |\n",
      "|    time_elapsed         | 5              |\n",
      "|    total_timesteps      | 92160          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0048545087   |\n",
      "|    clip_fraction        | 0.025          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.46          |\n",
      "|    explained_variance   | -5.9604645e-07 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 1.82e+04       |\n",
      "|    n_updates            | 440            |\n",
      "|    policy_gradient_loss | -0.00337       |\n",
      "|    std                  | 1.05           |\n",
      "|    value_loss           | 4.07e+04       |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.69e+03     |\n",
      "|    ep_rew_mean          | -1.29e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2007         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.004098695  |\n",
      "|    clip_fraction        | 0.00942      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.46        |\n",
      "|    explained_variance   | -8.34465e-07 |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 3.64e+04     |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.00198     |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 6.4e+04      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.69e+03     |\n",
      "|    ep_rew_mean          | -1.29e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2007         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.004098695  |\n",
      "|    clip_fraction        | 0.00942      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.46        |\n",
      "|    explained_variance   | -8.34465e-07 |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 3.64e+04     |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.00198     |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 6.4e+04      |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1996           |\n",
      "|    iterations           | 7              |\n",
      "|    time_elapsed         | 7              |\n",
      "|    total_timesteps      | 96256          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.00026350343  |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.46          |\n",
      "|    explained_variance   | -3.5762787e-07 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 4.07e+04       |\n",
      "|    n_updates            | 460            |\n",
      "|    policy_gradient_loss | -0.000102      |\n",
      "|    std                  | 1.05           |\n",
      "|    value_loss           | 9.2e+04        |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1996           |\n",
      "|    iterations           | 7              |\n",
      "|    time_elapsed         | 7              |\n",
      "|    total_timesteps      | 96256          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.00026350343  |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.46          |\n",
      "|    explained_variance   | -3.5762787e-07 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 4.07e+04       |\n",
      "|    n_updates            | 460            |\n",
      "|    policy_gradient_loss | -0.000102      |\n",
      "|    std                  | 1.05           |\n",
      "|    value_loss           | 9.2e+04        |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.69e+03      |\n",
      "|    ep_rew_mean          | -1.29e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1967          |\n",
      "|    iterations           | 8             |\n",
      "|    time_elapsed         | 8             |\n",
      "|    total_timesteps      | 98304         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012335178 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.46         |\n",
      "|    explained_variance   | -9.536743e-07 |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 4.68e+04      |\n",
      "|    n_updates            | 470           |\n",
      "|    policy_gradient_loss | -0.000253     |\n",
      "|    std                  | 1.04          |\n",
      "|    value_loss           | 1.01e+05      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.69e+03      |\n",
      "|    ep_rew_mean          | -1.29e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1967          |\n",
      "|    iterations           | 8             |\n",
      "|    time_elapsed         | 8             |\n",
      "|    total_timesteps      | 98304         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012335178 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.46         |\n",
      "|    explained_variance   | -9.536743e-07 |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 4.68e+04      |\n",
      "|    n_updates            | 470           |\n",
      "|    policy_gradient_loss | -0.000253     |\n",
      "|    std                  | 1.04          |\n",
      "|    value_loss           | 1.01e+05      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1956           |\n",
      "|    iterations           | 9              |\n",
      "|    time_elapsed         | 9              |\n",
      "|    total_timesteps      | 100352         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0040405714   |\n",
      "|    clip_fraction        | 0.0122         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.46          |\n",
      "|    explained_variance   | -3.5762787e-07 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 2e+04          |\n",
      "|    n_updates            | 480            |\n",
      "|    policy_gradient_loss | -0.00176       |\n",
      "|    std                  | 1.05           |\n",
      "|    value_loss           | 4.21e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1956           |\n",
      "|    iterations           | 9              |\n",
      "|    time_elapsed         | 9              |\n",
      "|    total_timesteps      | 100352         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0040405714   |\n",
      "|    clip_fraction        | 0.0122         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.46          |\n",
      "|    explained_variance   | -3.5762787e-07 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 2e+04          |\n",
      "|    n_updates            | 480            |\n",
      "|    policy_gradient_loss | -0.00176       |\n",
      "|    std                  | 1.05           |\n",
      "|    value_loss           | 4.21e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1949           |\n",
      "|    iterations           | 10             |\n",
      "|    time_elapsed         | 10             |\n",
      "|    total_timesteps      | 102400         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0014669783   |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.46          |\n",
      "|    explained_variance   | -5.9604645e-07 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 2.73e+04       |\n",
      "|    n_updates            | 490            |\n",
      "|    policy_gradient_loss | -0.000576      |\n",
      "|    std                  | 1.05           |\n",
      "|    value_loss           | 5.27e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1949           |\n",
      "|    iterations           | 10             |\n",
      "|    time_elapsed         | 10             |\n",
      "|    total_timesteps      | 102400         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0014669783   |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.46          |\n",
      "|    explained_variance   | -5.9604645e-07 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 2.73e+04       |\n",
      "|    n_updates            | 490            |\n",
      "|    policy_gradient_loss | -0.000576      |\n",
      "|    std                  | 1.05           |\n",
      "|    value_loss           | 5.27e+04       |\n",
      "--------------------------------------------\n",
      "\n",
      "üîç Evaluating on validation set...\n",
      "\n",
      "üîç Evaluating on validation set...\n",
      "   Validation MAE: 64.1931 (-8.82% vs LLM)\n",
      "   Validation MAPE: 14.25%\n",
      "   Avg Reward: -25.1607\n",
      "   üìä No improvement (4/5)\n",
      "\n",
      "üìà Training: Timesteps 100000 to 120000\n",
      "   Validation MAE: 64.1931 (-8.82% vs LLM)\n",
      "   Validation MAPE: 14.25%\n",
      "   Avg Reward: -25.1607\n",
      "   üìä No improvement (4/5)\n",
      "\n",
      "üìà Training: Timesteps 100000 to 120000\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 8.69e+03  |\n",
      "|    ep_rew_mean     | -1.29e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 2392      |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 0         |\n",
      "|    total_timesteps | 104448    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 8.69e+03  |\n",
      "|    ep_rew_mean     | -1.29e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 2392      |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 0         |\n",
      "|    total_timesteps | 104448    |\n",
      "----------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2131           |\n",
      "|    iterations           | 2              |\n",
      "|    time_elapsed         | 1              |\n",
      "|    total_timesteps      | 106496         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.00093183224  |\n",
      "|    clip_fraction        | 0.000146       |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.47          |\n",
      "|    explained_variance   | -5.9604645e-07 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 5.36e+04       |\n",
      "|    n_updates            | 510            |\n",
      "|    policy_gradient_loss | -0.000436      |\n",
      "|    std                  | 1.05           |\n",
      "|    value_loss           | 1.2e+05        |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2131           |\n",
      "|    iterations           | 2              |\n",
      "|    time_elapsed         | 1              |\n",
      "|    total_timesteps      | 106496         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.00093183224  |\n",
      "|    clip_fraction        | 0.000146       |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.47          |\n",
      "|    explained_variance   | -5.9604645e-07 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 5.36e+04       |\n",
      "|    n_updates            | 510            |\n",
      "|    policy_gradient_loss | -0.000436      |\n",
      "|    std                  | 1.05           |\n",
      "|    value_loss           | 1.2e+05        |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2043           |\n",
      "|    iterations           | 3              |\n",
      "|    time_elapsed         | 3              |\n",
      "|    total_timesteps      | 108544         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0010019278   |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.47          |\n",
      "|    explained_variance   | -3.5762787e-07 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 1.86e+04       |\n",
      "|    n_updates            | 520            |\n",
      "|    policy_gradient_loss | -0.000342      |\n",
      "|    std                  | 1.05           |\n",
      "|    value_loss           | 4.65e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 2043           |\n",
      "|    iterations           | 3              |\n",
      "|    time_elapsed         | 3              |\n",
      "|    total_timesteps      | 108544         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0010019278   |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.47          |\n",
      "|    explained_variance   | -3.5762787e-07 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 1.86e+04       |\n",
      "|    n_updates            | 520            |\n",
      "|    policy_gradient_loss | -0.000342      |\n",
      "|    std                  | 1.05           |\n",
      "|    value_loss           | 4.65e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1965           |\n",
      "|    iterations           | 4              |\n",
      "|    time_elapsed         | 4              |\n",
      "|    total_timesteps      | 110592         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.004971101    |\n",
      "|    clip_fraction        | 0.0296         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.47          |\n",
      "|    explained_variance   | -3.5762787e-07 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 1.59e+04       |\n",
      "|    n_updates            | 530            |\n",
      "|    policy_gradient_loss | -0.00385       |\n",
      "|    std                  | 1.05           |\n",
      "|    value_loss           | 4.01e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1965           |\n",
      "|    iterations           | 4              |\n",
      "|    time_elapsed         | 4              |\n",
      "|    total_timesteps      | 110592         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.004971101    |\n",
      "|    clip_fraction        | 0.0296         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.47          |\n",
      "|    explained_variance   | -3.5762787e-07 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 1.59e+04       |\n",
      "|    n_updates            | 530            |\n",
      "|    policy_gradient_loss | -0.00385       |\n",
      "|    std                  | 1.05           |\n",
      "|    value_loss           | 4.01e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1950           |\n",
      "|    iterations           | 5              |\n",
      "|    time_elapsed         | 5              |\n",
      "|    total_timesteps      | 112640         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0034047947   |\n",
      "|    clip_fraction        | 0.00596        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.47          |\n",
      "|    explained_variance   | -3.5762787e-07 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 3.55e+04       |\n",
      "|    n_updates            | 540            |\n",
      "|    policy_gradient_loss | -0.00151       |\n",
      "|    std                  | 1.06           |\n",
      "|    value_loss           | 6.12e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1950           |\n",
      "|    iterations           | 5              |\n",
      "|    time_elapsed         | 5              |\n",
      "|    total_timesteps      | 112640         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0034047947   |\n",
      "|    clip_fraction        | 0.00596        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.47          |\n",
      "|    explained_variance   | -3.5762787e-07 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 3.55e+04       |\n",
      "|    n_updates            | 540            |\n",
      "|    policy_gradient_loss | -0.00151       |\n",
      "|    std                  | 1.06           |\n",
      "|    value_loss           | 6.12e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1948           |\n",
      "|    iterations           | 6              |\n",
      "|    time_elapsed         | 6              |\n",
      "|    total_timesteps      | 114688         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.00063250074  |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.47          |\n",
      "|    explained_variance   | -3.5762787e-07 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 8.08e+04       |\n",
      "|    n_updates            | 550            |\n",
      "|    policy_gradient_loss | -0.000295      |\n",
      "|    std                  | 1.06           |\n",
      "|    value_loss           | 1.43e+05       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1948           |\n",
      "|    iterations           | 6              |\n",
      "|    time_elapsed         | 6              |\n",
      "|    total_timesteps      | 114688         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.00063250074  |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.47          |\n",
      "|    explained_variance   | -3.5762787e-07 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 8.08e+04       |\n",
      "|    n_updates            | 550            |\n",
      "|    policy_gradient_loss | -0.000295      |\n",
      "|    std                  | 1.06           |\n",
      "|    value_loss           | 1.43e+05       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1948           |\n",
      "|    iterations           | 7              |\n",
      "|    time_elapsed         | 7              |\n",
      "|    total_timesteps      | 116736         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0042432677   |\n",
      "|    clip_fraction        | 0.00884        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.47          |\n",
      "|    explained_variance   | -2.3841858e-07 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 1.99e+04       |\n",
      "|    n_updates            | 560            |\n",
      "|    policy_gradient_loss | -0.00161       |\n",
      "|    std                  | 1.05           |\n",
      "|    value_loss           | 5.28e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1948           |\n",
      "|    iterations           | 7              |\n",
      "|    time_elapsed         | 7              |\n",
      "|    total_timesteps      | 116736         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0042432677   |\n",
      "|    clip_fraction        | 0.00884        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.47          |\n",
      "|    explained_variance   | -2.3841858e-07 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 1.99e+04       |\n",
      "|    n_updates            | 560            |\n",
      "|    policy_gradient_loss | -0.00161       |\n",
      "|    std                  | 1.05           |\n",
      "|    value_loss           | 5.28e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1946           |\n",
      "|    iterations           | 8              |\n",
      "|    time_elapsed         | 8              |\n",
      "|    total_timesteps      | 118784         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0033950189   |\n",
      "|    clip_fraction        | 0.0149         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.47          |\n",
      "|    explained_variance   | -5.9604645e-07 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 1.66e+04       |\n",
      "|    n_updates            | 570            |\n",
      "|    policy_gradient_loss | -0.002         |\n",
      "|    std                  | 1.05           |\n",
      "|    value_loss           | 3.57e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1946           |\n",
      "|    iterations           | 8              |\n",
      "|    time_elapsed         | 8              |\n",
      "|    total_timesteps      | 118784         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0033950189   |\n",
      "|    clip_fraction        | 0.0149         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.47          |\n",
      "|    explained_variance   | -5.9604645e-07 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 1.66e+04       |\n",
      "|    n_updates            | 570            |\n",
      "|    policy_gradient_loss | -0.002         |\n",
      "|    std                  | 1.05           |\n",
      "|    value_loss           | 3.57e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1948           |\n",
      "|    iterations           | 9              |\n",
      "|    time_elapsed         | 9              |\n",
      "|    total_timesteps      | 120832         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0030349637   |\n",
      "|    clip_fraction        | 0.00278        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.47          |\n",
      "|    explained_variance   | -1.1920929e-07 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 3.42e+04       |\n",
      "|    n_updates            | 580            |\n",
      "|    policy_gradient_loss | -0.00109       |\n",
      "|    std                  | 1.06           |\n",
      "|    value_loss           | 6.79e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1948           |\n",
      "|    iterations           | 9              |\n",
      "|    time_elapsed         | 9              |\n",
      "|    total_timesteps      | 120832         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0030349637   |\n",
      "|    clip_fraction        | 0.00278        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.47          |\n",
      "|    explained_variance   | -1.1920929e-07 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 3.42e+04       |\n",
      "|    n_updates            | 580            |\n",
      "|    policy_gradient_loss | -0.00109       |\n",
      "|    std                  | 1.06           |\n",
      "|    value_loss           | 6.79e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1947           |\n",
      "|    iterations           | 10             |\n",
      "|    time_elapsed         | 10             |\n",
      "|    total_timesteps      | 122880         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.00010954638  |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.47          |\n",
      "|    explained_variance   | -2.3841858e-07 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 5.44e+04       |\n",
      "|    n_updates            | 590            |\n",
      "|    policy_gradient_loss | -9.18e-05      |\n",
      "|    std                  | 1.06           |\n",
      "|    value_loss           | 1.2e+05        |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.69e+03       |\n",
      "|    ep_rew_mean          | -1.29e+05      |\n",
      "| time/                   |                |\n",
      "|    fps                  | 1947           |\n",
      "|    iterations           | 10             |\n",
      "|    time_elapsed         | 10             |\n",
      "|    total_timesteps      | 122880         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.00010954638  |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.47          |\n",
      "|    explained_variance   | -2.3841858e-07 |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 5.44e+04       |\n",
      "|    n_updates            | 590            |\n",
      "|    policy_gradient_loss | -9.18e-05      |\n",
      "|    std                  | 1.06           |\n",
      "|    value_loss           | 1.2e+05        |\n",
      "--------------------------------------------\n",
      "\n",
      "üîç Evaluating on validation set...\n",
      "\n",
      "üîç Evaluating on validation set...\n",
      "   Validation MAE: 64.1931 (-8.82% vs LLM)\n",
      "   Validation MAPE: 14.25%\n",
      "   Avg Reward: -25.1607\n",
      "   üìä No improvement (5/5)\n",
      "\n",
      "üõë Early stopping triggered after 120000 timesteps\n",
      "   Best validation MAE: 64.1931\n",
      "\n",
      "‚úÖ Training completed!\n",
      "üìÇ Loading best model from ../results/ppo_best_model...\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "\n",
      "üéâ Final Validation Results:\n",
      "   Validation MAE: 64.1931 (-8.82% vs LLM)\n",
      "   Validation MAPE: 14.25%\n",
      "   Avg Reward: -25.1607\n",
      "   üìä No improvement (5/5)\n",
      "\n",
      "üõë Early stopping triggered after 120000 timesteps\n",
      "   Best validation MAE: 64.1931\n",
      "\n",
      "‚úÖ Training completed!\n",
      "üìÇ Loading best model from ../results/ppo_best_model...\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "\n",
      "üéâ Final Validation Results:\n",
      "   LLM-only MAE: 58.9895\n",
      "   LLM-PPO MAE: 64.1931\n",
      "   Improvement: -8.82%\n",
      "   MAPE: 14.25%\n",
      "\n",
      "üíæ Training history saved to ../results/ppo_training_history.csv\n",
      "üíæ Final model saved to ../results/ppo_stock_prediction_model\n",
      "   LLM-only MAE: 58.9895\n",
      "   LLM-PPO MAE: 64.1931\n",
      "   Improvement: -8.82%\n",
      "   MAPE: 14.25%\n",
      "\n",
      "üíæ Training history saved to ../results/ppo_training_history.csv\n",
      "üíæ Final model saved to ../results/ppo_stock_prediction_model\n"
     ]
    }
   ],
   "source": [
    "# Train PPO model with validation monitoring and early stopping\n",
    "try:\n",
    "    print(\"=\"*80)\n",
    "    print(\"üöÄ PPO Training with Validation-Based Model Selection\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Verify data\n",
    "    if len(train_df_ppo) < 10:\n",
    "        raise ValueError(f\"Not enough training data: {len(train_df_ppo)} samples\")\n",
    "    if len(val_df_ppo) < 10:\n",
    "        raise ValueError(f\"Not enough validation data: {len(val_df_ppo)} samples\")\n",
    "    \n",
    "    # Create training environment\n",
    "    env = StockPredictionEnv(train_df_ppo, window_size=5)\n",
    "    \n",
    "    # Test environment reset\n",
    "    print(\"\\nüìã Environment Setup:\")\n",
    "    obs, info = env.reset()\n",
    "    print(f\"   ‚úÖ Training samples: {len(train_df_ppo)}\")\n",
    "    print(f\"   ‚úÖ Validation samples: {len(val_df_ppo)}\")\n",
    "    print(f\"   ‚úÖ Observation shape: {obs.shape}\")\n",
    "    print(f\"   ‚úÖ Action space: {env.action_space}\")\n",
    "    \n",
    "    # Calculate baseline (LLM-only) performance on validation\n",
    "    print(\"\\nüìä Baseline Performance (LLM without PPO):\")\n",
    "    llm_val_mae = np.mean(np.abs(val_df_ppo['llm_prediction'] - val_df_ppo['actual_price']))\n",
    "    llm_val_mape = np.mean(np.abs((val_df_ppo['llm_prediction'] - val_df_ppo['actual_price']) / val_df_ppo['actual_price'])) * 100\n",
    "    print(f\"   Validation MAE: {llm_val_mae:.4f}\")\n",
    "    print(f\"   Validation MAPE: {llm_val_mape:.2f}%\")\n",
    "    \n",
    "    # Initialize PPO agent with improved hyperparameters\n",
    "    print(\"\\nü§ñ Initializing PPO Agent...\")\n",
    "    model = PPO(\n",
    "        \"MlpPolicy\",\n",
    "        env,\n",
    "        learning_rate=5e-5,  # Further reduced for finer control\n",
    "        n_steps=2048,\n",
    "        batch_size=64,\n",
    "        n_epochs=10,\n",
    "        gamma=0.99,\n",
    "        clip_range=0.2,\n",
    "        ent_coef=0.02,  # Increased entropy for more exploration\n",
    "        vf_coef=0.5,  # Value function coefficient\n",
    "        verbose=1,\n",
    "        max_grad_norm=0.5  # Gradient clipping for stability\n",
    "    )\n",
    "    \n",
    "    # Training with validation checkpoints\n",
    "    print(\"\\nüéØ Training PPO Model with Validation Monitoring...\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Training parameters\n",
    "    checkpoint_interval = 20000  # Evaluate every 20k timesteps\n",
    "    total_timesteps = 200000  # Extended training time\n",
    "    best_val_mae = float('inf')\n",
    "    best_model_path = '../results/ppo_best_model'\n",
    "    patience = 5  # Increased patience to allow more exploration\n",
    "    no_improvement_count = 0\n",
    "    \n",
    "    training_history = {\n",
    "        'timesteps': [],\n",
    "        'val_mae': [],\n",
    "        'val_mape': [],\n",
    "        'val_reward': []\n",
    "    }\n",
    "    \n",
    "    # Train in chunks to monitor validation performance\n",
    "    for checkpoint in range(0, total_timesteps, checkpoint_interval):\n",
    "        remaining_steps = min(checkpoint_interval, total_timesteps - checkpoint)\n",
    "        \n",
    "        print(f\"\\nüìà Training: Timesteps {checkpoint} to {checkpoint + remaining_steps}\")\n",
    "        model.learn(total_timesteps=remaining_steps, reset_num_timesteps=False)\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        print(f\"\\nüîç Evaluating on validation set...\")\n",
    "        val_metrics = evaluate_on_validation(model, val_df_ppo, window_size=5)\n",
    "        \n",
    "        # Store metrics\n",
    "        training_history['timesteps'].append(checkpoint + remaining_steps)\n",
    "        training_history['val_mae'].append(val_metrics['mae'])\n",
    "        training_history['val_mape'].append(val_metrics['mape'])\n",
    "        training_history['val_reward'].append(val_metrics['avg_reward'])\n",
    "        \n",
    "        # Print validation metrics\n",
    "        improvement_vs_llm = ((llm_val_mae - val_metrics['mae']) / llm_val_mae) * 100\n",
    "        print(f\"   Validation MAE: {val_metrics['mae']:.4f} ({improvement_vs_llm:+.2f}% vs LLM)\")\n",
    "        print(f\"   Validation MAPE: {val_metrics['mape']:.2f}%\")\n",
    "        print(f\"   Avg Reward: {val_metrics['avg_reward']:.4f}\")\n",
    "        \n",
    "        # Check if this is the best model\n",
    "        if val_metrics['mae'] < best_val_mae:\n",
    "            best_val_mae = val_metrics['mae']\n",
    "            model.save(best_model_path)\n",
    "            print(f\"   ‚≠ê New best model! Saved to {best_model_path}\")\n",
    "            no_improvement_count = 0\n",
    "        else:\n",
    "            no_improvement_count += 1\n",
    "            print(f\"   üìä No improvement ({no_improvement_count}/{patience})\")\n",
    "            \n",
    "            # Early stopping\n",
    "            if no_improvement_count >= patience:\n",
    "                print(f\"\\nüõë Early stopping triggered after {checkpoint + remaining_steps} timesteps\")\n",
    "                print(f\"   Best validation MAE: {best_val_mae:.4f}\")\n",
    "                break\n",
    "    \n",
    "    # Load best model\n",
    "    print(f\"\\n‚úÖ Training completed!\")\n",
    "    print(f\"üìÇ Loading best model from {best_model_path}...\")\n",
    "    model = PPO.load(best_model_path, env=env)\n",
    "    \n",
    "    # Final evaluation\n",
    "    print(f\"\\nüéâ Final Validation Results:\")\n",
    "    final_val_metrics = evaluate_on_validation(model, val_df_ppo, window_size=5)\n",
    "    final_improvement = ((llm_val_mae - final_val_metrics['mae']) / llm_val_mae) * 100\n",
    "    print(f\"   LLM-only MAE: {llm_val_mae:.4f}\")\n",
    "    print(f\"   LLM-PPO MAE: {final_val_metrics['mae']:.4f}\")\n",
    "    print(f\"   Improvement: {final_improvement:+.2f}%\")\n",
    "    print(f\"   MAPE: {final_val_metrics['mape']:.2f}%\")\n",
    "    \n",
    "    # Save training history\n",
    "    history_df = pd.DataFrame(training_history)\n",
    "    history_df.to_csv('../results/ppo_training_history.csv', index=False)\n",
    "    print(f\"\\nüíæ Training history saved to ../results/ppo_training_history.csv\")\n",
    "    \n",
    "    # Also save final model\n",
    "    model.save('../results/ppo_stock_prediction_model')\n",
    "    print(f\"üíæ Final model saved to ../results/ppo_stock_prediction_model\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error during PPO training: {e}\")\n",
    "    print(f\"\\nError type: {type(e).__name__}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92293ca",
   "metadata": {},
   "source": [
    "## 9. Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "50282923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Training progress visualization saved to ../results/ppo_training_progress.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABWoAAAPeCAYAAACVxSMrAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzs3QecE3X6x/Fn6U16V5qKSlNRsGFB4UDsqKAIitgrClbs6B2IvR6Ieti7gOhZzi6oNBGV80QQbChNkV6Enf/r+7ub/CfZZDcL2Uxm9/N+GZdMZiaT+c0kzzzzK3me53kGAAAAAAAAAAhNufDeGgAAAAAAAAAgJGoBAAAAAAAAIGQkagEAAAAAAAAgZCRqAQAAAAAAACBkJGoBAAAAAAAAIGQkagEAAAAAAAAgZCRqAQAAAAAAACBkJGoBAAAAAAAAIGQkagEAAAAAAAAgZCRqgVLmgw8+sLy8vNjj+++/j712+umnx6Z37do17XVqXn85rSMbtnZbUfqFcTxGVabPI32fBL9f9H0DAEBhiE2B5Dim0nfTTTfF9lXLli0zss7g99Jjjz2WkXUCmUCiFihhhx9+eOwHoE6dOrZx48ak83meZzvttFNs3o4dO1ppVVqCkuBFgv+YNWtW0nn333//AvMGL1SCdIzUq1cvbt5OnTqlfQGU6pHuhUyy9VWqVMlq1aplO+64o3Xv3t2GDx9uP/30U5p7quxITGSm+wAAIFuITQsiNs1ebFqjRg1r27atXXzxxbZgwYKtiqPSLaNk66tYsaJtt9121qJFCzvkkEPsqquusm+++Sat9ZU1WxPTpjqGAKSvQjHmBbCVgd9bb73l/v3HH3/Ya6+9ZieccEKB+T7++OO4YKUkagecfPLJ1r59e/fvZs2aWS6L0rYG3XfffQXuyM6YMcOmTp2a9jomTZpkv//+e9y0zz77zObMmRPbJ9n2559/useqVats4cKF9u6779ott9xi119/vXuUK5e9+37nn3++HXXUUe7fYe2PqMj0eVS3bl27/fbbY891AQ8AiBZi09K/rbkcm65du9b+85//uMc//vEPe+WVV1wlgGzZvHmzrVmzxj1+/PFH++ijj+y2225z8eVdd91lVapUydq2RPWYCkOPHj1ckl9UeSQTgjFt586dM7JOIBNI1AIl7LjjjrPatWu7QFieeOKJpMGwpvt0p7d///4lUoNCjyiI0rYGPffcc+5Hv0GDBrFp9957b7HWkarpjabfcccdRS5/0kknJa3lsLVJTX99K1eudLUydHG3ZcsW91AzpMWLF9vo0aOtpClJXLNmTbc9uSoxkSkzZ860559/Pvb8vPPOK1aC0//cuXAeaTsuv/zyjK0PAJB9xKalf1tzNTbdtGmTffrpp+7mgKxbt85OPfVUVwuzcuXKBZb7y1/+4hJ0ibY2qemvT0laJZn/+c9/2oYNG9xrimWVuFXiuHz58laS/Ngu14+pxJj2u+++szFjxhR6zaFYuCRi2gMOOMA9MomYFjnLA1DizjvvPE+nmx4VK1b0li9fHvf6hg0bvNq1a8fm6d27t5v+22+/eVdccYV32GGHeS1atPBq1Kjhlm/YsKHXvXt374knnvDy8/Pj1vX+++/H1qPHwoULY68NHDgwNv2QQw4psJ3jx4/3Onfu7FWpUsW9xxlnnOEtWbLEzesvp3UE3Xbbbd6xxx7rtW7d2qtTp45XoUIFr1atWm49f/3rX701a9bE5h03blzctiV7aPvT2daff/7Zu/zyy7327dt71atX9ypXruz2Uf/+/b1p06YVmP/GG2+MrU/z/fHHH2755s2bu33aqlUr729/+1uB/VmY4H4pV65c7N+33HJLbJ5ff/3VrV/Ty5cvn7JsfL/88kvcfLvsskvs340aNfL+/PPPAssklrn287Yoan1ff/2121/Bed54442U5Zwo1boTl1u7dq13zTXXuPfScXXJJZe4+VIdj9qficfSs88+6+2zzz5e1apV3Tl24oknej/++GOBbdJ+HTVqlLfzzjt7lSpV8nbccUd3PGzatGmb923i5/KP8eJ+bi2nc7Jjx45e48aN3Xbqc+20007e6aef7n355ZcF3ruw8yjxc/3rX//yunbt6s4nfdccfvjh3pw5c+KWSbaPM3GOff/9916/fv28unXruvc/6KCDvHfffbfIYwkAsHWITf+L2DSc2FT7JPi6fvOTxRnaR9uiqPWpzPbee++4eUaPHp3ycyTuH5VbsnUnLjdv3jzv9ttv93bbbTcXv+n4LIk4zffwww+741DH4A477OBddtll7rhPtb3pKqpc0/3cn3/+uXf++ee7GL1p06bu/Na26tjv27evN3ny5CLPl8LKYebMmd6RRx7pznvFygceeGDSdaZ7TaLvQ3136DtFn2P77bd3+1TTE+m7VN+vOjf0uXR8vfDCC0UeS0AQVz1AFkydOjXui/mBBx6Ie/3FF1+Me/2VV15x07/66qsig8dBgwZlJBhWUJJs/QoS27ZtmzIYrlevXqHb16FDB2/16tUZDYY//PBDF3inWocC0zvvvDPlj7u2uU2bNkmXvf7667cqGN5zzz1jQYJ+vP2g9YYbboi7yCnqB1rJQv91/bhPmTIlbplJkyaFnqiV6dOnx83To0ePjCdqlawLPi9uolZBWbIyVpC1fv36uG06+eSTk8579NFHZz1Rm+pzKyAs7NxR4Pj222/HrTvdC4AuXbp4eXl5Bdapc2Xp0qXFTtQW5xzTOpV4TnYeK8gu7FgCAGwdYlNi0zBjUx1vwdeffvrpUBK18tNPP7nPFUxEZzpRmxjbFTdRm26cJldffXXS40hJUSUPs5moTfW577///kLPOX3WxHWnm6jV5/RvRAQfSgSrssnWXJOkuqY49dRT49a3YsUKl5RO55qCRC0KQ9cHQBbsu+++1qZNG9cXk9+U7MILL0zatKxhw4Z2xBFHuH+r308tt88++1jjxo1dMzU1z/n888/t1VdfdYM8jBs3zjWl1jxb6+eff7YhQ4bEnquD/TPPPNO9v/qOUp+kqeywww526KGHug75NSCFtknzq6m3+qD66quv7O9//7tdeeWVru8fNaHRa2oOLhqcSn1C+YpqEq5mescff7ytWLHCPa9ataoNGjTINaN59tln7YcffrD8/HzXlGXvvfd2gwQk+u2339zyp512mjVt2tQeeeQRW758eawp2HXXXecGzyoONZG66KKL7IorrrBFixbZSy+95LbzoYcein1O9as6YcKEQtfz+OOPx/6t46BLly5xx46amB199NGFruPNN9+MfZ4gNU/KVP9XKss99tjDvvjiC/dc/XupK4RMNhWbPHmyO3fUTE3HUvPmzYu1/JQpU9x29uzZ095//33X157MmzfPJk6c6PoFE5WVmgX6VFZ6Tc3fnn76acu2VJ+7evXq7nju0KGDa1amY1/Hsprt6fhQc8LBgwfb119/Xez31L7Zbbfd3DE7e/Zse/311910rf/RRx+1q6++uljrK845pvNG3WcEj3udu/pcegAAMo/YlNg0m7FpInV/EKRjKZlPPvkkadcKvXr1snbt2lkm6HhRrKguD+Tbb7+1X375xZVDJmM7ba/2k47H4sbL6cZp6nt41KhRcefuwIEDbfXq1e68UayYTak+t7q52G+//WzPPfd0g9Sp71l1saYxMPQZNO9ll13mrl10PhXH9OnTXZmqqxYNfPzMM8/EBsTTuRTsuqE41xS9e/d2g+Dp2sAfME3/vvXWW2PHis7T4MB0Bx54oPsu0n7Q9yOQLhK1QJZoAAaNKur/gCgI2GWXXVwQpsSaTz8qFSr899TUj4GSLkoY6UdLyQz1EXbQQQe5DvwVdIn6DN2WYPipp56K9c8kCti6devm/q0+yxSQpaJgQT+sCqS0nQqAFbwpEFXyzt8+BcP6odZDfUL5wbASh8XpH0jBoIIS38svv+yCNVFAr2Ba/U7pB/7uu+9OGgyLBgu45JJL3L8VKKi/Nr/vpLlz57pkWHGdddZZrs9W7QMN3KBgaMmSJe41XfwUNeCWjotgkq1fv36xvzfccIP7t/r00udXUJOKLjaCfaL61IdUJgcq2HXXXWOJWh0/GmQi2P/ZtlIw+uKLL271QGU6JxRY6ZzRQGgK2pYuXepe0/nkJ2p1MeRToKjBNfzPoeNp+PDhlk2pPre2Qxd6Ond0caQLw0aNGrnj379Y0l8FpcUtZ82v408XwrLXXnu5i25/X22NdM6xX3/9NXaxIQrI/aT5tdde624GaF4AQOYRmxKbZis29SsR6P0VZwWTVoplUvU9+vbbb7tHovr162csUevHtEE6jjOZqFV5qtLA1g5Ulm6cpqTtfyuK/vemynvvvRfbT7o5oxsI2ZTqc5999tnu8eWXX7obJzp+9B1z7LHHxj6Prit0Tuq7pThUsWHatGmx8lM/yKqgsS0x7aWXXurOXenTp49LMIvicn3v6b00SF3wpoaO6Q8++MAlpzWfBszTvgDSQaIWyBJ1lH/NNde4Wofy5JNP2i233OKSEkoi+YI/oPrR0l3QomqVqdbBtvADUz9Y8gNh/0emVatWSWsu6EdHd3B1d7KwO7Tbun2p7sArmeYHwv5dYz1Xkitx3iD9YJ577rkpgzO/RkRxqVaJakJoMAK9ty4O/IBBtUCKqrEQHKhBgdiRRx7p/q2Eoh8Maz/r7q1qTobNDwRLis6XrU3S+hcnungU/dVx7Cdqg2UcPP51/ASTzTofs52oTfW5daGiz+QfV4Wdb8VN1Or7yQ/+RRfq/gXA1pwP6Z5jCm6Dx5HOH59qW+hCUBeYAIDMIzbNDGLTomPTVJUIlMBTcmtrE5hRiWmV+N+Wz5hunBY8b3RjIpjMHjBggEuOKqGYLak+twYn1nH573//u9Dlt+Y8VbI3mGQPnktbex5dcMEFSdcXXKdq0uqGTPAGl1+DWHG9vjdJ1CJdW38FDKBYmjRpEjdqqWoKKCgINi3T3dHg3XIFUOk0/VVTjm3hj/rrB5SJFCAnozvzai5WVDOabd2+IN1dLWy7gtNS/RhrnmDQkDjKrIL8rXXxxRfH/u3XKtEPc61atYrcR2oe5zvmmGNiTX1at27tgq2iRt71qcnh//ogj3t07drVMkk1b3zan6lqUgSD3+IcC2ritS1atmwZ9zxYzsEyDh7/iU3vUjXFK0nJPrea4KlmTVFJ2q0939LdV+lK9xwL7vtc2f8AUFYQm2YGsWnRsWmQ1qFYR8kv1aZUtwOp3HjjjUljWtUGL6mYVrbffvu0ErrpHke5ENOqxqpqImdTss+9fv161+VGUUnaXIlpE9dJTItsIFELZFEwqFDfNg8//HBcE4zg62qipKZEPtUk+O6779xdUAUJ6lMrU3S33efXOAzym0glCt4Z151LNTPRD6q2T/1hlQT1zVnYdgWnqV+yZPxalr68vLyMbZ+a1gUverTuYICciprkBH/gVTNBy/oP1Tz06Q66Atsw6Y693+2BqBmfXws0sTaoAjKf+odNl2p7bIt0y7mw4z/Yd2q2JPvcaiKoplu+O++80x0vOtfSCXSLkulzYmv2fa7sfwAoS4hNtx2xadGxabASgeIZddX04IMP2s4772xhU/JaXWEEa0z6NTILi2nVJUWq4zAXY1qdp8nGsChJyT63uh9R11c+9UW7bNkyd2zoO2ZblcS5FFwnMS2ygUQtkEVqihEM0IKDJGiAgFNOOSX2XH1r+U3RRE2N1Om/mlConyr16ZMp6rvUp4BDHbn71L9XqgEbgv1xaR3qi0yfQ32KFdZhevDHLph8SkewDyv9qL/xxhtxP4jB56n6uyppfv9iogGh0rmLXpyaCH7AGxYdf37/rr6hQ4emDFTUF5l/x3nkyJGWa4LHvwL1YG2XMPdzqnPNb4bq14R54YUXLKpUGycY8AZr7iTW5AEAZB6x6X8Rm0Y7Nt1aShhqbIBgf8jpxLSimLaku0zYlvNGlSrmz58fV2M+m90epBvTqosAv6ZvlGNanVMa6yJ408g/PvQ32H8tUBT6qAWyyO9zUSPNJgaCGg0z2HRczbwUHPh3sv/617+6YE8/sBq1M5NNtvQDqX4g/XVqVEv1hakEit4rFd1x9mtIqoaF+tZSsw6NKhsc8TJRsDmR7sYreFSfmgqki+p7VU211H+a/yOvASXOOOMMN7KuRvX0+wbStqvj9zCoLzKNHKvEZDoDP+hO/r/+9a/Y8/bt2ycdIEHBoUYO9ms13HbbbbHBPZIN2JBIiT31TVVc/vpUc0A1JvQ8GOhpMIpgTQ0/+eYHJwqA9XqmL+IyRfvEr0mh802DLfTt29d1M6CgNhck9oeli2MdZ9qfOt+i3OxWn8WvoaXmtkoEaBAxTWMgMQAoWcSm/0VsWrKx6dZSUv6OO+5I+lpxBnxLXJ9qbqpFko6RYC1ZHfM6zoLJN/UNu3r1avdc3TVoGdWOTNXfcJjUNcnYsWNdDK6bKgcffLDrC1YxvAYay8WYVn3najBZ1ehXP9lRpeNeLRAeeOAB91wDiR122GGuDFSLWM+BtHkAsmr69OnKXhV4vPrqqwXmvfXWW5PO2759e2/vvfeOPR84cGBsmffffz9u3oULF8Ze03z+9EMOOSTuvR544IGk79W0aVOvdevWSd9r8uTJXoUKFQosU6NGDe/444+PPW/RokXce33++edeuXLlCixXvXr1tLb1ww8/9GrXrp10e/XQuu+44464ZW688caU26N9FFxe+zAd2i5/GZVHUcaNG5e0bEaOHBk3fcqUKUmXf/TRR+PmmzhxYtIyT/VI/NyppLs+lf0tt9zibdmypcA6BgwYkHSZI444Iu659kmq/ZPOfg8ej0WVY6rl5OSTT066vb169Yp7/vjjj3vFlfi5Ercrnc+9adMmr0OHDkm3MXiuJK6/sPMoVTkUtlxh+3hrzzG91rhx4wKfKy8vzzv88MPjngMAMo/YlNi0pGPTxDgjlcTPXdgjk+tTjHHRRRd5GzZsKLCO6667LukynTp18ho2bBh7rvJM55gPynScJldffXXS7d1rr728Ro0axZ4PHz7cK66iyjXdzx2M7wqLaYPrL+x80fNk5VDUcqneq6jYPNVyK1as8Hbbbbe0ril++OGHtPc7yh66PgCyTP13Jd6R1p3+ww8/vMC8V111leu/SSN7qkmW5lPtvw8//DCuaUUmqFakahuoNqRqV6gJikYYVd9ewZEzgw488EBXE1HNuLSMamweccQR7m51YXfr99xzT9ekWQNUbM0IqLozOWfOHNenkfZltWrVXI2H5s2buxoYen+9FhXBpjC6y9ylS5ek86mWZ7Cvp+I2SdsWataoGgUaZVl90g0fPtzd+b7uuusK9N8ljzzyiKvpoBoqKhsdw6plodocuUh38G+99Vbbaaed3LmmQQOuv/56N0pyUGITuGzRNr333nvuTr1qN+l8U+0W1ZpQjaMo075WjRx1p6H9q0FG9t9/fzdYjfo+DnvfA0BpR2xKbBrF2HRrKW7VNqvGtMpNx7Ra8Nx///0FBoqSm2++2UaMGOFiYB3zLVq0sGHDhrlj3h9cLZeoSwbFhzoOdQyq9dJFF13kug9RzdpciKtefvllV7tc26ZtVF/F2se5Uut3a2mfTp482dXkVwsEHU9qJaYWY6rZnDgvkIqrnpLyVQAAygA1e0sWbKv5UuJoyakuDrF11AxTzWYVqAepyZ4utKdPnx7rUy/YDBMAAADpxbTqskFdO/g+/vjj0PpMLov7/8QTT3QJamndurV9++23IWwdooI+agEAZZ5q6KgfPPWlq5oS6rtMd8SDd/bV5xxJ2sxT7Q4FrBqwRjWaVANBCXHVyvGTtFJUH4EAAABl3TXXXGOzZ892SVnVAtbNcA0s5vdD7Q86ptZLyDzVQO/Zs6cbyFDXDerHWy0DXn/99dg8xLQoCjVqAQBl3nHHHVdotwwKtjSIWnBkbGSGBqUpbL9q8BV1taGuKAAAAJCauhS49957U76ubgbefvtt1/UUMk9dGmhg3FTUVcxDDz3k4lsgFWrUAgDKPI3YrIBp1qxZtnz5cvvzzz9dX7Cq4an+11TjNpOjGOP/qR8/9fX2/vvv24IFC2zFihWuDzj1Hae+BtXPl/pPBAAAQNGVD5YsWeL6cl62bJlt2LDBJQ81tkHv3r3trLPOcrEXSoZiWlXu+Oabb+z33393fSKrL9799tvPzjzzTDfWB1AUatQCAAAAAAAAQMgKDtUNAAAAAAAAAMgqErUAAAAAAAAAEDI63CsB+fn59ssvv9h2221HJ9EAAAAZpp67Vq9e7UZUVv9v2HrErQAAALkTu5KoLQEKdjUICgAAAErOTz/9ZDvssEPYmxFpxK0AAAC5E7uSqC0BqpHgF0DNmjVLvBaERnNs0KABNUoihHKLJsoteiizaKLcoimb5bZq1SqXXPRjLkQjbhXO72ii3KKHMosmyi2aKLdoys/R2JVEbQnwm40p2M1GonbDhg3uffhCiA7KLZoot+ihzKKJcoumMMqNpvrRiluF8zuaKLfoocyiiXKLJsotmvJzNHblCAIAAAAAAACAkJGoBQAAAAAAAICQkagFAAAAAAAAgJCRqAUAAAAAAACAkJGoBQAAAAAAAICQkagFAAAAAAAAgJCRqAUAAAAAAACAkJGoBQAAAAAAAICQVQh7AwAAAACUPj+u/NGWr1seNy0/P99+//13q7ulrpUrF19npH61+ta8VvMsbyUSUW7RQ5lFE+UWTZRbNP0YoXIjURtRG/7cYq9/9au99e/FtuyPtdag9s/Ws11jO6JDE6tSsXzYm4cUKLdootyihzKLJsotmig3pLog2vWBXW3D5g1pL1OlQhWbe9FcLmhDRLlFD2UWTZRbNFFu0fRjxMqNRG0Evf31Ervsxdm2av1mK5dnlu+Zlftljb317yV206v/trv67Gnd2zYKezORgHKLJsoteiizaKLcoolyQyqqtVKcCyLR/FqOi9nwUG7RQ5lFE+UWTZRbNC2PWLnRR20EL4jOeXKmrV6/2T3XBVHwr6af/eRMNx9yB+UWTZRb9FBm0US5RRPlBgAAAGQWidqINS1UrRXz3H9Jueme2eUvznbzI3yUWzRRbtFDmUUT5RZNlBsAAACQeSRqI0T9v6lpYaoLIp9eX7l+s70x59csbRkKQ7lFE+UWPZRZNFFu0US5AQAAAJmX53leUTE2imnVqlVWq1YtW7lypdWsWTNj6z3vyc/sX18vjjUpLErlCuWsTrVKGXt/bJ0V6zbZxs35ac9PueUGyi16KLNootxKf7mp79oebRvbmFP3zvlYqywqqX0569dZtvfY4pd5g2oNrFJ5zvGwbNqyyZatW1bs5Si38FBm0US5RRPlVrbK7bNzPrO9muyV9XiLwcQi5I91m9JO0oouoBavKl6HyQgf5RZNlFv0UGbRRLlFj2KXP9ZvCnszEBFbcyGF8FFu0UOZRRPlFk2UG4qDRG2E1K5WKTaicjqodZQbqC0WTZRb9FBm0US5lY0atbWrUmZID7WOwkVtseihzKKJcosmyq1slVtYSNRGSI92jezNfy9Oe/5bT+hgvTvuUKLbhKKNn/WzDX3hi7Tnp9xyA+UWPZRZNFFupb/cdIO5Z/tGJb5NKB3eHPBmxpoZIntdVlBu4aHMoolyiybKrWyVW1gYTCxCjujQxGpWrWB5Rcyn12tVrWC92jfJ0pahMJRbNFFu0UOZRRPlFk2UGwAAAJB5JGojpErF8nZXnz3dVU+qCyM3Pc/szj57uvkRPsotmii36KHMoolyiybKDQAAAMg8ErUR071tIxt7aidXi8Xv9y34V9MfPrWTmw+5g3KLJsoteiizaKLcoolyAwAAADKLPmoj6C9tG9m0a7rbG3N+tTfnLLZlK9dag1rV7fD2jV3TQmqt5CbKLZoot+ihzKKJcosmyg2p1K9W36pUqGIbNm9IexnNr+UQHsoteiizaKLcoolyi6b6ESu3PM/zvFDeuRRbtWqV1apVy1auXGk1a9Ys0ffKz8+3pUuXWsOGDa1cOSpIRwXlFk2UW/RQZtFEuUVTNsstm7FWaVeS+/LHlT/a8nXLCxwnv//+u9WtW7fAcaILoua1mmd0G1B8lFv0UGbRRLlFE+UWTT+GXG7FibeoUQsAAAAg43SBk3iR4xL65bkRk8sot+ihzKKJcosmyi2amkeo3HJnS7Jk0aJFNmDAAKtXr55VrVrVOnToYDNnzkw673nnnWd5eXl2zz33ZH07AQAAAAAAAJQdZapG7YoVK6xLly526KGH2htvvGENGjSwefPmWZ06dQrMO2HCBJs6dao1bdo0lG0FAAAAAAAAUHaUqUTtqFGjrFmzZjZu3LjYtFatWiWtdXvxxRfbW2+9ZUceeWSWtxIAAAAAAABAWVOmuj6YNGmSderUyfr06eP6oOjYsaM9/PDDBfqoOPXUU+2KK66wdu3ahbatAAAAAAAAAMqOMlWjdsGCBTZ69GgbOnSoXXPNNTZjxgwbPHiwVapUyQYOHBirdVuhQgU3PV0bN250j+Bobn7SV4+SpPV7nlfi74PMotyiiXKLHsosmii3aMpmuXFsAAAAoDQqU4laBfWqUTtixAj3XDVq58yZY2PGjHGJ2s8++8zuvfdemzVrlhtELF0jR4604cOHF5i+bNky27Bhg5X0Z1q5cqW7MMqlUepQOMotmii36KHMoolyi6Zsltvq1atLdP0AAABAGMpUorZJkybWtm3buGlt2rSxl19+2f178uTJtnTpUmvevHns9S1btthll11m99xzj33//fdJ1zts2DBXSzdYo1Z94Wqwspo1a1pJXxQpqaz34mI2Oii3aKLcoocyiybKLZqyWW5VqlSxqPnoo4/s9ttvdxUDfv31Vzdw7XHHHZd03vPOO88eeughu/vuu+3SSy8ttLLA+PHj7ZtvvrGqVavaAQcc4FqH7brrriX4SQAAAFBSylSitkuXLjZ37ty4ad9++621aNHC/Vt903bv3j3u9Z49e7rpgwYNSrneypUru0ciXaRk4wJTF0XZei9kDuUWTZRb9FBm0US5RVO2yi2Kx8XatWttjz32sDPOOMOOP/74lPMpgTt16lRr2rRpkev88MMP7cILL7TOnTvb5s2bXddePXr0sK+//tqqV6+e4U8AAACAklamErVDhgxxNQ3U9UHfvn1t+vTpNnbsWPeQevXquUdQxYoVrXHjxtRMAAAAwFbr1auXexRm0aJFdvHFF9tbb71lRx55ZJHrfPPNN+OeP/bYY27AXNXaPfjgg7d5mwEAAJBd0auOsA1U20C1FJ599llr37693XLLLa5Lg/79+4e9aQAAACjjXUeoFdcVV1xh7dq126p1qI9gqVu3boa3DgAAANlQpmrUylFHHeUe6UrVLy0AAACQKepbtkKFCjZ48OCtTvSqP1t19aUKCals3LjRPYJjK/jL61HS9B4acC4b74XModyihzKLJsotmii3aMrPYrkV5z3KXKIWAAAAyCXqquDee++1WbNmuX5+t4b6qp0zZ45NmTKl0Pk0ANnw4cMLTF+2bJlt2LDBsnGhopq/ujCKYl/DZRXlFj2UWTRRbtFEuUVTfhbLbfXq1WnPS6IWAAAACNHkyZNt6dKl1rx589i0LVu22GWXXea66SqqhddFF11kr732mn300Ue2ww47FDrvsGHDbOjQoXE1aps1a2YNGjSwmjVrWjYuipSM1vtxMRsdlFv0UGbRRLlFE+UWTflZLLcqVaqkPS+JWgAAACBE6pu2e/fucdN69uzppg8aNCjlcqoBosHHNAbDBx98YK1atSryvSpXruweiXSBkq2LS10UZfP9kBmUW/RQZtFEuUUT5RZNeVkqt+Ksn0QtAAAAUMLWrFlj8+fPjz1fuHChzZ492w38pZq09erVi5u/YsWK1rhxY9t1111j07p162a9e/d2NWj97g6eeeYZe+WVV2y77bazxYsXu+m1atWyqlWrZu2zAQAAIDNI1AIAAAAlbObMmXbooYfGnvvdDwwcONAee+yxtNbx3Xff2fLly2PPR48e7f527do1br5x48bZ6aefnqEtBwAAQLaQqAUAAABKmJKp6qogXcn6pU2cVpz1AQAAIPfReQYAAAAAAAAAhIxELQAAAAAAAACEjEQtAAAAAAAAAISMRC0AAAAAAAAAhIxELQAAAAAAAACEjEQtAAAAAAAAAISMRC0AAAAAAAAAhIxELQAAAAAAAACEjEQtAAAAAAAAAISMRC0AAAAAAAAAhIxELQAAAAAAAACEjEQtAAAAAAAAAISMRC0AAAAAAAAAhIxELQAAAAAAAACEjEQtAAAAAAAAAISMRC0AAAAAAAAAhIxELQAAAAAAAACEjEQtAAAAAAAAAISMRC0AAAAAAAAAhIxELQAAAAAAAACEjEQtAAAAAAAAAISMRC0AAAAAAAAAhIxELQAAAAAAAACEjEQtAAAAAAAAAISMRC0AAAAAAAAAhIxELQAAAAAAAACEjEQtAAAAAAAAAISMRC0AAAAAAAAAhIxELQAAAAAAAACEjEQtAAAAAAAAAISMRC0AAAAAAAAAhIxELQAAAAAAAACEjEQtAAAAAAAAAISMRC0AAAAAAAAAhIxELQAAAAAAAACEjEQtAAAAAAAAAISMRC0AAAAAAAAAhIxELQAAAAAAAACEjEQtAAAAAAAAAISMRC0AAAAAAAAAhIxELQAAAAAAAACEjEQtAAAAAAAAAISMRC0AAAAAAAAAhIxELQAAAAAAAACEjEQtAAAAAAAAAISMRC0AAAAAAAAAhIxELQAAAAAAAACEjEQtAAAAAAAAAISMRC0AAAAAAAAAhIxELQAAAAAAAACEjEQtAAAAAAAAAISMRC0AAAAAAAAAhIxELQAAAAAAAACErMwlahctWmQDBgywevXqWdWqVa1Dhw42c+bM2Os33XST7bbbbla9enWrU6eOde/e3aZNmxbqNgMAAAAAAAAo3cpUonbFihXWpUsXq1ixor3xxhv29ddf25133ukSsr5ddtnFHnjgAfvqq69sypQp1rJlS+vRo4ctW7Ys1G0HAAAAAAAAUHpVsDJk1KhR1qxZMxs3blxsWqtWreLmOeWUU+Ke33XXXfboo4/al19+ad26dcvatgIAAAAAAAAoO8pUonbSpEnWs2dP69Onj3344Ye2/fbb2wUXXGBnn3120vk3bdpkY8eOtVq1atkee+yRcr0bN250D9+qVavc3/z8fPcoSVq/53kl/j7ILMotmii36KHMoolyi6ZslhvHBgAAAEqjMpWoXbBggY0ePdqGDh1q11xzjc2YMcMGDx5slSpVsoEDB8bme+211+zkk0+2devWWZMmTeztt9+2+vXrp1zvyJEjbfjw4QWmq7uEDRs2WElfqKxcudJdGJUrV6Z6sog0yi2aKLfoocyiiXKLpmyW2+rVq0t0/QAAAEAYKpS1C4hOnTrZiBEj3POOHTvanDlzbMyYMXGJ2kMPPdRmz55ty5cvt4cfftj69u3rBhRr2LBh0vUOGzbMJX+DNWrVxUKDBg2sZs2aJf6Z8vLy3HtxMRsdlFs0UW7RQ5lFE+UWTdkstypVqpTo+gEAAIAwlKlErWrHtm3bNm5amzZt7OWXX46bVr16ddt5553dY7/99rPWrVu7fmqVkE2mcuXK7pFIFynZuMDURVG23guZQ7lFE+UWPZRZNFFu0ZStcuO4AAAAQGlUpqLcLl262Ny5c+Omffvtt9aiRYsia4gE+6AFAAAAAAAAgEwqU4naIUOG2NSpU13XB/Pnz7dnnnnGDRZ24YUXutfXrl3r+q7VPD/88IN99tlndsYZZ9iiRYvcAGQAAAAAAAAAUBLKVNcHnTt3tgkTJrguDG6++WZr1aqV3XPPPda/f3/3evny5e2bb76xxx9/3PVPW69ePbfM5MmTrV27dmFvPgAAAAAAAIBSqkwlauWoo45yj1QDU4wfPz7r2wQAAAAAAACgbCtTXR8AAAAAAAAAQC4iUQsAAAAAAAAAISNRCwAAAAAAAAAhI1ELAAAAAAAAACEjUQsAAAAAAAAAISNRCwAAAJSwjz76yI4++mhr2rSp5eXl2cSJE1POe95557l57rnnniLX++CDD1rLli2tSpUqtu+++9r06dMzvOUAAADIFhK1AAAAQAlbu3at7bHHHi6xWpgJEybY1KlTXUK3KM8//7wNHTrUbrzxRps1a5Zbf8+ePW3p0qUZ3HIAAABkC4laAAAAoIT16tXL/vrXv1rv3r1TzrNo0SK7+OKL7emnn7aKFSsWuc677rrLzj77bBs0aJC1bdvWxowZY9WqVbN//OMfGd56AAAAZEOFrLwLAAAAgJTy8/Pt1FNPtSuuuMLatWtX5PybNm2yzz77zIYNGxabVq5cOevevbt9+umnKZfbuHGje/hWrVoVe389Sprew/O8rLwXModyix7KLJoot2ii3KIpP4vlVpz3IFELAAAAhGzUqFFWoUIFGzx4cFrzL1++3LZs2WKNGjWKm67n33zzTcrlRo4cacOHDy8wfdmyZbZhwwbLxoXKypUr3YWREsuIBsoteiizaKLcoolyi6b8LJbb6tWr056XRC0AAAAQItWMvffee10/sxpErCSpBq76tQ3WqG3WrJk1aNDAatasadm4KNJn1PtxMRsdlFv0UGbRRLlFE+UWTflZLDcN+pouErUAAABAiCZPnuwGAGvevHlsmmrLXnbZZXbPPffY999/X2CZ+vXrW/ny5W3JkiVx0/W8cePGKd+rcuXK7pFIFyjZurjURVE23w+ZQblFD2UWTZRbNFFu0ZSXpXIrzvo5ggAAAIAQqW/aL7/80mbPnh17NG3a1PVX+9ZbbyVdplKlSrb33nvbu+++G1czRM/333//LG49AAAAMoUatQAAAEAJW7Nmjc2fPz/2fOHChS4hW7duXVeTtl69enHzV6xY0dWM3XXXXWPTunXrZr1797aLLrrIPVcXBgMHDrROnTrZPvvs42rfrl271gYNGpTFTwYAAIBMIVELAAAAlLCZM2faoYceGnvu9xOrROtjjz2W1jq+++47N4iY76STTnKDgN1www22ePFi23PPPe3NN98sMMAYAAAAooFELQAAAFDCunbt6kYVTleyfmmTTVPtWr+GLQAAAKKNPmoBAAAAAAAAIGQkagEAAAAAAAAgZCRqAQAAAAAAACBkJGoBAAAAAAAAIGQkagEAAAAAAAAgZCRqAQAAAAAAACBkJGoBAAAAAAAAIGQkagEAAAAAAAAgZCRqAQAAAAAAACBkJGoBAAAAAAAAIGQkagEAAAAAAAAgZCRqAQAAAAAAACBkJGoBAAAAAAAAIGQkagEAAAAAAAAgZCRqAQAAAAAAACBkJGoBAAAAAAAAIGQkagEAAAAAAAAgZCRqAQAAAAAAACBkJGoBAAAAAAAAIGQkagEAAAAAAAAgZCRqAQAAAAAAACBkJGoBAAAAAAAAIGQkagEAAAAAAAAgZCRqAQAAAAAAACBkJGoBAAAAAAAAIGQkagEAAAAAAAAgZCRqAQAAAAAAACBkJGoBAAAAAAAAIGQkagEAAAAAAAAgZCRqAQAAAAAAACBkJGoBAAAAAAAAIGQkagEAAAAAAAAgZCRqAQAAAAAAACBkJGoBAAAAAAAAIGQkagEAAAAAAAAgZCRqAQAAAAAAACBkJGoBAAAAAAAAIGQVwt4AAAAAIFf88ccf9sknn9jXX39ty5cvt7y8PKtfv761adPG9t9/f6tTp07YmwgAAIBSikQtAAAAyrRNmzbZM888Y4899phNmTLF8vPzk85Xrlw569Kliw0aNMj69etnlStXzvq2AgAAoPSi6wMAAACUWWPGjLEdd9zRzjvvPKtZs6bdfffdLln7yy+/2Pr1623dunW2aNEiN+2uu+6yWrVquXl32mkne+ihh8LefAAAAJQi1KgFAABAmTVixAi7/PLLXS1ZJWGTadKkiXsccMABNnjwYFu1apX94x//sJEjR9q5556b9W0GAABA6USiFgAAAGXWggULrEKF4oXEqnl76aWX2kUXXVRi2wUAAICyp8x1faCmawMGDLB69epZ1apVrUOHDjZz5kz32p9//mlXXXWVm1a9enVr2rSpnXbaaa7pGwAAAEqf4iZpM7UsAAAAkKhMRZcrVqxwA0Aceuih9sYbb1iDBg1s3rx5sdF71QfZrFmz7Prrr7c99tjDzX/JJZfYMcccE0vmAgAAoGzVuH3uuefczf7GjRvbiSeeaG3atAl7swAAAFAKlalE7ahRo6xZs2Y2bty42LRWrVrF/q1+yd5+++24ZR544AHbZ5997Mcff7TmzZtndXsBAAAQnokTJ9pJJ51k+++/v2tp9cknn9jNN99sjz32mPXv3z/szQMAAEApU6YStZMmTbKePXtanz597MMPP7Ttt9/eLrjgAjv77LNTLrNy5UrLy8uz2rVrp5xn48aN7uHTABOSn5/vHiVJ6/c8r8TfB5lFuUUT5RY9lFk0UW7RlM1yy/R7aH3lyhXsEeymm26yMWPGuIHGfOedd55rfUWiFgAAAJlWoaw1XRs9erQNHTrUrrnmGpsxY4YbubdSpUo2cODAAvNv2LDB9Vnbr18/N2hEKhrxd/jw4QWmL1u2zK2jJOnCQslkXRglu8BAbqLcoolyix7KLJoot2jKZrmtXr06o+tTl1f33HOPdevWrcD77LjjjnHTWrZsaWvXrs3o+wMAAABlLlGrC4hOnTrZiBEj3POOHTvanDlzXE2JxEStBhbr27evu9hQcrcww4YNc8nfYI1adbGgPnALS/Bm6jOpxq/ei4vZ6KDcoolyix7KLJoot2jKZrlVqVIlo+tTjVn1Pdu1a1e76667Yl1jaVDZU045xc4991zX9cE333zj4kK1yAIAAAAyrUwlaps0aWJt27aNm6bBIF5++eWkSdoffvjB3nvvvSKTrZUrV3aPRLpIycYFpi6KsvVeyBzKLZoot+ihzKKJcoumbJVbptevG+4DBgxwLa7at29vF198sV133XV2ww03uK6yNJjYL7/8Yo0aNbLbbrvNdX8AAAAAZFqZStR26dLF5s6dGzft22+/tRYtWhRI0s6bN8/ef/99q1evXghbCgAAgGxq2LChPfLII6627CWXXGK77LKLa4V11llnuQcAAABQ0spUNZUhQ4bY1KlTXdA9f/58e+aZZ2zs2LF24YUXxpK0avY2c+ZMe/rpp23Lli22ePFi99i0aVPYmw8AAIASttdee9nkyZPtjjvucDVqO3fubJ9++mnYmwUAAIAyoEzVqFWgPWHCBNen7M033+z6H9PAEf6ovYsWLbJJkya5f++5555xy6p2rfotAwBga6jP882bN7ubgCi6r1PdPNWAnHR9UHbLrWLFila+fHnLljVr1riE7Lp161yyVn3T9u7d293g7969ux133HGu2wN1hQAAQFlEPJscsWs05Wew3BSzVqhQwXUDtq3KVKJWjjrqKPdIRqP46osHAIBMUquMX3/91SWAUDT9FitwWr16dUaCHUSz3LSOHXbYwWrUqGElTS2ulIjVtletWtX9HTVqlF166aV2yy232JlnnmmXX3657brrrnbllVe6R6YHNAMAIJcRz6ZG7BpNXobLrVq1am5srEqVKm3TespcohYAgGzSj//ChQvdXVaNGq8fbgK49GprZOquNKJXblrXsmXL7Oeff7bWrVuXeM1aDR7WqVMne/HFF12i9vbbb3fJWLW6atCggbuZ/9JLL7kWVupK69FHH3WDzgIAUBYQzxaO2LVsl5vnee5GhmJXnSeKXbelhi6JWgAASpB+tBXcNmvWzN1lRdEIdqMp0+WmBOn333/vmqSVdKJWg82effbZLkkrJ510kl111VUu2NZ2+A499FCbNWuWPfTQQyW6PQAA5BLi2cIRu0aTl8FyUwypbrt0I1/ny7a0vKLzDAAAsoD+qoDiyeaFzh577GFPPPGEG69g7dq1dt9997kLUXV1kOxcPv/887O2bQAA5AriWaDkzw9q1AIAAKBMGzt2rBs4rHnz5u55zZo17ZFHHrFatWqFvWkAAETWjyt/tOXrlqc9f/1q9a15rf/+FgNlFYlaAAAiYMOfW+z1r361f/17if2xbpPVrlbJerRrZEd0aGJVKpZss/Bt0bVrV9tzzz3tnnvucc/V16cGaNKjsLvR6iv0hBNO2OYamRMmTHCDRAGFadOmjX399dc2b948W79+ve2yyy407QQAYBuTtLs+sKtt2Lwh7WWqVKhicy+am1PJ2q2JZTMVgxLLlk3UWwcAIMe9/fUS22fEOzb0hS/sX18vtqkLf3d/9VzT3/l6Scbf8+ijj7bDDz886WuTJ092geOXX35Z7PXOmDHDzjnnHMukm266yQXQiTQyca9evawkPfbYY25fKNGXSMlmvaaAPpGSgXXr1rX69evbxo0bC7yuZbRs4uPWW28tsc9S1ukGgbo60LFEkhYAgG2jmrTFSdKK5i9ODdzCEMvmTixbvXp122uvvdz6gp85Way72267WVlHohYAgBxP0p7z5ExbvX6ze57vWdxfTT/7yZluvkw688wz7e2337aff/65wGvjxo2zTp062e67717s9WpgpmwlwRo3bmyVK1cu8fdR8Ll06VL79NNP46Y/+uijsab0iV5++WVr166dC0YnTpyYdJ6bb77ZBejBx8UXX1win6Ese/bZZ91gEsWlZbQsAADIPcSyuRPLfv7559a5c2c3WOsnn3wSe13LJ8a6U6ZMsbIu0olaZfB//PHHsDcDAIAS6+7gshdnm3nuv6TcdM/s8hdnu/kz5aijjnKBqO6yB61Zs8bdDVfw+9tvv1m/fv1s++23dwFrhw4dikxc6e6633RM1NT84IMPdiOjtm3b1gXUia666qpYU/Qdd9zRrr/+evvzzz/da9q+4cOH2xdffBG7E+9vs/4dDBy/+uorO+yww9yorPXq1XO1IfR5fKeffrprWnbHHXdYkyZN3DwXXnhh7L1S0Uixp5xyiv3jH/+ITdNFwQcffOCmJ6PAd8CAAe6hfyez3XbbuQA9+FAgjcxS00UdX7fddpstXLiwyPnnz59vI0aMsJ133tmGDBmSlW0EAAC5G8secsghLm5T4pFYtmAsq8/+4IMPuu1+9dVX4943MdatX7++lXU5l6jVgfv888/Hnq9evdqOOOKIpFXSx48fb61atcryFgIAkB3qk3bV+s0pk7Q+vb5y/WZ7Y86vGXtvBU6nnXaaCxSDtQ0V2G7ZssUFtRs2bLC9997b/vnPf9qcOXNcsHjqqafa9OnT03qP/Px8O/74461SpUo2bdo0GzNmjAtkkwV52g71IXrvvffaww8/bHfffbd7TXfmL7vssrg78pqWaO3atdazZ0+rU6eOa7Kmz/HOO+/YRRddFDff+++/b9999537+/jjj7v3TQzwkznjjDPshRdesHXr1rnnWkbN7Ro1alRgXq1fNRb69u3rHmp+98MPP6S1z5B5CxYscBc2d955p0u+7rTTTtanTx+78sorbeTIkS4pe8UVV9iJJ57oLs7UPYIu0AYNGuTKEgAA5J5sx7KqCTp69Ghi2ULKo2LFirZp06Yit6Wsy7nBxHSi6KTxqRDffPNNu/zyy0PdLgAAMuno+6fYstUF+3MKWrGueIHM1S9/ZaPemFvoPA22q2yvXnxgWutTwHb77bfbhx9+6AZS8JuKaZCvWrVquUfw91nN8t966y0X5O2zzz5Frl/B5TfffOOWadq0qZumpFhiX1zXXXdd7N9KlOk9n3vuOZdI0535GjVqxO7Ip/LMM8+4GOOJJ56I1Up94IEHXP9lo0aNigWhCn41vXz58q4p15FHHmnvvvuunX322YV+lo4dO7oaEi+99JIL8BXc3nXXXS4JmEi1FfQZ9V6ioFv7VX11BSnQD352eeONN+yggw4qdFtQPDoerr32Wre/VcvjlVdecc3yVCHAv7BTjRYlcFVj5thjj3XHjS42AAAoqzqN7WSL1yxO+fqmLVuXkDv8qcOtUvlKKV9vXKOxzTxnZk7FsspZNWzY0MWjxLIFKa+nG+IrV650NYKDNYT12YMGDBjgKm+UZTmXqAUAoCxQknbxquINsFCUjZvzM7pOBXcHHHCAC8YU3KrJt+6Yq78p0Y1VBaMKZhctWuSCMA0mkG6/Xf/5z3+sWbNmsSSt7L///gXmU0ub++67z929V/OuzZs3W82aNYv1WfRee+yxR1zXAV26dHE1IebOnRsLblWbQYGtT83GFESmezGgIFV9eanWg1oEKVAO0j5T7QbVpggGpArYb7jhBjeglU+1OFXTM0hN81AydIHUu3dv9/DL6vfff3f/1mAZweMCAICyTknaRasXZXy9y9Yti2Qsq/hUiGXLFah0oASzErIaFFeJY59aKU2aNClu/TWLuV9KIxK1AACEQDVbi6IatUq+pqtyhXJWp1qlbX7fIPXfpdoF6ldKgZtfq1BUQ0FBmpqBq08vBY7q7zOTTZrUrKp///6u7y7drVfNB9VA0F35kpBYS1I1KRUAp0PbqZoRqk2gmghK/CVSLQ1dCCQ2aVPQq9oOf/nLX2LT1EeXmuIjHLrIUd92AAAgec3WwqhG7dYkXRtUa1BkjdriIJYNL5b1Kx0oSatEsrYlSF1GEOsWRKIWAIAQpNP9wPhZP9vQF75Ie523ntDBenfcwTJJ/U5dcsklrrmVmlqdf/75sSDr448/ds3AdRddFAR+++23blCwdLRp08Z++ukn1xeX7vbL1KlT4+ZRE/QWLVq4pum+xD6wFOQFu01K9V5qwqXaAX5NBG2/7vrrbn4mqNblMccc42plpGqypcEWTj755LjPI3/729/ca8HgFgAAIFcV1f3ArF9n2d5j9y72et8c8Kbt1WQvi1os69/cJZal0kGpG0xMErPsqaYBAFCaHdGhidWsWsGK+gXU67WqVrBe7f+b7Mwk3QHXHfNhw4a5IDTYFL9169ZuZFsFoGqOde6559qSJUvSXnf37t3dKLADBw50I92qKVpi0Kf3+PHHH13NAzUXU7OxCRMmxM2jvr4WLlxos2fPtuXLl7sma8lqCFSpUsW9lwaL0AALql2h2gLJBknYWgqgtQ1qapdo2bJlrg9UbUP79u3jHhrsQqP6+k3t/QFVFy9eHPdYtWpVxrYVAACgtMtGLKt1EssWjGWLoi4gEmPdJcXY/6VVTiZqVTVd/VLo0apVKzftqKOOik3zH0V1hgwAQJRVqVje7uqzp8vEpkrWuul5Znf22dPNX1K/yytWrHDNtYL9yarPqb322stNV79fGgDhuOOOS3u9qgGgQHX9+vVuwIazzjrL3Y0P0l39IUOGuBFt99xzTxdIX3/99XHzaEAIjUp76KGHutoMzz77bIH3Ul9jaqql4LFz58524oknWrdu3Qr0u7WtNCBEvXr1kr7mD/6g902kaVr2qaeeik1TP1+qaRx8qDkaAAAAciuWVX+xylERy/5/LFuUf//73wVi3RYtWlhZl+f5w9nmiEGDBhV7GfUzkktU20X9jmhEu5LuCFlV85cuXepGGAx22ozcRrlFE+UWPblQZuo8X3fIdeNRd8G3xttfL7HLX5xtK9dvtnJ5Zvmexf6qJq2StN3bZu5OetgUmugOu/rFokVN2S23ws6dbMZamfLRRx+5vvA+++wzV6NHF3bBi0H1B6faNmpCqSaQe++9t7vY23fffVOuU80ktZwuilQLRRefqtWjC890yyDb+zIXvpdRfJRb9FBm0ZSr5bY18ezWdn3w2TmfZbTrg2wgdo0mL0dj15zrozbXkq4AAITtL20b2bRrutsbc361t+YssT/Wb7LaVStZz/aNXHcHJVWTFkDmqE85jdasEZWPP/74Aq+r6aRqxey4446uZs7dd99tPXr0cCNUpxrUbNSoUTZ69Gg3+rJGeZ45c6ar9KALgcGDB2fhUwEAkFz9avWtSoUqtmHzhrSX0fxaDijLci5RWxzqN0M1D1SFHACA0kzJWA0UlunBwgCYq71Uu3ZtV5O1KOqfTf3YHXzwwcV6j169erlHKqecckrc87vuussNyvHll18mbWIoaj6pQVCOPPLIWB93ai45ffr0Ym0bAACZ1rxWc5t70Vxbvm552ssoSavlgLIsconadevWuQ6Kn376aXvnnXdcNWUStQAAANha6hPtySefjCVL1Sxt//33dy29Erse+Ne//uUGzChqdOZtsWnTJhs7dqyrGatauKkccMABbj6NUK0auRrIZMqUKS7JCwBA2JR0JfEKlMJErfppUafJSs6+8sorLlm78847uyZdRx99dNibBwAAgAhLHLJBFQG++eYb111BNr322mt28sknu1hXyWONRF2/fuomoFdffbXr80wjM5cvX94lj9WvrUaGTkUjSQdHk9byfrytR0nTe2h/Z+O9kDmUW/RQZtGUq+Xmb5f/QEH+fmH/lN1y8/53fiSLqYpzTud0onbq1KkuOfvCCy+4bg40+psCV9Uc0Kh9AAAAQGmh0Z5nz57t4t6HH37Y+vbta9OmTXODyiSjGFmx8jPPPOP6qNWyl156qRtUbODAgUmXGTlypA0fPjxplw4aBKOk6UJFNZZ1IZNLA+WgcJRb9FBm0ZSr5fbnn3+6bdONTD0QT+Xlt7RhMLGyW26bN29258lvv/1mFStWjHtt9erV0U3Uzp07NxZwLliwwHbaaSc7++yzrV+/fla5cmXXrKtOnTphbyYAAACQUdWrV3etxvTYb7/9rHXr1q6f2mHDhiWd/4orrnC1alULVzp06GA//PCDS8amStRqXUOHDo2rUdusWTM3YFlRoxBngi5gdDGk98ulJAQKR7lFD2UWTblabrqRp0RThQoV3APJJSbnULbKrUKFCu68rVevnlWpUiXutcTnha7Hckzbtm2tcePGLjF70kknWefOnWOvfffdd6FuGwAAAJDNC/ZgNwWJ1NIs8UJeXSAU1rxOFR/0SKT1ZCspoCRENt8PmUG5RQ9lFk25WG7aFm2X/0DBmpn+fmH/lN1yy/vf+ZHs/C3O+VwhFzPZK1ascLUBfvrpJ9t9992TBpMAAABApqg/2t9//9392/+r2kP+v31r1qzZqvVrufnz58eeL1y40HVVULduXVfzQn3LHnPMMa5vWnV98OCDD9qiRYusT58+sWW6detmvXv3jg2kq7EatFzz5s1d1weff/65G0jsjDPO2KptBAAAQLhyLlG7ZMkSe/HFF+2pp55ygWmNGjXs2GOPdaPwtmzZMuzNAwAAQCl03nnnuUfQ8ccfX2jti+KYOXOm64PW53c/oC4KxowZ4wYve/zxx12SVolbtSqbPHmyS8AGW5fpdd/9999v119/vV1wwQW2dOlS1zftueeeazfccEOxtw8AAADhy7lEba1ateyss85yD9WoVV+1eihxq6StAmMFsps2bbJKlSqFvbkAAKCUU+wxYcIEO+644+z777+3Vq1auZqLe+65Z9ibhgy58cYbS/w9unbtWuiIwuPHjy9yHTr+grbbbju755573AMAACAZYtloyZ1OT5LQwAZXXXWVffHFF65pmGo5bL/99nbddddZ/fr17YQTTnA1DwAAQOadfvrpLqBLRS1dUiWIFAQqKFR/mWq+HfTrr7+6zvb1emLiKUi1D4P9oTVq1Mi1tlH3SGHGJtr+9u3bZ/29legL7g89EmuAzpgxwzWPr127tht8tWfPni6OKoxqaao5vT+YVN++fV0Lp6Bvv/3WtXBS/KV5DjzwQHv//ffj5nn33Xft4IMPdq9rvAHFcMGRof1jIvExdepUy4VEbXEfAAAgt4UdyybGbmU9lh07dqzbJ4oVtT/++OOPAvMcc8wxrksnDb6l7qBOPfVU++WXXwpdr1oT7bTTTla1alUXzypmVQXPZH777TfbYYcdCry/EtcdO3Z0FUTVtVSw6yvFs3vvvbdNnz7drKwnaoPUV+1tt91mP/74o7333nvuIkIXCPTBBQBA7tIN1ieeeCJumm6yano6zj77bBdMKkB75ZVXXGubAQMGWFgUrCsJGdaIx/7+8B+KjYJ9oB5++OEuuJ02bZpNmTLF1bhUsvbPP/9M2S9rjx49XLCq+Orjjz92rZYUoAYHpDrqqKNckKp5PvvsM9tjjz3ctMWLF7vXlQw+8sgj3bpmzZplzz//vE2aNMmuvvrqAu/5zjvvxH0GBb65Qp9HieN58+aFvSkAACAHEMtmjgZBVax6zTXXFFpR44UXXrC5c+fayy+/7CoUnHjiiYWuV7HkuHHj7D//+Y+99dZbrgWTYtItW7YUmPfMM890+cVEatV/2GGHuTh25cqVNmLEiNhrd955p3Xp0sX22Wcfy4bIJGqDlIF/5JFHXDD90ksvhb05AAAgBfW/qcApSM81PR3VqlVzwaTuqO+3335uECUFUD4FYAq41IRLd9F33XVXu/fee+PW8cEHH7jAqnr16q6mqQKtYE0GBc177bWXu3O/44472vDhw+NqgiarXaGWPv669Vy1STt16uS294ADDnDBZVBx3iOd/eE/VCPBp5oDuvt/8803u/2gvk1V81O1Y1PV3FBiVp/psccesw4dOriHLj7Un6qSsqI+UZW4VNJVgW3r1q3t1ltvdcH2nDlz3DxKzOo1tXraeeed7ZBDDnFJZA2IpQG5gtT/avAzaCDZsCk5rfEQdNGl42O33XZz5VVYLRkAAFD6EcsW/z1SufTSS108qf2QypAhQ9zrLVq0cNuh+XUTPVWlAznnnHNcqy7VkNY2/vWvf3UJ8cQ4bvTo0a4W7eWXX15gHUryKqm+yy67WL9+/dxzWbBggT366KNu8NZsyblErao5p/tQVl0XFgAAIDfp93rFihWudqfor56rxmZxKQmpO+z77rtvbJpqfar5kgYi/frrr90gSrpLr/lEAaSavClx+OWXX9qnn37qgjl/MCgN1nTaaafZJZdc4pZ/6KGHXGxR3GDs2muvdXfbleBUDYVgi5903kNN83QjuihPP/20635AzdWGDRvmkqU+BfZKgiqYVOJx/fr17t9t2rRJOSDrxo0b3b6oXLlybJoC8HLlysXKTOvUulWbRDVwtU/1GRo2bBirDav1aLkgXWxs2LDB1cBNPCa0rLpPUK3bXPDAAw/Yc8895z7PZZdd5prMqZawyg0AAJRdxLKZjWWLu7+efvppl7BN98a+YlUl0pX4VjcPPm23KjMonlWcm0itxd5++223v5W09mvdqpsxVT5QK7Ws8XJMXl6eV7VqVa9Vq1Zey5Yti3xovlyzcuVKjRTh/pa0LVu2eL/++qv7i+ig3KKJcoueXCiz9evXe19//bX7W8Cdd3re9tsX/Tj66ILLalo6y+o9ttLAgQO9Y489NuXrLVq08O6+++6kry1cuND9Fn7++efepZde6g0aNMhN198hQ4a46Xpd8yXKz8/3Nm3a5B1yyCFexYoVverVq3vVqlVz8++yyy5Jlwm68MILvRNOOMH9+7fffnPLffDBB0nn7datmzdixIi4aU8++aTXpEmT2HMtP2HChAKfS95//333/J133onN/89//tNN88s8nfe4+uqrvVNPPbXQz/XQQw95b775pvfll196Tz31lLf99tt7vXv3jpvnq6++8nbaaSevXLly7rHrrrt633//fcp1Ll261KtZs6Z3ySWXeGvXrvXWrFnjXXTRRW77zznnnNh8P/30k7f33nu7OK18+fJu22fNmhV7/a233nLv98QTT3h//vmn9/PPP3sHHXSQW88zzzzj5lm2bJl35513elOnTvWmT5/uXXXVVW59r7zySrHPnUzHWnvssYd32GGHuWPPpzLTZ1q0aJFXmmUzbs2V72UUH+UWPZRZNOVquaX8TSaWdfP5sWswjhBi2eT891yxYkXS16+88srY/tpvv/285cuXF7nOBx980O1nLaP4d/78+bHXNmzY4O2+++5um4Pv//vvv8fKbc6cOd7BBx/sNW/e3OvXr5+LixTX6vhRXNujRw8XY1977bUptyFTsWvOJWp32GEHF7R37tzZnTD6kooaErUoCuUWTZRb9OR8ovbGGxU5Ff3Yb7+Cy2paOsvqPUIObpVYrFGjhisL/VUyMd1E7emnn+7NmzfPPaZMmeIdccQRXuvWrb1Vq1bF5n/ggQe8vfbay6tfv74L0BQQK47waR2VK1f2jjrqKO+ee+7xfvnll9hrWqZKlSpuOf+h59o2JS7TDW6V8PQpgalpP/zwQ9rvsTXeffddtw4/EF23bp23zz77eKeddppLhH766acuyG/Xrp17LRUlWXfcccdYEnbAgAFuf5533nmx8jjmmGO8Xr16uTL47LPPvPPPP98lioP78o477nBJX61DwfXIkSPd9j333HMp31sB/YEHHhh6olbbrQA/6LvvvnP7RJ+5NCNRi3RQbtFDmUVTrpZbyt9kYtkiE7XEssVP1C5btsybO3eu969//cvr0qWL22eJ+zbRH3/84X377bfehx9+6B199NFuf/rHqxLrJ510UoH3DyZqEyk5rIqhqqygihE33XSTq9DQpk0bb9KkSSUau4YzEkYh1I/Ehx9+aM8884zdcsstdsUVV7gq3v3793ddHWS1ujEAACVJ/YumMxBBgwbJp6WzbKAP07Co31P1+an+ntQMX832/X6xilKrVi3X56nor5ryq48v9YmqTv/VXF39TKmp1v777+/ihNtvv90NpuVT86fBgwfbm2++6ZZTP6pq2qT+rzQAl/rYOv744wu8d2JT/sIEm2P5TdH8wbgy9R6J/GZz8+fPdyPdKnZSX1xqEuc36dK0OnXquH7FTj755KTr0WALGqhBfdGqqZv6PlNfaup/TNRX7Wuvveaa+fl94v797393+1D92foDhg0dOtQuvvhiW7ZsmdWtW9dti7pn8NeT6jNoPWFTP7r63InHnt+tAwAASIJYtkjEssVXv35991B/sdrf6sJA/dRq/xS2n/XQWAraL4p/J0yY4MpMsexXX30VG+Pqv7lrHYINXByr3GMixbXqU1fdUqgfX/V7qz6CNXiunm9N1xfpyrlErSgxq4f6C3v99dfdRYY6XL7gggusV69ebrAH7ZRgf2oAAETO0KH/fWyNHOnbM13q50q/4+rEf1tHqhX1v+oPhqV+q7Run5KOiTp27OgeShwqyFNsoSBOAw5osAQ/gC4JJfUe/gWCgn1Rf7VK0PrBtfjP/UC7MAqIRcHs0qVLXZ9s/nr9dQXpeeJ69V5NmzZ1f5999lkXWOvzF/YZ/O0PW3C/pTMdAIAyj1i22Ihliyf/f7FmcW6c/6/3gNgyL7/8cmx/y4wZM1x5fvTRR27QskTqo1aDifmDyGnAN38ws8IGNSvVidpgRl+DOeihDP748eNtzJgxdtJJJ9lNN91k119/fdibCABAqbZy5coCNQY0uJTfOf+iRYsKvJ4s4NEoqn369ClQa7EoShIuXrzY/XvJkiXujrfu3KsWqOiuuQYFeOutt9ygAU8++aQLvvRvWbhwoY0dO9YlHZVAVJA5b9682CBRGrDhqKOOsubNm7uWO0o+ahCpOXPmuDvnmZDOeyjo1r7UZ0lGAbsC8iOOOMLtfw0moVFxNcKtP9jBX/7yF9cS6cILL3Q1WxXY3nrrra6W7KGHHurm0Xt069bNvY9GDxYFoaqtoFoFqo2rgSK0bg0gJroYUK0EjW6sz6JBwh5++GG3b1WrwKfaH927d7dKlSq5Ggx6bw2E4V+QqPatXtNFhiiu+8c//mGPPPKI5QKNuHzuuecWmK6y8z9DMHmrcwMAAOQ2YtnciGVF+0EPtQYT1XJVDWKtV62xVIt4xowZbsBZxZ6Kf5X3U8sxvzZtYiy7YMECV8tY+1Ox7M8//+xiUMWriptFywepFZko/q1Ro0bcaxoIVxVFVeHAr6TQpUsXe/DBB12MraTvXXfdZWU2UetTFlwHrZrtff755+6gTjV6MQAAyBw17fETa8GElp9cu+OOO9wjSAGmAqwgJQv9GpvFoYSgHqKATUlJtbbxk4hKrCk20E1cJc/UvEk1Et544w33erVq1eybb75xScLffvvN1d5UkOUn5Hr27Oma9WsU2FGjRrmbxGrapqZomZLOe/z666/2448/plyHEpzvvPOO3XPPPW40W11cnHDCCa7pm0/rfPXVV13TNAWzCi5Vdmom59daVS0ABfh+LVnRcwXXGllX8ZVG/VWi1qdy0zo0/bDDDnPraNeunYvLNEKuT/OMGDHCxW2artfVEipIFyc//PCDOx60vQqsFfCHTUloAABQ+hDL5kYsK6p4qTjVpwoHfqWB008/3X3W8ePH24033ujiXX3Www8/3MW7fov6xFhW+cHJkye7GFnddDVq1Mit95NPPrGGDRsW+7Nq+1QRYc8994xNu++++1zLfq1X3bIqBi9Jeeqo1nKQaoGozw1lsSdOnOgKQbU0tHN69+7t+obIVatWrXJ9Y+jOjd+XW0nuJzVP1AGY2CQRuYtyiybKLXpyocx0V1Z3wnVXvCT6cCqNFJps3rzZBcQ0Oy+75VbYuZPNWKu0y/a+zIXvZRQf5RY9lFk05Wq5Ec8Wjtg1mrwcjV1zrkatst5q2vfiiy+6uwXqc0O1M/r27btVdy8AAACATFFzOQ38oWZxAAAAQCblXKJW1cv9viRU5dvv4kBVqFNVoy5skAoAAABgW6hll1p4Pf30064LCtW+IFELAACAUp+oFY3Gpg561TdFUdWUVT1ZI7ABAAAAmWx+qjESlJxVf7tK1mq048GDB9vRRx8d9uYBAACgFMq5RK06EQYAAADCMHXqVJecfeGFF1w3Bxr5WUlajbiswUcAAACAMpOoZdRdAAAAZJNGD1ZyVuMkLFiwwHbaaSc7++yzXTdcGmV4l112cSM1AwAAAGUqUQsAQGmk7noA5OY507ZtW2vcuLFLzJ500knWuXPn2Gvfffdd1rYDAIBcRjwLlPz5US4jawEAAElVrFjR/VXTaQDp27Rpk/tbvnz5rJynK1assB9++MF++ukn27hxY4m/JwAAUUE8CxTNPz/882VrUaMWAIASpCRT7dq1benSpe55tWrV3ECYKPxu9ObNm61ChQrsqzJabhrIa9myZe580fpK2pIlS+zFF1+0p556yvr06WM1atSwY4891k455RRr2bJlib8/AAC5jHi2cMSuZbvcPM9zSVqdHzpPtrWSAYlaAABKmJpUix/couhgR4m6cuXKEeyW4XLTepo3b56VY6BWrVp21llnuYdq1KqvWj2UuFXSVtvwzTffuFq+lSpVKvHtAQAg1xDPpkbsGk1ehstNSVr/PNkWJGoBAChh+uFv0qSJNWzY0P7888+wNyfnKWD67bffrF69ei5wQtksNyVEwyj/Zs2a2VVXXeUeX375pUvWPvfcc3bdddfZrbfean/5y1/smGOOYQBcAECZQjybGrFrNOVnsNzU3UGmuusiUQsAQJboxzsb/W2WhqBJwU6VKlUIdiOkNJbb7rvvbrfddpt7fPDBBy5pO378eJs4cSKJWgBAmUQ8WzZioLIgP0fLLXe2BAAAAMhRXbt2tUceecQWL15sL730UtibAwAAgFKIRC0AAABQjC4ZevfuHfZmAAAAoBSi6wMAAACUaepztrj99L3yyisltj0AAAAom0jUAgAAoEx77bXXXP9kGqlXIwAXhRGdAQAAUBJI1AIAAKBM23777W3RokVWv359O+WUU+zkk092SVsAAAAgm+ijFgAAAGXaTz/9ZO+//7517NjRbrnlFmvWrJl1797dxo0bZ6tXrw578wAAAFBGkKgFAABAmXfIIYfYQw89ZIsXL7aXXnrJ6tWrZxdddJE1bNjQjj/+eDdt48aNYW8mAAAASjEStQAAAMD/VKxY0Y499lh7/vnnbcmSJbHk7UknnWS33XZb2JsHAACAUoxELQAAAJBAtWffeuste+WVV+zzzz93g421bNky7M0CAABAKUaiFgAAADCz/Px8l5w9/fTTrVGjRtavXz9bv369Pfzww7Z06VI79dRTw95EAAAAlGJlLlGrEX0HDBjg+h2rWrWqdejQwWbOnBl7ffz48dajRw/3el5ens2ePTvU7QUAAEDJ+uSTT1x/tE2aNLEjjzzS5s+fbyNGjLBffvnFXn/9dRc7Vq9ePezNBAAAQClXwcqQFStWWJcuXezQQw+1N954wxo0aGDz5s2zOnXqxOZZu3atHXjggda3b187++yzQ91eAAAAlDzFfrqBf8QRR7hatH4XBz/++KN7JLPXXntleSsBAABQ2pWpRO2oUaOsWbNmNm7cuNi0Vq1axc3jN2n7/vvvs759AAAACIe6OHj55Zdd66rCeJ7nWl1t2bIla9sGAACAsqFMJWonTZpkPXv2tD59+tiHH35o22+/vV1wwQXUnAUAACjDgjfxAQAAgLCUqUTtggULbPTo0TZ06FC75pprbMaMGTZ48GCrVKmSDRw4cJtGBdbDt2rVqtiAFHqUJK1fNTtK+n2QWZRbNFFu0UOZRRPlFk3ZLLdMv8e2xIEAAABAppSpRK2C+k6dOrnBIaRjx442Z84cGzNmzDYF6CNHjrThw4cXmL5s2TLbsGGDlfRnWrlypbswKleuzI0NF1mUWzRRbtFDmUUT5RZN2Sy31atXl+j6AQAAgDCUqUStRvJt27Zt3LQ2bdq4/si2xbBhw1wt3WCNWvWFq8HKatasaSV9UaR+0vReXMxGB+UWTZRb9FBm0US5RVM2y61KlSolun4AAAAgDGUqUdulSxebO3du3LRvv/3WWrRosU3rrVy5snsk0kVKNi4wdVGUrfdC5lBu0US5RQ9lFk2UWzRlq9w4LgAAAFAalalE7ZAhQ+yAAw5wXR/07dvXpk+fbmPHjnUP3++//24//vij/fLLL+65n9ht3LixewAAAAAAAABAppWp6gidO3e2CRMm2LPPPmvt27e3W265xe655x7r379/bJ5Jkya5vmuPPPJI9/zkk092z9WPLQAAAAAAAACUhDJVo1aOOuoo90jl9NNPdw8AAAAAAAAAyJYyVaMWAAAAAAAAAHIRiVoAAAAAAAAACBmJWgAAAAAAAAAIGYlaAAAAAAAAAAgZiVoAAAAAAAAACBmJWgAAAAAAAAAIGYlaAAAAAAAAAAgZiVoAAAAAAAAACBmJWgAAAAAAAAAIGYlaAAAAAAAAAAgZiVoAAAAAAAAACBmJWgAAAAAAAAAIGYlaAAAAAAAAAAgZiVoAAAAAAAAACBmJWgAAAAAAAAAIGYlaAAAAAAAAAAgZiVoAAAAAAAAACBmJWgAAAAAAAAAIGYlaAAAAAAAAAAgZiVoAAAAAAAAACBmJWgAAAAAAAAAIGYlaAAAAAAAAAAgZiVoAAAAAAAAACBmJWgAAAAAAAAAIGYlaAAAAAAAAAAgZiVoAAAAAAAAACBmJWgAAAKCEffTRR3b00Udb06ZNLS8vzyZOnBj3+k033WS77babVa9e3erUqWPdu3e3adOmFbneRYsW2YABA6xevXpWtWpV69Chg82cObMEPwkAAABKColaAAAAoIStXbvW9thjD3vwwQeTvr7LLrvYAw88YF999ZVNmTLFWrZsaT169LBly5alXOeKFSusS5cuVrFiRXvjjTfs66+/tjvvvNMlegEAABA9FcLeAAAAAKC069Wrl3ukcsopp8Q9v+uuu+zRRx+1L7/80rp165Z0mVGjRlmzZs1s3LhxsWmtWrXK4FYDAAAgm0jUAgAAADlk06ZNNnbsWKtVq5arhZvKpEmTrGfPntanTx/78MMPbfvtt7cLLrjAzj777JTLbNy40T18q1atcn/z8/Pdo6TpPTzPy8p7IXMot+ihzKKJcosmyi2a8rNYbsV5DxK1AAAAQA547bXX7OSTT7Z169ZZkyZN7O2337b69eunnH/BggU2evRoGzp0qF1zzTU2Y8YMGzx4sFWqVMkGDhyYdJmRI0fa8OHDC0xXFwsbNmywbFyorFy50l0YlStHL2xRQblFD2UWTZRbNFFu0ZSfxXJbvXp12vOSqAUAAABywKGHHmqzZ8+25cuX28MPP2x9+/Z1A4o1bNgw5QVGp06dbMSIEe55x44dbc6cOTZmzJiUidphw4a5xG6wRq26T2jQoIHVrFmzhD5Z/DZrMDW9Hxez0UG5RQ9lFk2UWzRRbtGUn8Vyq1KlStrzkqgFAAAAckD16tVt5513do/99tvPWrdu7fqpVXI1GdW6bdu2bdy0Nm3a2Msvv5zyPSpXruweiXSBkq2LS10UZfP9kBmUW/RQZtFEuUUT5RZNeVkqt+KsnyMIAAAAyNGaHsH+ZBN16dLF5s6dGzft22+/tRYtWmRh6wAAAJBpJGoBAACAErZmzRrXrYEesnDhQvfvH3/80dauXev6mJ06dar98MMP9tlnn9kZZ5xhixYtcgOF+bp162YPPPBA7PmQIUPcMur6YP78+fbMM8+4QcguvPDCUD4jAAAAtg1dHwAAAAAlbObMma4PWp/fT6z6klWfst988409/vjjrn/aevXqWefOnW3y5MnWrl272DLfffede92neSZMmOC6Rrj55putVatWds8991j//v2z/OkAAACQCSRqAQAAgBLWtWtXN6pwKuPHjy9yHd9//32BaUcddZR7AAAAIPro+gAAAAAAAAAAQkaiFgAAAAAAAABCRqIWAAAAAAAAAEJGohYAAAAAAAAAQkaiFgAAAAAAAABCRqIWAAAAAAAAAEJGohYAAAAAAAAAQkaiFgAAAAAAAABCRqIWAAAAAAAAAEJGohYAAAAAAAAAQkaiFgAAAAAAAABCRqIWAAAAAAAAAEJGohYAAAAAAAAAQkaiFgAAAAAAAABCRqIWAAAAAAAAAEJGohYAAAAAAAAAQkaiFgAAAAAAAABCRqIWAAAAAAAAAEJGohYAAAAAAAAAQkaiFgAAAAAAAABCRqIWAAAAAAAAAEJW5hK1ixYtsgEDBli9evWsatWq1qFDB5s5c2bsdc/z7IYbbrAmTZq417t3727z5s0LdZsBAAAAAAAAlG5lKlG7YsUK69Kli1WsWNHeeOMN+/rrr+3OO++0OnXqxOa57bbb7L777rMxY8bYtGnTrHr16tazZ0/bsGFDqNsOAAAAAAAAoPSqYGXIqFGjrFmzZjZu3LjYtFatWsXVpr3nnnvsuuuus2OPPdZNe+KJJ6xRo0Y2ceJEO/nkk0PZbgAAAAAAAAClW5mqUTtp0iTr1KmT9enTxxo2bGgdO3a0hx9+OPb6woULbfHixa67A1+tWrVs3333tU8//TSkrQYAAAAAAABQ2pWpGrULFiyw0aNH29ChQ+2aa66xGTNm2ODBg61SpUo2cOBAl6QV1aAN0nP/tWQ2btzoHr5Vq1a5v/n5+e5RkrR+1QQu6fdBZlFu0US5RQ9lFk2UWzRls9w4NgAAAFAalalErYJ61agdMWKEe64atXPmzHH90SpRu7VGjhxpw4cPLzB92bJlJd63rT7TypUr3YVRuXJlqoJ0pFFu0US5RQ9lFk2UWzRls9xWr15dousHAAAAwlCmErVNmjSxtm3bxk1r06aNvfzyy+7fjRs3dn+XLFni5vXp+Z577plyvcOGDXO1dIM1atUXboMGDaxmzZpW0hdFeXl57r24mI0Oyi2aKLfoocyiiXKLpmyWW5UqVUp0/QAAAEAYylSitkuXLjZ37ty4ad9++621aNEiNrCYkrXvvvtuLDGrpOu0adPs/PPPT7neypUru0ciXaRk4wJTF0XZei9kDuUWTZRb9FBm0US5RVO2yo3jAgAAAKVRmUrUDhkyxA444ADX9UHfvn1t+vTpNnbsWPfwLy4uvfRS++tf/2qtW7d2idvrr7/emjZtascdd1zYmw8AAAAAAACglCpTidrOnTvbhAkTXFcFN998s0vE3nPPPda/f//YPFdeeaWtXbvWzjnnHPvjjz/swAMPtDfffJMmdgAAAAAAAABKTJlK1MpRRx3lHqmoVq2SuHoAAAAAAAAAQDbQwRcAAAAAAAAAhIxELQAAAAAAAACEjEQtAAAAAAAAAISMRC0AAAAAAAAAhIxELQAAAAAAAACEjEQtAAAAAAAAAISMRC0AAAAAAAAAhIxELQAAAAAAAACEjEQtAAAAAAAAAISMRC0AAAAAAAAAhIxELQAAAAAAAACEjEQtAAAAAAAAAISMRC0AAAAAAAAAhIxELQAAAAAAAACEjEQtAAAAAAAAAISMRC0AAAAAAAAAhIxELQAAAAAAAACEjEQtAAAAAAAAAISMRC0AAAAAAAAAhIxELQAAAAAAAACEjEQtAAAAAAAAAISMRC0AAAAAAAAAhIxELQAAAAAAAACEjEQtAAAAAAAAAISMRC0AAAAAAAAAhIxELQAAAAAAAACEjEQtAAAAAAAAAISMRC0AAAAAAAAAhIxELQAAAAAAAACEjEQtAAAAAAAAAISMRC0AAAAAAAAAhIxELQAAAAAAAACEjEQtAAAAAAAAAISMRC0AAAAAAAAAhIxELQAAAAAAAACEjEQtAAAAAAAAAISMRC0AAABQwj766CM7+uijrWnTppaXl2cTJ06Me/2mm26y3XbbzapXr2516tSx7t2727Rp09Je/6233urWe+mll5bA1gMAACAbSNQCAAAAJWzt2rW2xx572IMPPpj09V122cUeeOAB++qrr2zKlCnWsmVL69Gjhy1btqzIdc+YMcMeeugh23333UtgywEAAJAtFbL2TgAAAEAZ1atXL/dI5ZRTTol7ftddd9mjjz5qX375pXXr1i3lcmvWrLH+/fvbww8/bH/9618zus0AAADILmrUAgAAADlk06ZNNnbsWKtVq5arhVuYCy+80I488kjXVQIAAACijRq1AAAAQA547bXX7OSTT7Z169ZZkyZN7O2337b69eunnP+5556zWbNmua4P0rVx40b38K1atcr9zc/Pd4+SpvfwPC8r74XModyihzKLJsotmii3aMrPYrkV5z1I1AIAAAA54NBDD7XZs2fb8uXLXVcGffv2dQOKNWzYsMC8P/30k11yySUumVulSpW032PkyJE2fPjwAtPVF+6GDRssGxcqK1eudBdG5crRuC8qKLfoocyiiXKLJsotmvKzWG6rV69Oe14StQAAAEAOqF69uu28887usd9++1nr1q1dP7XDhg0rMO9nn31mS5cutb322is2bcuWLfbRRx+5QclUa7Z8+fIFltO6hg4dGlejtlmzZtagQQOrWbOmZeOiKC8vz70fF7PRQblFD2UWTZRbNFFu0ZSfxXIrzk11ErUAAABAjl5ABLspCNIAY1999VXctEGDBtluu+1mV111VdIkrVSuXNk9EukCJVsXl7ooyub7ITMot+ihzKKJcosmyi2a8rJUbsVZP4laAAAAoIStWbPG5s+fH3u+cOFC181B3bp1rV69eva3v/3NjjnmGNc3rbo+ePDBB23RokXWp0+fuORs79697aKLLrLtttvO2rdvX6BGrtaVOB0AAADRQKIWAAAAKGEzZ850fdD6/O4HBg4caGPGjLFvvvnGHn/8cZekVbK1c+fONnnyZGvXrl1sme+++869DgAAgNKJRC0AAABQwrp27eoGq0hl/PjxRa7j+++/L/T1Dz74YKu2DQAAALmBzjMAAAAAAAAAIGQkagEAAAAAAAAgZCRqAQAAAAAAACBkJGoBAAAAAAAAIGQkagEAAAAAAAAgZCRqAQAAAAAAACBkJGoBAAAAAAAAIGQkagEAAAAAAAAgZCRqAQAAAAAAACBkJGoBAAAAAAAAIGQkagEAAAAAAAAgZCRqAQAAAAAAACBkZSpRe9NNN1leXl7cY7fddou9/t1331nv3r2tQYMGVrNmTevbt68tWbIk1G0GAAAAAAAAUPqVqUSttGvXzn799dfYY8qUKW762rVrrUePHi55+95779nHH39smzZtsqOPPtry8/PD3mwAAAAAAAAApVgFK2MqVKhgjRs3LjBdidnvv//ePv/8c1ebVh5//HGrU6eOS9x27949hK0FAAAAAAAAUBaUuUTtvHnzrGnTplalShXbf//9beTIkda8eXPbuHGjq01buXLl2Lyap1y5cq7WbWGJWi2rh2/VqlXur2rilnRtXK3f8zxq/UYM5RZNlFv0UGbRRLlFUzbLjWMDAAAApVGZStTuu+++9thjj9muu+7quj0YPny4HXTQQTZnzhzbb7/9rHr16nbVVVfZiBEj3IXG1VdfbVu2bHHzFkbJXq0rkbfbbuaVK7x3iT87dLA/Hn88blrtgQOt4ldfFfl51p5zjq055xxbuXKl297y69ZZ/YMPtnSsGDfONu+xR+x55bfftppXXVXkcl61arb8f91F+La7+WarMnFikctu7NbNVt1+e9y0ej17Wrlly4pcdvV119mG44+PPS8/f77V7dvX0vHbG29YfqNGsedVn3zSatx9d5HLbd5xR1vx0ktx02pdcIFVmjq1yGXX9e9vay+7LG5ag732iv07z/Osvue5mwNeXl7cfCsfeMA2HXBA7HmlTz6xWhddZOlYNmtW3PPqd95p1Z5+usjlNu23n638+9/jptU58USrsGBBkcuuGTLE1p96aux5uSVLrF6vXmlt7+8vvGBbdt459rzK+PG23V//WuRy+Q0a2G9vvRU3reYVV1jld98tctkNxx1nq2+4IW5a/QMPtLx164pcduXIkfbHPvu48003cSp88YXVGTTI0rH8o4/Mq1Ej9rzamDFWfezYIpfb1u+IdeedF3uet2ZNmfuOKOxcy+XviMKUhe8Iv9x+e+EF83bZJTLfEatGjbKNf/lL7HmZ+4648soiz7dMfUesXr06re1EMWjchiLiVtP31KRJ8dOOOcYs4bslqaFD//vwqQzbtUtv2155xWzvvf//+WuvmQWO3ZR0Tn3zTfy0K64we/bZopc98kizhx6Kn9apk9nixUUve9ttZqec8v/P584169bN0jJjhlmTJv//XN8DN99c9HL6rnzvvfhp/fubffhh0cuefbbZjTfGT9thh7inOqMb5OdbXuIx8tRTZl27/v/zDz4wGzDA0vLzz/HPdT318MNFL3fIIWaJv12HHWb27bdFL6vv93PO+f/nus7r3Dm97dVvyK67/v/zZ54xu/LKopdTa86ZM+OnnXuu2T//WfSy/fqZJcRG7lxds6boZfW7vc8+///8s8/Mjj3W0vKf/5htt93/P7/rrv8+ipLp74g2bcrcd0TKcy3HvyNSKiPfESq38s89Z9awYXS+I8aMMTvqqDL9HZFX1PmW6e+INJWpRG2vwIXh7rvv7hK3LVq0sBdeeMHOPPNMe/HFF+3888+3++67zyVh+vXrZ3vttZf7d2GGDRtmQwMHjGrUNmvWzMovWWLli9imci1aWMPgyayTfNUqyysiOSzbeZ5Va9jQXRBpALRya9ZYuTSWk7o64ILvW6lSWst6221XcHtVGzmNZauuX29VEpf97be0lq1ZoYLVDC67bFnan7V+nTrxn7VcubSWLVenTsHPumZNWttbY/Nmq56wbOJ7pjo2aletGr+9Vaum/VkLbO/mzWltb5U1a6xy4rIrVqR3HJYrZ9sFl920Ke3trVerVvxnrVAhvbIpV67gZ12/Pq3trbZxo1VNXHbpUstL46K/duXKtql27f+eb/peqFEj7c/aoH59s/91q+LeU8mMdD7rNn5H1Aguq1YCZfA7onxEvyOsjH9HlP/fd0S5CH1H1KpUKb5sytp3xOLFRZ5vmfqOUKsnZFg6Zd+sWcFpupm2aFHRy/6vxVmM56W3nGzaFP98/fr0lg1eRPpWrEhv2d9/LzhNCZh0lk28sbN5c/qfdcuW+Oe62E5nWcVUiZYvT2/ZlSsLTktYziUhki0baFUYe57uZ022Heksq8+VSANAp7NsYvJC+zvd7VU5Jpbz1n5WHV/pLKvjNdEvv/w3QVEUnSeJ51G626vzM/H8TWdZviO2+Tsi5bmW498RKZWR7wiVW15i2fAdkfPfEXlFnW+Z/o5IU5lK1CaqXbu27bLLLjZ//nz3XIOJfffdd7Z8+XLXl61eV3+2O+64Y6HrUXcJwS4TYnSnq4gkb16DBgWz9w0amG2/fZHbn6cL2HLlXKJWf8uVL5/WclJOFzjB961ePb33rFGj4PbWrZvesvXqFVw2SX/BSbdXF4TBZXUxnO5nrVgxflmdbOlsb6NGW182tWsXXDawnPe/Zpuu/BK3V0mY4LJ6nu5nTXzP2rXT295kx6FqGCb7UU58T+3P4LLa3+lur8oxuKzKOZ3tbdy44PbWq5fesnXrFly2adO07jrmVav2/+eb1qHzKN3PqvMz+L4Klra2bIrxHRG3bBn8jijsXMvl74jClIXviFi5KfkXoe+IcjpPgsuWse8Ib/vtizzfMvUdUdRNdGyFNOJWd2wlm5bOcRO4EeGo1nWax5v7Tg9K93svUEs9Rjfn0llWx2WiNH+TrFq1+OcVKqT/WXUeBqX5vee+kxPpBlA6yyZL4CQsl/L3NPEaSM/T/azJtiOdZfW5EqX5m1TgmCjG954rx8RyTmfZZMdNmt977nhNlOZvkjtPgopx/eTOz8TzN51l+Y6wbf2OKDJ2zdHviJTKyHeEys1LLBu+I3L+O8Ir6nzL9HdEmvI8teEto9asWeP6p73pppts8ODBBV73BxH7z3/+47pLSJdq1NaqVct1SeAPTFZSdFAtXbrU1U7hoiU6KLdootyihzKLJsotmrJZbtmMtUq7bO9Lzu9ootyihzKLJsotmii3aMrP0di1TNWovfzyy+3oo4923R388ssvduONN1r58uVdFwcybtw4a9OmjWvW/Omnn9oll1xiQ4YMKVaSFgAAAAAAAACKq0wlan/++WeXlP3tt99cMvbAAw+0qVOnun/L3LlzXX+zv//+u7Vs2dKuvfZal6gFAAAAAAAAgJJUphK1z2kUvkLceuut7gEAAAAAAAAA2UTnGQAAAAAAAAAQMhK1AAAAAAAAABAyErUAAAAAAAAAEDIStQAAAAAAAAAQMhK1AAAAAAAAABAyErUAAAAAAAAAEDIStQAAAAAAAAAQMhK1AAAAAAAAABAyErUAAAAAAAAAEDIStQAAAAAAAAAQMhK1AAAAAAAAABCyCmFvQGnkeZ77u2rVqhJ/r/z8fFu9erVVqVLFypUj7x4VlFs0UW7RQ5lFE+UWTdksNz/G8mMuRCNuFc7vaKLcoocyiybKLZoot2jKz9HYlURtCVBBS7NmzcLeFAAAgFIdc9WqVSvszYg04lYAAIDciV3zPKoilEhW/pdffrHtttvO8vLySjwrr8D6p59+spo1a5boeyFzKLdootyihzKLJsotmrJZbgpfFeg2bdqUmisRiluF8zuaKLfoocyiiXKLJsotmlblaOxKjdoSoJ2+ww47ZPU9dVDxhRA9lFs0UW7RQ5lFE+UWTdkqN2rSRjduFc7vaKLcoocyiybKLZoot2iqmWOxK1UQAAAAAAAAACBkJGoBAAAAAAAAIGQkaiOucuXKduONN7q/iA7KLZoot+ihzKKJcosmyg3p4DiJJsoteiizaKLcoolyi6bKOVpuDCYGAAAAAAAAACGjRi0AAAAAAAAAhIxELQAAAAAAAACEjEQtAAAAAAAAAISMRC0AAAAAAAAAhIxEbZaNHDnSOnfubNttt501bNjQjjvuOJs7d27cPBs2bLALL7zQ6tWrZzVq1LATTjjBlixZEjfPjz/+aEceeaRVq1bNreeKK66wzZs3x83zwQcf2F577eVGsNt5553tscceK7A9Dz74oLVs2dKqVKli++67r02fPr2EPnnpcuutt1peXp5deumlsWmUW25atGiRDRgwwJVL1apVrUOHDjZz5szY6xpP8YYbbrAmTZq417t3727z5s2LW8fvv/9u/fv3t5o1a1rt2rXtzDPPtDVr1sTN8+WXX9pBBx3kyqRZs2Z22223FdiWF1980XbbbTc3j7bj9ddfL8FPHk1btmyx66+/3lq1auXKY6eddrJbbrnFlZOPMgvfRx99ZEcffbQ1bdrUfRdOnDgx7vVcKqN0tqWsKKzc/vzzT7vqqqvcPqxevbqb57TTTrNffvklbh2UW9lD7Bp9xK3RQdwaPcSu0UDsGk0fldXY1UNW9ezZ0xs3bpw3Z84cb/bs2d4RRxzhNW/e3FuzZk1snvPOO89r1qyZ9+6773ozZ8709ttvP++AAw6Ivb5582avffv2Xvfu3b3PP//ce/3117369et7w4YNi82zYMECr1q1at7QoUO9r7/+2rv//vu98uXLe2+++WZsnueee86rVKmS949//MP797//7Z199tle7dq1vSVLlmRxj0TP9OnTvZYtW3q77767d8kll8SmU2655/fff/datGjhnX766d60adPc/n3rrbe8+fPnx+a59dZbvVq1ankTJ070vvjiC++YY47xWrVq5a1fvz42z+GHH+7tscce3tSpU73Jkyd7O++8s9evX7/Y6ytXrvQaNWrk9e/f353bzz77rFe1alXvoYceis3z8ccfu7K87bbbXNled911XsWKFb2vvvoqi3sk9/3tb3/z6tWr57322mvewoULvRdffNGrUaOGd++998bmoczCp++va6+91hs/fryuQrwJEybEvZ5LZZTOtpQVhZXbH3/84X6fnn/+ee+bb77xPv30U2+fffbx9t5777h1UG5lD7FrtBG3RgdxazQRu0YDsWs0vV5GY1cStSFbunSpO+A+/PDD2MGmAtcXvO8///mPm0cHnn+wlitXzlu8eHFsntGjR3s1a9b0Nm7c6J5feeWVXrt27eLe66STTnLBtk8H8YUXXhh7vmXLFq9p06beyJEjS/ATR9vq1au91q1be2+//bZ3yCGHxAJeyi03XXXVVd6BBx6Y8vX8/HyvcePG3u233x6bprKsXLmy+4IWfRGrHGfMmBGb54033vDy8vK8RYsWued///vfvTp16sTK0X/vXXfdNfa8b9++3pFHHhn3/vvuu6937rnnZujTlg7aR2eccUbctOOPP979cApllnsSg6ZcKqN0tqWsSnaRkizBo/l++OEH95xygxC7Rgdxa7QQt0YTsWv0ELtGk5Wh2JWuD0K2cuVK97du3bru72effeaqcKuatE/Vq5s3b26ffvqpe66/qmrdqFGj2Dw9e/a0VatW2b///e/YPMF1+PP469i0aZN7r+A85cqVc8/9eVCQmoipCVjivqXcctOkSZOsU6dO1qdPH9dkr2PHjvbwww/HXl+4cKEtXrw4bn/WqlXLNcsLlpuaSGg9Ps2v/T5t2rTYPAcffLBVqlQprtzUNHTFihVplS3+64ADDrB3333Xvv32W/f8iy++sClTplivXr3cc8os9+VSGaWzLSg8RlEzM5WVUG4QYtfoIG6NFuLWaCJ2jb5cKiNioG1TWmJXErUhys/Pd31FdenSxdq3b++mqXB1gPgHlk9Bkl7z5wkGTf7r/muFzaPgav369bZ8+XLXn06yefx1IN5zzz1ns2bNcn21JaLcctOCBQts9OjR1rp1a3vrrbfs/PPPt8GDB9vjjz/uXvf3WWH7U38VLAdVqFDBXaBmomwpt3hXX321nXzyye6CsWLFiu4iRd+T6ldIKLPcl0tllM62IDn1X6l+v/r16+f69BLKDcSu0UHcGj3ErdFE7Bp9uVRGxEBbrzTFrhWKvQQyepd7zpw57o4bcttPP/1kl1xyib399tuu82hE54JSd89GjBjhnitw0jk3ZswYGzhwYNibhyReeOEFe/rpp+2ZZ56xdu3a2ezZs12wq87hKTMgO1TTrm/fvm5QBCUNAB+xazQQt0YTcWs0EbsC4fuzlMWu1KgNyUUXXWSvvfaavf/++7bDDjvEpjdu3Ng1E/rjjz/i5tcorHrNnydxVFb/eVHz6M6CRqCrX7++lS9fPuk8/jrw/9Rsa+nSpW5UW92B0ePDDz+0++67z/1bd0oot9yjERfbtm0bN61NmzZuFGPx91lh+1N/VfZBGvFYo0dmomwpt3gaUdqvmaAml6eeeqoNGTIkViOIMst9uVRG6WwLkge6P/zwg0vy+DUShHIr24hdo4O4NZqIW6OJ2DX6cqmMiIGKrzTGriRqs0wZfgW6EyZMsPfee89atWoV9/ree+/tmkyonxuf+sbQD/T+++/vnuvvV199FXfA+Qek/+OueYLr8Ofx16HmTnqv4Dy6i6vn/jz4f926dXP7XHdI/YfueKtJi/9vyi33qGmmyiFI/Ue1aNHC/Vvnn744g/tTzfXUX02w3HQho4sen85d7Xf1OePP89FHH7kfiWC57brrrlanTp20yhb/tW7dOtdnUJAu8rS/hTLLfblURulsCwoGuvPmzbN33nnH6tWrF/c65VY2EbtGD3FrNBG3RhOxa/TlUhkRAxVPqY1diz38GLbJ+eef79WqVcv74IMPvF9//TX2WLduXWye8847z2vevLn33nvveTNnzvT2339/9/Bt3rzZa9++vdejRw9v9uzZ3ptvvuk1aNDAGzZsWGyeBQsWeNWqVfOuuOIKN4rrgw8+6JUvX97N63vuuefcKHSPPfaYGw3vnHPO8WrXrh03uitSC46eK5Rb7tGojxUqVPD+9re/efPmzfOefvppt3+feuqp2Dy33nqr23+vvPKK9+WXX3rHHnus16pVK2/9+vWxeQ4//HCvY8eO3rRp07wpU6a4EZT79esXN6Jjo0aNvFNPPdWbM2eOKyO9z0MPPRSb5+OPP3bbcscdd7iyvfHGG92Iy1999VUW90juGzhwoLf99tt7r732mrdw4UJv/PjxXv369d3I0j7KLDdGEv/888/dQ6HEXXfd5f7tj7CaS2WUzraUFYWV26ZNm7xjjjnG22GHHdxvVDBGCY6CS7mVPcSupQNxa+4jbo0mYtdoIHaNptVlNHYlUZtlOriSPcaNGxebRwV5wQUXeHXq1HEHSO/evd3BFvT99997vXr18qpWrep+CC677DLvzz//jJvn/fff9/bcc0+vUqVK3o477hj3Hr7777/fBWmaZ5999vGmTp1agp++dAe8lFtuevXVV92Fhi4SdtttN2/s2LFxr+fn53vXX3+9+3LWPN26dfPmzp0bN89vv/3mvsxr1Kjh1axZ0xs0aJD70Qj64osvvAMPPNCtQ8GavqgTvfDCC94uu+ziyq1du3beP//5zxL61NG1atUqd17p+K5SpYo7B6699tq4H1vKLHz6nkr2W6aLlVwro3S2paworNx0cZkqRtFyPsqt7CF2LR2IW6OBuDV6iF2jgdg1mt4vo7Frnv5X/Hq4AAAAAAAAAIBMoY9aAAAAAAAAAAgZiVoAAAAAAAAACBmJWgAAAAAAAAAIGYlaAAAAAAAAAAgZiVoAAAAAAAAACBmJWgAAAAAAAAAIGYlaAAAAAAAAAAgZiVoA2Aqnn366tWzZcquWvemmmywvL89ymT6bPiMAAACij9gVAKKBRC2AUkVBZDqPDz74wMoSfd50902uW7dunbtgKGtlCAAASh9i1+SIXQGUVXme53lhbwQAZMpTTz0V9/yJJ56wt99+25588sm46X/5y1+sUaNGW/0+f/75p+Xn51vlypWLvezmzZvdo0qVKpYtS5YscfshaNiwYVajRg279tpr46YPGDDANm7caOXKlbOKFStarlm+fLk1aNDAbrzxRhf0AgAARBWxa3LErgDKKhK1AEq1iy66yB588EEr6qtOd7qrVatmZUn79u2tfv36kbu7T7ALAABKK2LX1IhdAZQFdH0AoMzp2rWrC/Q+++wzO/jgg12Qe80117jXXnnlFTvyyCOtadOmrsbBTjvtZLfccott2bKl0H6+vv/+e9f06o477rCxY8e65bR8586dbcaMGUX286XnCswnTpzotk3LtmvXzt58880C26/gtFOnTq5Wg97noYceynjfYYn9fD322GNu/VOmTLHBgwe7YLN27dp27rnn2qZNm+yPP/6w0047zerUqeMeV155ZYELDNXiuOeee9zn0rarVoiWX7FiRdx8M2fOtJ49e7pAvGrVqtaqVSs744wzYvtZ7y3Dhw+PNXkLBr3ffPONnXjiiVa3bl33PtpXkyZNinsP//N89NFHbhvq1atnNWvWdJ+hONsDAABQ0ohdi0bsmt72AMh9FcLeAAAIw2+//Wa9evWyk08+2TWX8puSKQhSk6qhQ4e6v++9957dcMMNtmrVKrv99tuLXO8zzzxjq1evdgGUgqnbbrvNjj/+eFuwYEGRTbEUSI4fP94uuOAC22677ey+++6zE044wX788UcXjMnnn39uhx9+uDVp0sQFewrCb7755lgAWNIuvvhia9y4sXvvqVOnusBeQe8nn3xizZs3txEjRtjrr7/u9pWCdgWPPu0T7d9Bgwa5gHnhwoX2wAMPuM/08ccfu/2zdOlS69Gjh/s8V199tVu3AlztF9H00aNH2/nnn2+9e/d2+1Z233139/ff//63denSxbbffnu3fPXq1e2FF16w4447zl5++WW3TJAuMPQeCpbnzp3r1v3DDz/E+kUransAAACygdh16xC7ErsCkaOuDwCgtLrwwgt1azxu2iGHHOKmjRkzpsD869atKzDt3HPP9apVq+Zt2LAhNm3gwIFeixYtYs8XLlzo1lmvXj3v999/j01/5ZVX3PRXX301Nu3GG28ssE16XqlSJW/+/PmxaV988YWbfv/998emHX300W5bFi1aFJs2b948r0KFCgXWWZR27dq5fZGMPps+o2/cuHFu/T179vTy8/Nj0/fff38vLy/PO++882LTNm/e7O2www5x6548ebJb/umnn457nzfffDNu+oQJE9zzGTNmpNzuZcuWuXm0HxN169bN69ChQ1xZaXsPOOAAr3Xr1gU+z9577+1t2rQpNv22225z01Vu6W4PAABAphC7pkbsSuwKlAV0fQCgTFLzLN0dT6TmQT7VLlCfUgcddJDrB0zNkopy0kknueZTPi0rqpVQlO7du7vmYD7daVeTJn9Z1UB455133B12NW/z7bzzzq6GRTaceeaZcc3U9t13X9dMTNN95cuXd022gp/5xRdftFq1armBMLRP/cfee+/tan+8//77bj7d9ZfXXnvNDXpRHL///rurRdK3b99Y2emhGihq/jVv3jxbtGhR3DLnnHNOXG0R1XaoUKGCq1mxrdsDAACQKcSuW4fYFUDUkKgFUCapeVGlSpUKTFfzIzUxUmCmQFPNhtS8TFauXFnketWEKsgPfBP7jkpnWX95f1k1ZVq/fr0LbhMlm1YSErdR+0maNWtWYHrwMyvQ1P5r2LCh26fBx5o1a9xnk0MOOcQ1mVPzNPWrdeyxx9q4cePcSL5FmT9/vgu8r7/++gLvocEbxH8fX+vWreOeK/BW0zw1EdvW7QEAAMgUYtetQ+xK7ApEDX3UAiiTgrUPfBpUQMGNglz1naUaAurQf9asWXbVVVe5AQWKojvyyRQ1cu+2LpstqbYx2fTgdmvfKdB9+umnky7v91OmGg8vvfSS60Ps1VdftbfeessNfnDnnXe6aQpGU/HL5/LLL3e1EJIp7kXBtmwPAABAphC7bh1iV2JXIGpI1ALA/6gTfjU1Umf7GlHXp4EDcoGCRQXfuvueKNm0XKILBzV902AJyS40Eu23337u8be//c0NctG/f3977rnn7Kyzzko5QvCOO+7o/qo5mJripUO1JQ499NDYc9WQ+PXXX+2II45Ie3sAAADCQOxacohdAYSFrg8AIOHOevBu+qZNm+zvf/+75cr2KYibOHGi/fLLL3GB7htvvGG5TH1vqZ+yW265pcBrmzdvdjVCRE3OEmth7Lnnnu6v32SrWrVq7q+/TPBioGvXrvbQQw+5gDXRsmXLCkzTyL/B/rs0cq62x+83LZ3tAQAACAOxa8khdgUQFmrUAsD/HHDAAa5frYEDB9rgwYPd3e8nn3wyp5pv3XTTTfavf/3L3d3X4AEKIB944AFr3769zZ4923KVmuWde+65NnLkSLedPXr0cLUHVCtAgzXce++9duKJJ9rjjz/uLi7U15pqMmhghYcfftg16fNrCqhWQ9u2be3555+3XXbZxerWres+vx4PPvigHXjggdahQwc7++yzXU2FJUuW2Keffmo///yzffHFF3HbpYuZbt26uWB87ty57r21/DHHHONeT2d7AAAAwkDsWnKIXQGEhUQtAPxPvXr13Aipl112mV133XUu8NVgDAqGUvUblW0aaVY1ENSXlQYe0EAI6pPsP//5T1oj+4ZpzJgxbvtVa+Caa65xI9S2bNnS7WMF735QPH36dNc0S0GqBnbYZ599XP9grVq1iq3rkUcesYsvvtiGDBniAlYNuKBgV0HwzJkz3QAKjz32mGsOqNoKHTt2tBtuuKHANulCQevWa6qd0K9fP7vvvvtiTdTS3R4AAIBsI3YtWcSuAMKQ5+XS7TYAwFY57rjj3Ki/usuPoikQHjRokM2YMcM6deoU9uYAAACUKcSuxUPsCpQd9FELABGzfv36uOcKcF9//XXXxxUAAACQS4hdASB9dH0AABGjvqtOP/109/eHH35wgwhUqlTJrrzyyrA3DQAAAIhD7AoA6SNRCwARc/jhh9uzzz5rixcvtsqVK9v+++9vI0aMsNatW4e9aQAAAEAcYlcASB991AIAAAAAAABAyOijFgAAAAAAAABCRqIWAAAAAAAAAEJGohYAAAAAAAAAQkaiFgAAAAAAAABCRqIWAAAAAAAAAEJGohYAAAAAAAAAQkaiFgAAAAAAAABCRqIWAAAAAAAAAEJGohYAAAAAAAAAQkaiFgAAAAAAAABCRqIWAAAAAAAAAEJGohYAAAAAAAAAQkaiFgAAAAAAAABCRqIWAAAAAAAAAEJGohbIER988IHl5eXFHt9//33stdNPPz02vWvXrmmvU/P6y2kd2bC124rcddNNN8XKtGXLllYalMbPVFIee+yxuO+mTNA+99ensgAAZMbTTz9t++yzj9WoUSP2PbvnnnuGvVkAgBK6xg7G6YrbEX0kaoEUDj/88NgXXp06dWzjxo1J5/M8z3baaafYvB07drTSqrQkYYMJ7OCjSpUq1rx5czv22GNtwoQJYW9m5CXu3woVKrgLxx122MEOOOAAGzx4sM2cOTPszcxJwURmug/d7AEAZP/mevCh37m2bdvaxRdfbAsWLMjqdr311ls2YMAAmzFjhq1duzar743M3DxOrKwBpFOpp7gmT55sZ5xxhu2666623XbbWeXKla1p06Z2xBFH2EMPPWQbNmyw0vgdXb58eatVq5btsccedtFFF9m3334b9qYCSVVIPhmAkpIKeOWPP/6w1157zU444YQC83388cdxgXhJ1Fw9+eSTrX379u7fzZo1s1wWpW1NpGT8Tz/95B6TJk2ya665xv72t7+FvVmlxpYtW9yFox6LFi2yTz/91O6//347/vjj7ZFHHnE3RLKlR48e7mJaFLAhtc6dO9vtt9+e0XVee+21tnLlSvdvJe0BoLTQb9x//vMf9/jHP/5hr7zyinXv3j0r7/3cc8/F/l23bl2XiFASpmHDhll5fwC5bc2aNXbmmWfaCy+8UOC1X3/91T3eeOMNu/XWW+2ll16yvffe20qT/Px8W7VqlX355ZfuMW7cOJfUVawbZcE4PeqfBf9FohZI4bjjjrPatWu7JK088cQTSRO1mu6rWLGi9e/fv0Rq9+oRBVHaVlFyUAnZzZs3u7uqajK4adMm99qoUaPssssucxc7pZWClZo1a5b4+3Tq1MlOOukkW7dunc2bN89effXVWKJu/PjxrlaA7u5Xq1YtK59XycFcThAGE5myYsUKGzFiROz5X/7yF5dsDlLN/pIo53bt2rlHJp199tkZXR8AhEm/b/qdU/ygm5C6uS/6zTv11FPdb5xqrJVUYrhq1apWrlw5++GHH2LTVTNu+PDhVlriCOQ2joNoJCn1XfX666/HprVu3dp69+7tbujou8t/Td9ZijWnTZvm5skl+p5Vi9bifKf639G63ps+fXqs5aS+o1UpZ+LEiRZll19+edibgEzzAKR03nnneTpN9KhYsaK3fPnyuNc3bNjg1a5dOzZP79693fTffvvNu+KKK7zDDjvMa9GihVejRg23fMOGDb3u3bt7TzzxhJefnx+3rvfffz+2Hj0WLlwYe23gwIGx6YccckiB7Rw/frzXuXNnr0qVKu49zjjjDG/JkiVuXn85rSPotttu84499livdevWXp06dbwKFSp4tWrVcuv561//6q1ZsyY277hx4+K2LdlD25/Otv7888/e5Zdf7rVv396rXr26V7lyZbeP+vfv702bNq3A/DfeeGNsfZrvjz/+cMs3b97c7dNWrVp5f/vb3wrsz8IE94vWGXTVVVfFfa5PP/20wPIrV670RowY4e2zzz5ezZo13XY0a9bMffY5c+bEzTtx4sTYulQ+GzdujL3Wr1+/2Gv33ntvbPrUqVPjtmHx4sVu+oIFC7xLLrnEO/DAA70ddtjBq1atmlepUiWvadOm3lFHHeVNmjSpwLYmlt3atWu9a665xu03lbnW5/vyyy+9I4880ttuu+3co2fPnt5nn31WoAzSFXzfxONvxYoV3uGHHx43j/a9T8d/suPLl+rYTrbcI4884nXs2NHt/z322MPNV9hn0nP/Nc03c+ZMt190flStWtXt/8mTJyf9zBMmTIg7F8866yxv6dKlhZ6L6Uj8XNquwl5P9bkzcQwVVg7ffvutd/LJJ3v16tVz57beX+dAosR9nOp78LvvvvMefPBBr0OHDm59DRo08M4880zv999/L7BOHdtXX321Oxc1b9u2bb3Ro0e7z1zYsQQAxZX4XaXvySDFNMHX33333bjXZ8+e7Q0aNMjbcccd3Xe04qE999zTxTPB+CvVd6Z+g7p16+ZiEE3T93phMVrwe3bdunXeXXfd5R1wwAEuhvXj0169ennPP/98kZ913rx53u233+7ttttu7vdDsWSy+G/u3Lnecccd57ZRcaZiHj+eeeedd9zvkH5T69ev7+LWxO/1TMTSxfkNkenTp3unn366t9NOO7ltU7koTta0+fPnF7gGuP/++72DDjrIfT5tW+PGjb0TTzzR++STT7ziCMYkidcAifHKL7/84p122mnud1axmn67ta9FMZtiN+0rla225ccffyxyH919991emzZt3D5SPDBkyBBv1apVWx1PFucYU6zir1MxSeLxr3hR2+XP89RTT8W9rrjlmGOOcfte76P3O/TQQ918icdHYqyk8/Kee+7xdtllF3cetmvXznvyySfdvNoO7QftD72/zk/FeMkU57pga69tiroOSye2fPrpp+OWUXkEr0vksccei5tHsbr/GVU+qb7zpG/fvrHXdY4G6Ti7+OKL3feG1qP9rWNOsf+yZcsKrCsxvvzqq6/cd03dunXdtM8//3ybvqN1Heq/tuuuu8a9pnWff/75rjxV/tpWHQMqH33GZNcAf/75pzuP9ttvP3e9UL58ebetikVPPfVU79lnny2wjL4Phw0b5mJ0nbN6D333XHDBBd4PP/xQYP7CrrFTfdbE81bfW7rO1/eavr+3335777LLLnPTkynO+YXMIlELFCIxYfbAAw/Evf7iiy/Gvf7KK6+46foxKeoHVQF6JhK1SkQkW79+5PXjkOoHXAFeYdunoHb16tUZTdR++OGHLphNtY5y5cp5d955Z8pgRtusH/Vky15//fUZSdTed999BS5IgpSIatmyZcrPoB/ZF154ITa/Lgb0ufzXP/7449hrSpT50xVM+3QB5E9XGfpeffXVIsth+PDhcdubWHa6oAg+9wPrGTNmuCAhcX0KTnQxmGp/FaaoAFLHV6NGjWLz6P39gDFTidrEz1vcRK2CNAUmycr566+/Tutc1IW4gv/C9kWmE7WpPncmjqFU5bD77ru7i8bE9eXl5bmL8q1J1OpCPtk2HnzwwXHr27RpU4HP7D+OPvroQo8lACiuopIAiheDrytB4vv73//uElupvoP1u//rr7+m/M7cf//9XRIg8be8sO91/3tW6w3+HiV7nHDCCS7pkOqzJn7XJkvUKgZNFu8pIaIEazAuSvW9nolYOt3fENFvn36vUr1XMEmnG7BK3KWaV59PCcBMJ2qV+EkWgyoBre0LJjT9hxIy69evT7mPlAhP9hl00zm4XLrxZHGPMSWEgwnAZ555Jm7fPProo7HXlABTEli2bNniEmCFvU+fPn28zZs3p4yV9t5776TL6RxV/JdOPFPc64KtvbYp6lxIJ7YMxmw6Rv0EfyJ9xwTX/f3337vpwf3do0ePAjG9bm4kK0fdsA+WceJDycLEmDq4rbrpr5smwWW2NlGr40GVcPybXMmuV3UDprB9reMg8Ts/+P2X7LHvvvvGza+bObpJlWp+HesfffRRxhO1qb4TVbZBW3N+IbPo+gAoxL777mtt2rRx/Yz53RxceOGFSbs9UP9famYman6m5TTqbuPGjV0XCuqU/fPPP3dNvvV9qj5xzjvvPDfP1vr5559tyJAhsedqtqJ+h/T+6hdt4cKFKZfVgE6HHnqotWjRwjX/1zZp/ueff941o/vqq6/s73//u1155ZWxPir1mj/404477mjnn39+Ws2uRV1IqC9SNeEWNdMbNGiQayb17LPPuuZ6apKjphvqD+mQQw4psI7ffvvNLX/aaae5Du/Vr+ny5cvda/fee69dd911VqlSpa3uP1VdH2i/+fbaay/beeed4+ZR8yC/8/4GDRrYKaec4rpGUH/Gn3zyievnVtunz6B9pH2r0ZZnzZrlllHzfjW51zpUfj5NT/ZvlZFPg3FpXWq6o/fWvlNZqZ/k999/381zyy23uGNg++23T/o5tW4d12rOpGU1eJrKXgMKqN8qUWf7+lwa0Orll1+2d99910qC+ohVn8YqO9H76/jKZJcE+rw6xtVtibpVWLp0abGWV/MonSvq0kR9Fz/zzDNuuspZ2z1mzJik52L16tXtrLPOcufio48+6poEZlOqz52JYygV9fWl4137Yf369fbwww+7c0bHl74/unXrVuzPMWXKFLecjgk1S9P3knz00Uc2depU22+//dxzlUXwvNl9993doIBffPGF628aALJJTYiDFAuK4gT1G6t4R/Qdpu6iVq9ebY8//riLab7++msXR/zrX/9KuW59r2vQMH1PK7ZUbKLfqtGjR8fGTfC7HBL/d1W/Zf/+979j6zrxxBPdwGdvv/12bJv1u6+udm644Yak76/vWnWHc/TRR7vvdw3Ok0jxZL169VwMqe1RX5cyd+5c99m0PzSmgwY982OMxO/1TMTS6f6GvPjii3bjjTfGltP+VXyi31F9Fr1fkLqzmD17diz2Vsyk/a/f0jfffNOVr34LVQZdunSxTPn999/d7+sll1zifrsVB8uyZcvcMaC4SseXYmp/n6u7KX12fZ5k3nvvPfd7qcGV1DepykT097bbbiv0OEiMJ7fmGNP+0zz+NZXirH79+sWW9+Mu0WfQ9YNo25588slY3Kp4R59B5aXpf/75pytXxTzq4iyZzz77zJ1/us7RvlT/rHLBBRe4v8ccc4w71jWegmLUxHhma64LtvbaRu/73XffxeJO0efyx3fwxwdJRdsa/F7Svtpll12SzqvvjeC8fkyp6zZ/n+u8VWzp93+tY0zHpuhc1X4RlYfK039N+1Ov6RxRd3M6VjVuhcpP52ey7xOd84pfdd6pG4ZvvvnGDQBdHNp2PRLpe+aKK66Im6YuFfTdoGNH32M6r9QdmT6zzgsdB+oaT/tJx6OOjaeeeiq2vD6LriG1jD7fhx9+GLd+XROoi0W/nLVv/XXpvNX5o2W1Hp2/mRxLQ9+J2v86J7X//WNX/1a/xDoGM3V+YRtlOPELlDqjRo2Ku3vk331UM41gTTs1j0mkZgsvvfSSq1lxxx13uJqSumvoL3PzzTdvU43akSNHxi0TvMurmptF3WlVU5vXX3/dGzNmjKvJqu1TLYPgXfagoro1KGweNQcJbo/e16duGoK1Of3aGclqGQRrKAS7FdBDTffTEbxLm+qhmgT+HWSfakz7r6s2i+6i+3RHUbWQkx0Pas7kT1cTelGNEj0P1mzWsaVmJH6zHj1efvnlAtuv+Z577jl3x9c/roJ3qrXuVHdSjz/+eHeXNEh3loPzXHfddbHX1NQpeMc3kzVqRbUWgvP5tQ4yVaNWtXrUbC5RujVqdQd/0aJFsdfUjNN/ba+99kp5Lr7xxhspz+1s1KhN9bkzcQylKgfVMJg1a1bstUsvvTT2mo7pralRq+5k/KZVagYbrEWm2u8+1dLyp6tmi1/jJlktB2rUAthWid9VJ510kvseVXPlxFr8ajni10zUd5o/vWvXrnG/x2p2H1zuiy++SPqdqe9BNXFPprBudlQDLbj+K6+8Mi6GCdai03e2v22Jn1VNe4M1LVN9106ZMiX2mpoPB19TKx6/NmUwlg5+r2cilk73N0S/58Hf/cSahmoGr1hVVC7B93jvvffi5j3iiCPi3j+TNWoTm/4n1nxUSz/RZw7u86FDh6bcR2effXZc65RgbVi1/CpOPLm1x9gHH3wQm67jQWXl184NlpnfRZqWC8amN9xwQ4Hu3fzXFGf775MYK6lWqH98PPTQQ3Gv+fG6qFulZPHM1l4XbO21TWHXikXR8RtcVvFsKqqdHZxX+1O0rxRf+tMVQyY77tVtgE+f25+uLiaC3x3qxiNYvn7L1GTXasm60SpM4r5K9VCXFanoXNf5pu7p9L2jLgOCy/o1XtV60p+mmrqJ3Ulov6kbLp/W58+vlgf+8e5/16iGfLKu8TJRo1axebALnuBrfvdnW3t+IbOoUQsUQXfvdKdIdyJFd5FU40wj6+puki94l053RwcOHGj//Oc/C113sEbl1vBrt0qjRo3iaqyp9kCrVq2S1qrVXcyrr77a3an1B84qie0LCt6Z1R3nXr16xZ7rbqye685c4rxBust67rnnxp7vuuuuca/7tXW3lbZHZaw7nEGqKeHT8ZDqTrToLnqwVuwdd9wRm67fU93RFNXC1uedP3++u2Ot8lCNCf8OZteuXWPr0V1P1VQIrru45aZjWXePUx1HEhwQTzUuVWtGtVZKwn9ji5KjGvC6s7+1VMvEv7uceMwFj7fgPtTxHRxQT2Wo2sn+XetsSPW5M3EMpbL//vtbx44di9xXxaFa+zoPRDVU6tevb0uWLIlbp2oyqJaWr0+fPrEaN/53s2qqAUBJUYsjPRKp1pe+f/zaX8E4QiONJ6s95tP3tFoHJFK8pNpaxZUYWylO9Wk7VEPXn0dxiL5XVaM1kVo+FVWbTb95wZqkiqd++eUX92/FpqppKqpNqZhLNeoSfysyEUun8xuiwYRUY8+nmo2J8Z1ayeiRWIZy2GGHpXz/on5ri0u1Cv1a0v5+9stMAxr7tRj1mbWf/X1e2G+wrnN8Wkffvn1jtYu1b7W/dI2RTjy5tcfYwQcf7Frmqcaorq1U41aDjr7wwgux6y/VxPRrTms5vzai3Hzzze6RjI4jtZjbbbfdCrym2q/+8aF9GaT9kKzVYHBfbu11QRjXNpmgfaWa8P7xoRaRqsGtfawa08muiYP7SOUQjM+S7SPVYk6k2sKKx7eFP5iYykk1VrXtGlhMx7GOuWDNcbWC1PdAsGZ4Yd89qtWs41Pzq7aszj3V0lbt3w4dOrjrc01Ltk9Uvqq1W9g+GTx4sGWKX1u8sGMtU+cXtk38tyuAApo0aRI3urqaNii5FOz2QAGzvoh9ajZcVGApag6zLdSdgM9vehKULLCS++67zzWhKSxJm4ntC/KTj6m2KzgtVVCieYIXB4mjffpNCYtDP67aF2r24m+DmvIceeSRrjlYqs9QFDVD8ykAVXDtf7Y5c+bEmmkfeOCB7uE3xQs231YTE11Y+NRMJp2gv7ByS/ZDGjyOkh1LqY6jTNCPe1Cq5vaJCd10j81tDRwSA/fgMRc83oL70G/iGpRsWklK9bkzcQxtzb7a2oR8Ovs/8fhN3NfZ3vcAyjYlIvQdrAtiNeXt2bPnNscRmfhdS3zvxN/2xOepYrF03j94g1OC3VIlvubHR4m/q5mIpdP5DdHnDP5GBRMqyWSiDLeW4rPg/gruV70WTPyn2q/J1lnYcZD4G1vYcbC1x5ifAEzs7iDY7UEw+VecMiisHILHYmLXacHXgvsyeKxk4lgoiWubZJQMDH5GNclPJfE1XQv7VE5+gl5Jd1UAUEUbv/KSkqpKUubCd16QKlDoJtNVV13lruGvvfba2GuqnOPfLFIXDUcddVSRSdrE7x4dq+pOQHSD5JVXXnGVdHSzQt2CDB06NCe+Q4LfiamOtUydX9g21KgF0qAfJfXbJPpBUt+Lfh9O/us+9dP02muvxZ7rLtrYsWNdbQIFULobHFx2WwRrzCXre9OvNZAoWOtDgciECRNcHzP6AVd/YkpcZlow4Zhsu4LT/P6WEulOf5B/F3xbqMaofrjlnHPOcftBZag7rrrIUlLVD9CCn0FBlX7YUwn2J6S+jXQXV/2hifa3+leSgw46yK3/sccei9WoTdY/re5uqr/NYC0A9R+k8tN+UKCdzg+lXyMkKLHmpY6losorE7Sfg8eiatb4tWwSa2n4fVv5gYRqXaQj2ectjnSPuaLOxcWLF1s2JfvcmTqGUimJ8zOddSb23ZW4/7O97wGUPWp1EowFU9Fvq/8dpZu0hdUSS9Vf+9b+rgV/1/3f9mBNrsTf+lSxWDrvn/jdHRRMeqWSqVg6nd8QfU5N9xNwhY3vkGw/qqZZYbUEM2lb92syOh6DNesSj4NUrZKSHQfbcowpoaWamorxVHFBLc+mTZsW+2yqjZvqfbRsYX20JibsM7U/t/a6oKRjp2R03qjlk99fqsYVUGu+4FgcPtVkDtK1ik9JR9Uif+edd9w5oxam/jWyJPYDG9xHqnVa2PdkqjLc1lg+mWC/1qpZq+8TVRbRsef3VSzqi1atUFUbX7XvU22LWj8ouaubc6qRq75l9Vf7Rsf03Xff7Voo6touuE+UBA8mcRM1a9bMMil4vKU61jJ1fmHbkKgF0qBAWsGEf+c3OGiQkptKePjU+bffTEdUM9PvPF6JEv0wZoqSWmoe5Ac/6uTc7/5AteZSBZtqphBch/9jpUEaEgdMSPXlrh+r4tAFh//Dr2SQfrj87g8UJAZ/5DM5mFRxKFhR0nb48OGx8lLn6n7TreB2aV8p4Ah24eBTYJl4l1JBjZ+o1aAECm70o6+7xH4wqPIK3sUMNqcLlplo4AW/9qmaT25Lgs1Pjvr0mf1gU014CjsmtpbWq/MmmERT8yn/bn/ihYH2nT9Yn26U5Nrd28RzUQNz+Yl2lU82uz1IpSSPoTApwa+LTL/7g/Hjx7sLZ/9YKqluOwCguPxBrUS/f7pBrBvGiTcmVUMt07FQ4vrUJcOoUaPcvxW3BgfD0YV6YrPYbMpmLK2Bw9Rtjz/oq7o4U+IkmMBSmWjAN93QTNyPiuWCg+v6lLTJpWbrqejz+om4/2vvTuBlqv/Hj7/vde2y79mXLFG4IrsiRNkVJUuyVQglspNdKxHZWoQkicoWlUoSUtbImr3sZL3zf7w/3/+Z39zV3Gtmzpy5r+fjcVwzc+bMZz6fuXPPeZ/3eX80K9IzSKf7CIm5qup2PmMakKpbt66ZRE8DW3rpuef4e7ZDn6cBYGu/RsfHSrrwpMcXepm5r4Ndlts5LkiKmEHdxB6L6feNFajV8dDjWd1n8tyufh48r7zSTNSYpeB0AmIN1Cqd3OzQoUPu9nmW0rD6SCfmVRoA1YnFYl49p4FSPdbQyekCJeaJHuv7Jua+spYL09/xuALYnnRyQU320StsPa+y1asjre8r/Y7RY4OYx8R65W7MMjd6nKjH9bearNsfguX3K7kjUAt4Qf+46h+WKVOmxPrDqGfHPM8W606cBpmsS4VeffVV80Wmf4RmzZrl03IC+sdj2LBh7m1qbSqdaV7PkOlrJfQFrGf6lGYsaG0kvTxYZ5q0Mj3j4vmHVWdK1Vln9ctZAyK3qp+jwU4N/llf+jp7pP6h1wMUvVxE60wqbfsLL7wgdtH39Nprr7nbozNg6k6HZnjqjqLW0tq5c6f7MvLmzZubS12sLE89E6uXDGlwSP9gW/QPs85wq6y6P5pNo+9XaxjpDqgG+PTgxDrzrSUTLHrAoG2wLkvRdupOgfbn7QaidMfIqq2kRo0aZQKLeoZUPxOedYqSSretlwDpjqyWO9AdMs/L6fQyqcGDB7tv6+dCa31ZpRG0TVpDTncWYpakCAb6GdEAv74/67Ohl22qmTNnSjDw52fIblrLztqJ1O82zRrRS9c0g1gvPwOAYKDZWfqdpAfhms2mWUq6H6H7APr3X7OxNJCiGaWegSpf0ICBnszXg3+lV1Ts27fP/P3X4JhnfVH9+xDzypZACuS+tNKMOasmqe7/6f5b69atTYDq8OHDZl9ZjwH0b7v240MPPeSuyaknmTXZIDIy0vSZ7gNqoEv3FTVD1CpvFaysk98aKNL34XnJt/5tDeRnTLMxdT3lmWwSM0tTn6fBdOvydQ166evouOjJWz0JonMHaIBU+9+q3etrt3NckBQxA5w6H4GWVtGED63tmlCNXKWfaQ2WW8kx+rnW7yDtH736T/vLM5Ndk5R0PpOYdH3r99OzTIL2h87T4KlHjx4mmKv7x5qMon2gcwno8aP+ru3YscMkC+i2dMzjy+S/XcuXLzfHMxqQ1df0LKuhx1xWkDjmCSrN5Nb6tnpcpEHs+Nx///3mCjU96aE/9ThG90E9TypZSSiaVazfadoe/U7Tet7aJ7qfrt9tejJK+8RK/LhVORZfC5bfr2TPx5OTASEr5my81rJ06dJY644dOzbOdcuUKeOKjIyMc0behGbyTGiWR50FN67X0tleixcvHudrrVu3zhURERHrORkyZDCzuFq3dZbhmLO5hoeHx3qezpDrTVu/++47V+bMmeOdeVO3rTP6evKcGTVme2LO3urtbO6eM4nG3KZ68cUXo213wYIF7sd0JmCdVf5Ws4h6zripdBb6VKlSRVvntddecz/esmXLaI9VqlQpVru6desW52vVqVMn2gzI2mfxzfYZH51JV8cx5rZ19t2qVasm2F/x8Wa2VV1atWrlOnv2bKznz5gxI871ixQp4ipZsmScn21vPxMJfa48Z9f27MtbPW/q1KlxtlfXK1WqlPt2x44dve7D+N5XzHZ5+759/RlKaIbxhJ4XXx/fakbj+J6nM1XXqFEjzvf28MMPR7ut30MAcDtiflfF/JufkHfeeSfOfbCYi7d/l7z9TlbHjh1zlS5dOsHXbdGihev69euJnmk+of0/z3bFfCy+9+brfelb9eOwYcNcYWFh8fbL4sWL3eueOHHCVa5cuVuOYUJjFd++Rcx2J7Tf4dnnMR+L77MQs48aNWoUZ9u1j3XfNbH7k0n5jFmuXLniypIlS7R1c+XKFee6OtP8U089dcsx8Py8JbSvFLNfPB9L6L0n5bjgdo5typcvH+f2Fy5c6PLGhQsXzH73rdqr7+nXX3+Ndzvdu3eP9ZwvvvgiznX1dyeuY4yYi+fn/lbfZbcSczwTWoYPHx7tuQ0aNIhzPc/ft5hjmjp16gRfo3DhwtGOdX788UdX9uzZb9k2z/FP6Ds2vnbd6vc2vucl5fcLvsVkYoCXNONPzwh70ixUz9ndLVqo/J133jFnNvUyEF1Pz0prloSesfQlPZuqWY96Jl8zf/XyDM3u07NcMSdssOjZrxUrVphLL/Q5WjdJLyvXDADPyzVi0rOgOkumTp52qxl/46IZolrzVTNKtC/1cjPNxtV6R9ZM9PqY3bQNnpcoaSasVbtMx1TPjmqWgPafnvnVM7F6hlGzETSjWWvQepbDUFq/TM+2evLMsvCs/xSzPq1FSyboJd2a4aGfK+03nQRNs1OTWpvMouUv9PIVvWRLP6O6aFaEntHVM6i+OkOr/aCfS8141LPsmpmtZ2rjqt2lGama6aHZCvo50d8jvbxQL6Hy5wRnSdWtWzdzCZmWQfD8XdQMEs/JIOKr9xYI/vwM2Unfi2ZL6Hdvvnz5zOdFsyK0JtigQYOirWtn/wOA1r/XK0T0MmTdp9B9If3+1b9rtWrVMleXeNYT9yX9O6qX/OqVQ/p3WP/26mtrFpzuz2q9Sd2nDIa/B4Hcl1aa/apllvQKMC2zoPu5Ojb6f/1b7lmjUTN+dT976tSppkyV/r3XfUGtX6klrTQLT8tI6d/XYKf7BZMnTzZZoLrvojUzNdtVr15KSu3d2/mMWVcwetK+jGtd3afUSaF0wjm9Ss/626/b0H0cveLxzTffNMct/pTU44Kk0v1MzWDU0hFJqWervzu6363795rZqVf16efW+h3TMdLPtWad6rFlfGJmOev3V1xlH6xMYz3+0yxNPc7UNmgf6RWp+hnR3xM9BglUrVPrM6IlwHTfcciQIdEe11JmenWn/i7oZ0ozXfVYMKEr5LTPtE90zPWzrp9ZfZ96W+d/0e8Lz2Md/axo9rp+32s/awau9onuo+ptzdTXrH3PqysDKVh+v5KzMI3W2t0IAACcTssyxHVQo+UFNHhr1b/Sgzdf7bDj1v2vJRH0gFHpTrOWeog5uzMAAMmBBug8kwH0cnMmAwKA4GL/6VIAAEKAzkit9av0DL0W/9cz45pBoNkqVpBWz0hTy8k/9MBTM580O11rn+kkLpop4Xm2X+txE6QFAAAAEKwI1AIA4AN6gYqWctAlLnpZmE4ik5RLCXFrOlGFBmXjuwxLJ7nQSekAAAAAIFhRoxYAAB+oXbu2qfel9cq0DpVm1GqtMq2/pbO7ar0vre8M/9B6Xjr7sc6KrLUFtY6WZjBrbTSth6czGXvWngYAAACAYEONWgAAAMDhdOKlCRMmyPHjx+Xee+81ZVd0okgAAAA4Bxm1AAAAgIMtWLDAzKitM9dv3rzZBGo1w/zkyZN2Nw0AAACJQEYtAAAA4GCVK1eW++67TyZPnmxuR0VFmUn1evToIf3797e7eQAAAPASGbUAAACAQ127ds1MYli3bl33feHh4eb2+vXrbW0bAAAAEicikevDC5rFcPToUbnjjjskLCzM7uYAAACEFL0g7MKFC5I3b14TlEzO/vnnH7l586bkypUr2v16e9euXbHWv3r1qlk891tPnz4t2bJlY78VAADA5n1XArV+oEFavdwMAAAA/nP48GHJly+f3c1wlDFjxsjw4cPtbgYAAECyc9iLfVcCtX6gmbTWAGTMmNGvr6VZEKdOnZIcOXIk+4wSJ2HcnIlxcx7GzJkYN2cK5LidP3/enBS39rmSs+zZs0uKFCnkxIkT0e7X27lz5461/oABA8zEY5Zz585JgQIFZNmyZZI+ffqAtFleeSUwrxMqRo/2zXbod3v6XdH3iUPf24N+tw99Hxp9n4BLly7JI4884tW+K4FaP7AuG9MgbSACtVeuXDGvw8GsczBuzsS4OQ9j5kyMmzPZMW5cqi+SKlUqiYyMlG+++UaaNm3qHgu9/fzzz8daP3Xq1GaJqUaNGn7fb3XLli0wrxMqatf2zXbod3v6XdH3iUPf24N+tw99Hxp9f4skA2/3XQnUAgAAAA6mGbLt27eXihUrSqVKleTNN980mRsdO3a0u2kAAABIBAK1AAAAgIM9/vjjpuzEkCFD5Pjx41KuXDlZvnx5rAnGAAAAENwI1AIAAAAOp2UO4ip1AAAAAOcgUAsAAIKKy+WSmzdvmnqn1Kh1Dq2Lev36dZ+NW8qUKc0kWQAAAEByQaAWAAAEjWvXrsnRo0flwoULZjZ6JotyVoBdg7U6dr4YN91Gvnz5JEOGDD5pHwAAABDsCNQCAICgoEG+/fv3myzKO++8U9KkSUNGrcMCtTdu3JCIiIjbDtTqtrTm6t9//y3FixcnsxYAAADJAoFaAAAQNNm0GqzVLMpUqVL5JOAHZwZqVY4cOeTAgQOmnAKBWgAAACQHpKkAAICgQhYtFEF6AAAAJDccCQEAAAAAAACAzQjUAgCAkLRv9T55p/Q75ieC07Bhw6RcuXJ2NwMAAAAICgRqAQBASNZL/eaVb+Sfnf+Yn3o7ENavX2/qqTZq1CggrzdnzhxTIkAXLRmRJ08eefzxx+XQoUMBeX0AAAAAvkOgFgAAhJy/Vv4lRzceNf/Xn3o7EGbOnCk9evSQ77//Xo4e/d/r+1vGjBnl2LFjcuTIEVm0aJHs3r1bWrVqJcFEJwQDAAAAkDACtQAAIKRo9uzawWslLMX/JqPSn3rb31m1Fy9elAULFkj37t1NRq1mu1qeeOIJk+kaM3iZPXt2+eCDD8ztCxcuyJNPPinp06c3mbFvvPGG1K5dW1544YUEX1ezaXPnzm2eU7VqVenUqZP88ssvcv78efc6S5YskQoVKkiaNGmkSJEiMnz4cLlx44Z57MUXX5RHHnnEve6bb75ptrl8+XL3fcWKFZMZM2aY/2/cuFEeeugh0/ZMmTJJrVq1ZPPmzbHaNHXqVGncuLF5P6NGjTL3jx07VnLlyiV33HGHaeeVK1eS1NcAAABAKCJQCwAAQjKb1nXzf4FZ/RmIrNpPPvlESpYsKSVKlJC2bdvKrFmz3MFhDcAuXbrUBHMtK1askMuXL0uzZs3M7T59+siPP/4oX3zxhaxatUrWrVsXKwB6KydPnpTFixeb8gu6KN1Ou3btpFevXrJjxw6ZNm2aCSJbwVMNtP7www9y8+ZNc/u7774zQdhvv/3W3NZM3b/++ssEja2Acvv27c1zfv75ZylevLg0bNjQ3B+z/qy+tz/++EOefvpp0z963+jRo+XXX381geUpU6bcRo8DAAAAoSXC7gYAAAAkZHrF6XLx+P8FOBOigdHLpy7H+di8R+dJuhzpTLanNzLkziBdfu2SqLIHGqBVDRo0kHPnzpmgpwY469evbzJLNYj61FNPmXU+/vhjk3Gq2aUa5Hz//ffNfXXq1DGPz549W/LmzXvL19XXyZAhw//e++X/vfeePXua11OaPdu/f38TXFWaUTty5Ejp16+fDB06VGrUqGFef8uWLRIZGWnKNrz00kvy+eefm/U1YHvnnXearFr14IMPRnv96dOnS+bMmc171fftmUXcsWNH9+3WrVubLFpd1KuvviqrV68mqxYAAAD4/wjUAgCAoKZB2gtHomdrJkXU9Si5eNS7gG9iaV1YLTeggVgVERFhSh1o8FYDtXr7sccek7lz55pA7aVLl0w5gvnz55v19+3bZ0ohVKpUyb1NLSug2bm3ooFezbzV53/99dfmNaxsWbV161aTqet5n2bPaoBUA7saZL333ntNQDZVqlRm6dKliwniagawBmA169Zy4sQJGTRokFlfM3h1W7qdmBOYVaxYMdrtnTt3Srdu3aLdV6VKFVm7dm0iehoAAAAIXQRqAQBAUNPM1sRk02pANj7hKcO9zqr19nWVBmS15qtnBqy2J3Xq1DJ58mQTdNXyBxrw1OCmljZImzZttAzUpAoPD3dnu5YqVcqUKdA6uR9++KG5T4OtmlXbvHnzWM/VmrVKg8kaeNX2ahuzZs1qtqXlDTRQ27dvX/dzNDP333//lbfeeksKFixonqMB12vXrkXbtpXRCwAAAMA7BGoBAEBQ87b8wN4Ve2Vug7kJrqNB3Cazmkix+v8LbPqCBmh1QrDXXntN6tWrF+2xpk2byrx580wmqU70lT9/fjPhmGa+tmrVSlKmTOkuR6D/14m6ChQo4C5p8Oeff0rNmjUT1R4tc1C0aFHp3bu3mUBMF834tYK5cdHgrNbU1cxfK3iswVttu7bBqk+rNDtXa8tqXVp1+PBh+eeff27ZLg38btiwwdTLtWiNWwAAAAD/Q6AWAAA4nmavrh28VsJShLknEYuLPq7rFa1X1OtatbeybNkyOXPmjKm9qpmznlq0aGGyba1L/rVu67vvvmuCn56X/Gv5As1U1dqwms2aM2dOU3pAs2UT204NBuskXkOGDDFt05+PPPKICQC3bNnSbFPLIWzbts3UiVUaDNY6tbr+2LFjzX0anNX1ddKvu+66y719nTxMs3W1tMH58+dNmzU7+FZ0MrMOHTqY51WrVs2UaNi+fbsJUgMAAAAQCbe7AQAAALfrr5V/ydGNRxMM0ip9XNfT9X1FA7F169aNFaS1ArW//vqr/P777+a2lj/YsWOHmZxLg5WeXn/9dVNCQIOquj19XLNQrfIEiaHZtF9++aWpm6sTmWkAduXKlXLffffJ/fffL2+88YYpW2DJkiWLlC1bVnLkyCElS5Z0B2+joqKi1ae13q8GpjVTV+vt6sRlGli+Fa3ZO3jwYDOJmU5advDgQVOiAQAAAMD/hLk0BQU+pdklerCmlyxmzJjRr6+lB1Ba604PkDRDBs7AuDkT4+Y8jJmz6ORW+/fvl0KFCplL8HXxJptUd2VmVJ4hRzcdFYm/PO3/CRfJG5lXntnwjM+yav1BJxzTgK6WVNBs3WCn46BlILwdN28/D4ULF44VrA7kvlaos6UvH300MK8TKpYu9c126Hd7+l3R94lD39uDfrcPfR8afe+j/S1KHwAAAEe7ee2mnDt0zrsgrYoSOX/4vHleROrg2RXasmWL7Nq1SypVqmR24kaMGGHub9Kkid1NAwAAABAAwXN0AgAAkAQabO28sbNcPnXZ6+ekz5k+qIK0lokTJ5qJv1KlSmXKA6xbt06yZ89ud7MAAAAABEDwHaEAAAAkUqb8mcziZOXLl5dNmzbZ3QwAAAAANnFkwb4DBw6YWm1as0xnGS5atKiZGfnatWtxrr93714zm3LmzJlvue1Dhw5Jo0aNJF26dKamoc5krPXWAAAAAAAAAMBfHJlRq/XbdIKYadOmSbFixWTbtm3SuXNnM+mGXjLo6fr169KmTRupUaOG/PTTTwlu9+bNmyZImzt3brPusWPHpF27dpIyZUoZPXq0n98VAAAAAAAAgOTKkYHaBg0amMVSpEgRU89t6tSpsQK1gwYNkpIlS0qdOnVuGahduXKl7NixQ1avXi25cuWScuXKyciRI+Xll1+WYcOGmXpxAADAv1wul91NQBDgcwAAAIDkxpGlD+KisyNnzZo12n1r1qyRhQsXyjvvvOPVNtavXy9ly5Y1QVpL/fr15fz587J9+3aftxkAAPwfvYJFXb7s/aRgCF1WSasUKVLY3RQAAAAgIByZURtXDdpJkyZFy6b9999/pUOHDvLRRx9JxowZvdrO8ePHowVplXVbH4vP1atXzWLRwK7S8gy6+JNuXzNO/P068C3GzZkYN+dhzJwlLCxMMmXKJCdPnjTliLS+vN4H59CSU1bA/Xbo76x+DnQugvDw8Fi/w/xOAwAAIBQFVaC2f//+Mm7cuATX2blzpyllYDly5Igpg9CqVStTp9ai/3/iiSekZs2a4m9jxoyR4cOHx7r/1KlTcuXKFb++th6oaDaxBiL0QAbOwLg5E+PmPIyZ82hgVjMo9QSpBuoI1Drvd86Xv2s6uavuT8V04cIFn70GAAAAECyCKlDbt29fkwWbEK1Hazl69Kg88MADUrVqVZk+fXqssgdffPGFO8vWyqiKiIgw6z799NOxtq2TiP3yyy/R7jtx4oT7sfgMGDBA+vTpEy2jNn/+/JIjRw6vs3mTSt+THsTqaxGEcA7GzZkYN+dhzJxJx0v//mbOnJlArcN+306fPm1KUd3u75uOu2bmxredNGnS3Nb2AQAAgGAUEWwHZrp4QzNpNUgbGRkps2fPjrUjr/Vm9bJJy5IlS0y2rk4oduedd8a5zSpVqsioUaNMBk/OnDnNfatWrTLB1tKlS8fbltSpU5slJm1TIAIDejATqNeC7zBuzsS4OQ9j5kyaVWtd9g7nBGovXrxosmD9PW58LgAAABCKgipQ6y0N0tauXVsKFixoMmY9L4mzMl9LlSoV7Tm//vqr2akvU6aM+77FixebbNhdu3aZ2/Xq1TMB2aeeekrGjx9vLrscNGiQPPfcc3EGYgEAAAAAAAAg2QZqNctVJxDTJV++fNEe0xIH3tK6hbt3746WvbNs2TLp3r27ya5Nnz69tG/fXkaMGOHT9gMAAAAAAACAJ0deN6Z1bDUgG9eS0HPOnj0b53Y8aZbuV199JZcvXzaZupqxq3VtAQAAAAAAAMBfHBmoBQAAAAAAAIBQQqAWAAAAAAAAAGxGoBYAAAAAAAAAbEagFgAAAAAAAABsRqAWAAAAAAAAAGxGoBYAAAAAAAAAbEagFgAAAAAAAABsRqAWAAAAAAAAAGxGoBYAAAAAAAAAbEagFgAAAAAAAABsRqAWAAAAAAAAAGxGoBYAAAAAAAAAbEagFgAAAAAAAABsRqAWAAAAAAAAAGxGoBYAAAAAAAAAbEagFgAAAAAAAABsRqAWAAAAAAAAAGxGoBYAAAAAAAAAbEagFgAAAAAAAABsRqAWAAAAAAAAAGxGoBYAAAAAAAAAbEagFgAAAAAAAABsRqAWAAAAAAAAAGxGoBYAAAAAAAAAbEagFgAAAAAAAABsRqAWAAAAAAAAAGxGoBYAAAAAAAAAbEagFgAAAAAAAABsRqAWAAAAAAAAAGxGoBYAAAAAAAAAbEagFgAAAAAAAABsRqAWAAAAAAAAAGxGoBYAAAAAAAAAbEagFgAAAAAAAABsRqAWAAAAAAAAAGxGoBYAAAAAAAAAbEagFgAAAAAAAABsRqAWAAAAAAAAAGxGoBYAAAAAAAAAbEagFgAAAAAAAABsRqAWAAAAAAAAAGxGoBYAAAAAAAAAbEagFgAAAAAAAABsRqAWAAAAcKADBw5Ip06dpHDhwpI2bVopWrSoDB06VK5du2Z30wAAAJAEEUl5EgAAAAB77dq1S6KiomTatGlSrFgx2bZtm3Tu3FkuXbokEydOtLt5AAAASCQCtQAAAIADNWjQwCyWIkWKyO7du2Xq1KkEagEAAByIQC0AAAAQIs6dOydZs2aN9/GrV6+axXL+/HnzUzNzdQmIsLDAvE6o8NW40O+J48vfB/o+ceh7e9Dv9qHv7RMVmH2fxOxjEagFAAAAQsDevXtl0qRJCWbTjhkzRoYPHx7r/lOnTsmVK1ckIPLnD8zrhIqTJ32zHfrdnn5X9H3i0Pf2oN/tQ9+HRt8n4MKFC+ItArUAAABAEOnfv7+MGzcuwXV27twpJUuWdN8+cuSIKYPQqlUrU6c2PgMGDJA+ffpEy6jNnz+/5MiRQzJmzCgBcfhwYF4nVOTM6Zvt0O/29Lui7xOHvrcH/W4f+j40+j4BadKkEW8RqAUAAACCSN++faVDhw4JrqP1aC1Hjx6VBx54QKpWrSrTp09P8HmpU6c2S0zh4eFmCQiXKzCvEyp8NS70e+L48veBvk8c+t4e9Lt96Hv7hAdm3ycx+1gEagEAAIAgotmtunhDM2k1SBsZGSmzZ88OXLAVAAAAPkegFgAAAHAgDdLWrl1bChYsaOrSap1ZS+7cuW1tGwAAABKPQC0AAADgQKtWrTITiOmSL1++aI+5uPQRAADAcbg2CgAAAHAgrWOrAdm4FgAAADgPgVoAAAAAAAAAsBmBWgAAAAAAAACwGYFaAAAAAAAAALAZgVoAAAAAAAAAsFmE3Q0AAAAAnOyff/4xS1hYmGTPnl2yZctmd5MAAADgQARqAQAAgES4dOmSLFy4UJYsWSI//fSTCdJ60mBtlSpVpGnTptKqVStJnz69bW0FAACAcxCoBQAAALzw77//ypgxY2TatGly5coVueeee6RJkyZSpEgRyZIli7hcLjlz5ozs379fNm3aJJ07d5YePXpI165dpX///iaACwAAAIRUoPbAgQMycuRIWbNmjRw/flzy5s0rbdu2lYEDB0qqVKlirb93714pX768pEiRQs6ePZvgtvWStZjmzZsnrVu39ul7AAAAgLMUKlRIihUrJhMmTJAWLVpIjhw5Elz/1KlTsmjRIpk+fbpZzp8/H7C2AgAAwHkcGajdtWuXREVFmWwG3Vnetm2byVjQy9AmTpwYbd3r169LmzZtpEaNGubSNG/Mnj1bGjRo4L6dOXNmn78HAAAAOMunn34q9evX93p9DeR269bNLCtWrPBr2wAAAOB8jgzUahDVM5Cql5vt3r1bpk6dGitQO2jQIClZsqTUqVPH60CtBmZz587t83YDAADAuRITpPXlcwEAAJA8ODJQG5dz585J1qxZo92npRF0oofffvtNPvvsM6+39dxzz8kzzzxjAsCaAdGxY8c4SyJYrl69ahaLdVmbZv3q4k+6fa2H5u/XgW8xbs7EuDkPY+ZMjJszBXLcgvmzcfToUTly5Ig56Z8/f367mwMAAAAHCYlArdagnTRpUrRsWp3soUOHDvLRRx9JxowZvd7WiBEj5MEHH5R06dLJypUr5dlnn5WLFy9Kz549432OTioxfPjwOOuS6UQT/j5Q0SC1HhiFh4f79bXgO4ybMzFuzsOYORPj5kyBHLcLFy5IsDl27Jg88cQT8t1335nbepL//vvvl7lz55ratgAAAICjArU6G+64ceMSXGfnzp2mlIFFMxa0DEKrVq1MnVqL/l93lmvWrJmoNgwePNj9f52ATOve6oQRCQVqBwwYIH369ImWUasZFFqXLDFB4qQeFOmBgL4WB7POwbg5E+PmPIyZMzFuzhTIcUuTJo0EG70KS9/7vn37zES3O3bskKefftosepUXAAAA4KhAbd++fU0WbEK0HIHnpWUPPPCAVK1a1cyk60l3iL/44gt3lq11KV5ERIRZV3eavVG5cmUZOXKkKW2QOnXqONfR++N6TA9SAnGAqQdFgXot+A7j5kyMm/MwZs7EuDlToMbNzs/F2LFjzT5rypQpo93/66+/yrJly9zZs+XKlTOltPSEPgAAAOC4QK1mIejiDc2k1SBtZGSkzJ49O9YO+/r16+XmzZvu20uWLDHZujqh2J133ul1m7S+bZYsWeIN0gIAACD5+OSTT2TGjBny2muvSZMmTdz36z6p7mvqlVh58uSRXbt2ycyZM6VChQq2thcAAADO4cg0FQ3S1q5dWwoUKGAyZrUW7PHjx81iKVWqlJQpU8a9aHBWg7n6fw28qsWLF0cro7B06VKz471t2zZT93bq1KkyevRo6dGjhy3vEwAAAMFl06ZN8tJLL5kyW3Xr1pXt27eb+999912zj1qwYEFzgv+ee+6RFClSyKxZs+xuMgAAABwiqDJqvbVq1SoTSNUlX7580R7TEgfe0gkvdu/e7b6tl7C988470rt3b7OdYsWKyeuvvx6t9i0AAACSd3mHrl27SuvWrWXo0KFSsWJF6dSpkymVtW7dOjl8+LCZWCxXrlwmaAsAAACEdEat1rHVQGpcS0LPOXv2bJzbseikZFu2bDEzCV+8eNGUPdAdcerjAQAAwFOmTJnkzTffNBm2e/bsMSf4J02aZK7iqlSpEkFaAAAAJBoRSAAAACCJSpcuLStWrDBzJmigtmzZsubqLwAAACCxCNQCAAAAXtKrrrp3724yZ3XeA70ia8eOHdK4cWNTr7Zdu3bSokULc/uvv/6yu7kAAABwEAK1AAAAgJeeffZZ+eKLL8yEs++//778999/0rBhQ7l27ZqZ7+Dll182cyBoEFeza/v162d3kwEAAOAQBGoBAAAAL3355ZcyYMAAad++vcmanTFjhhw6dMhk01ry5MljgrjffvutmWAMAAAA8AaBWgAAACARk4jt37/fffvAgQMSFhZm7o9JJxVbv359gFsIAAAAp4qwuwEAAACAU2hpAy1/sHXrVlPe4Ouvv5bmzZtLkSJF7G4aAAAAHI5ALQAAAOClrl27yt13321KIGh92mnTpkmbNm3sbhYAAABCAIFaAAAAIBGqV69uFgAAAMCXqFELAAAAeOHy5cu2PBcAAADJA4FaAAAAwAv58+eXESNGyLFjx7x+zpEjR2TIkCFSoEABv7YNAAAAzkfpAwAAAMALU6dOlWHDhplgbbVq1aRu3bpSoUIFKVy4sJlYzOVyyZkzZ2T//v3y66+/yurVq+Xnn3+W4sWLy5QpU+xuPgAAAIIcgVoAAADAC4899pi0bNlSvvjiC5kzZ46MGjVKrl27JmFhYdHW04BtqlSppF69evLpp59K48aNJTycC9kAAACQMAK1AAAAgJc04Nq0aVOzXL16VTZt2iS7du2Sf//91zyeLVs2KVmypERGRkrq1Kntbi4AAAAchEAtAAAAkAQaiK1atapZAAAAgNvFNVgAAAAAAAAAYDMCtQAAAAAAAABgMwK1AAAAAAAAAGAzArUAAAAAAAAAYDMCtQAAAAAAAABgMwK1AAAAAAAAAGCzCLsbAAAAADjF5s2bE/2cChUq+KUtAAAACC0EagEAAAAvVaxYUcLCwrxa1+VymXVv3rzp93YBAADA+QjUAgAAAImQJk0aadSokdSvX18iItidBgAAgG94tWcZHh7udeaAJ7IHAAAAEEqmTZsmH3/8sXz22Wfy7bffSsuWLeWJJ56Q6tWr2900AAAAOJxXgdohQ4bECtQuXrxYtm/fbjIJSpQoYe7btWuXrFy5UsqUKSNNmzb1T4sBAAAAm3Tu3NksR44cMQHbefPmybvvvisFChSQNm3amOWee+6xu5kAAAAI1UDtsGHDot2ePn26nDx5UrZt2+YO0lp27twpDz74oOTNm9e3LQUAAACCxJ133ikvvfSSWXT/d+7cuSZoO378eCldurRMnDjRJDQAAAAA3gqXJJgwYYI8//zzsYK0qlSpUuYx3UkFAAAAQp3u/7766qvmirNatWqZq842bNhgd7MAAACQHAK1f//9t6RMmTLex/UxXQcAAAAIZfv375fRo0dL2bJlpXz58nL48GEZNGiQdOjQwe6mAQAAwGGSNE2t1qCdMmWKmThBL/vypAFafUx3VgEAAIBQoyXAFixYYGrUauZs7ty55bHHHpOZM2dKpUqV7G4eAAAAklOg9o033jA1t+666y5p1qyZFCtWzNy/Z88e+fzzz8XlcslHH33k67YCAAAAtqpXr56sXbtWMmTIIM2bN5eRI0ea+RnCw5N0oRoAAABwe4Ha6tWrm+yBwYMHm1pc//33n7k/bdq0JoA7fPhwMmoBAAAQclavXm32ee+77z45deqUvP3222aJT1hYmCxZsiSgbQQAAEAyCdRev37dzGybNWtWE6SNiooyO6kqR44cZBMAAAAgZBUoUMAEX/VKMgAAAMDWQK0GYiMjI+W1116Tnj17mtu5cuXyaaMAAACAYHTgwAG7mwAAAIAQlej01xQpUkjBggXl6tWr/mkRAAAAEAJ27NhhJhwDAAAAvJGkOgU9evSQ6dOny+nTp5PydAAAACDkaZmwp556yu5mAAAAIJQnE7t586akTp1aihYtKi1btpRChQqZSRU8ae2u3r17+6qdAAAAAAAAABCykhSoffHFF93/nzlzZpzrEKgFAAAAAAAAAD8Gavfv35+UpwEAAAAAAAAAfBWo1cnEAAAAAAAAAAA2BmoBAACA5Oj111/3et0ff/zRr20BAABAaElyoPb333+XSZMmyebNm+XcuXMSFRUVq0btX3/95Ys2AgAAAEHBc64Gb+g+MQAAAOC3QO23334rDRo0kCxZskjFihVly5Yt8uCDD8qVK1dk/fr1cvfdd0tkZGRSNg0AAAAELeZqAAAAQFAFaocMGSJFihSRn3/+Wa5duyY5c+aUV155xQRrN2zYIA8//LCMGzfO960FAAAAbJSYuRouXbpkrjwDAAAAvBEuSaDlDjp16iQZM2aUFClSmPtu3rxpflauXFm6du0qgwcPTsqmAQAAgJDw5ptvSv78+e1uBgAAAEI5UBsRESF33HGH+X/mzJklZcqUcvLkSffjmm27Y8cO37USAAAAAAAAAEJYkgK1xYoVkz179rgnSChZsqQsXrzY/fiXX34puXPn9l0rAQAAAAAAACCEJSlQ27BhQ5k3b57cuHHD3O7Tp4989tlnUrx4cbN88cUXpvwBAAAAAAAAAMBPk4lp/dlevXq569O2b9/e/H/RokXm58CBA6VDhw5J2TQAAAAAAAAAJDtJCtRqTdps2bJFu69t27ZmAQAAAEKVTqrrraNHj/q1LQAAAAgtSQrUTps2TWrWrCmlSpXyfYsAAACAIFWxYkUzR4M3XC6X1+sCAAAASQrUdu/e3ex0Zs2aVapXry41atQwS2RkpISHJ6nsLQAAABD0Zs+ebXcTAAAAEKKSFKg9fvy4fP/99/LDDz/IunXrpF+/fiZjIH369HL//fe7A7e1a9f2fYsBAAAAm+jcDAAAAEDQBGpz5swpLVu2NIu6cOGC/PTTTyZo++mnn8qwYcNMxu2NGzd83V4AAAAAAAAACDlJCtR6+uuvv0yAVhfNstXbmllbpUoV37QQAAAAAAAAAEJckgK1kydPdgdntQyCVatWa9dqyYMKFSpIihQpfN9aAAAAAAAAAAhBSQrU9uzZ0wRiW7RoIS+99JKZRAwAAAAAAAAAkDThSXnSc889J2XKlDH1aKtVq2ayaQcMGCBfffWVnDt3LolNAQAAAAAAAIDkKUmB2kmTJsmWLVvk9OnT8tlnn0nNmjXlhx9+kObNm0u2bNmkXLly0qNHD9+3FgAAAEAsV69eNfvgOqHvb7/9ZndzAAAAEKhArSVjxozSsGFDGT16tHzwwQfy9ttvS/HixeX333+XKVOm3M6mAQAAgKCmAdF58+ZFu2/FihUmiaFy5cry1ltvBawt/fr1k7x58wbs9QAAABAkNWrVjh07zGRi33//vfl55MgRc7/uILZu3dpMKgYAAACEKg2OpkuXTtq0aWNu79+/X5o1a2auMNN94j59+kjatGmlS5cufm3H119/LStXrpRFixaZ/wMAACAZBWqzZ88uZ86cEZfLJSVLlpSHH37Y1KnV4GyhQoV830oAAAAgyGzdutVMrGvRK8x0wl0tEab7y48//ri8++67fg3UnjhxQjp37iyff/65CRp7UyJBF8v58+fNz6ioKLMERFhYYF4nVPhqXOj3xPHl7wN9nzj0vT3od/vQ9/aJCsy+T2L2sZIUqG3fvr0JympwVndCA+3AgQMycuRIWbNmjRw/ftxkLLRt21YGDhwoqVKlcq9TuHDhWM9dv3693H///fFu+9ChQ9K9e3dZu3atZMiQwbzXMWPGSEREkpOPAQAAEIJ0El3NnrXoxLoPPfSQe/9Y/+/PDFdNmujQoYN069ZNKlasaPZ/b0X3a4cPHx7r/lOnTsmVK1ckIPLnD8zrhIqTJ32zHfrdnn5X9H3i0Pf2oN/tQ9+HRt8n4MKFC+KtJEUfX3vtNbHTrl27TDR62rRpUqxYMdm2bZvJJLh06ZJMnDgx2rqrV6+Wu+++233bc2c6pps3b0qjRo0kd+7c8tNPP8mxY8ekXbt2kjJlSlOHFwAAALDkyZNHdu7caf6v+42bNm2Sjh07uh+/ePGihIcnfkqI/v37y7hx4xJcR19Xyx3ojv+AAQO83rauqyUZPDNq8+fPLzly5DDzTwTE4cOBeZ1QkTOnb7ZDv9vT74q+Txz63h70u33o+9Do+wSkSZNGvJXkNFENai5cuNBknp48eVJGjBghZcuWNZkF33zzjVSrVk1y5col/tCgQQOzWIoUKSK7d++WqVOnxgrUamBWA6/e0J1drb2rwV1tu86cq5m7L7/8sgwbNsydrQsAAAA0adJEJk2aZDJRN2zYIKlTpzY1aj1LI+h+amL17dvXZMomRLerV5fp1WL6up40u/bJJ5+U999/P9bzdN2Y6ysNKCclqJwkLldgXidU+Gpc6PfE8eXvA32fOPS9Peh3+9D39gkPzL5PYvaxkhSoPXv2rAmU/vLLL6Y8gGay9ujRwzymt3v27GkyUQOZhaoB4qxZs8a6v3Hjxmbn+a677jITPujt+OiOrgabPQPM9evXN6UQtm/fLuXLlw+6Wl+6fb3sLWA1xeATjJszMW7Ow5g5E+PmTIEct2D5bLz66qumZMCHH34omTNnljlz5rj3I3V/8NNPP5Xnnnsu0dvV7FZdbuXtt982bbAcPXrU7LsuWLBAKleunOjXBQAAgL2SFKjVy7E0cLlixQoTvMzpkSqsEyi0bNnS1OgKVKB27969JpvBM5tWA8ZaokEzezVyrbPgNm3a1Ey0EF+wVuvdxswCtm7rY8FY60sPVDRIrQdGAcuCwG1j3JyJcXMexsyZGDdnCuS4JabOlz/p/ubcuXPjfezvv//2aoKvpCpQoECs11RFixaVfPny+e11AQAAEESBWg12agatTpDw77//xnpcs1c1o8Bf9bhKlizpvn3kyBGT3duqVStTp9aikzh41t+67777TJbBhAkTEsyqTQo7a33pQVFYWJh5LQ5mnYNxcybGzXkYM2di3JwpkOOWmDpf/qSJCZrBqokKMWkfZMqUyZZ2AQAAIBkFajVbonDhwvE+fv36dblx44bf6nFZNPD6wAMPSNWqVWX69Om33L5eArZq1ap4H9datlrOwdOJEyfcj8XH7lpfelAU0Lpi8AnGzZkYN+dhzJyJcXOmQI1bsHwuHnnkEVN6q3nz5vL444+b/VI721aoUCGT0QwAAIBkFKjVy6k2b96c4KRcpUuX9ls9LiuTVneGIyMjZfbs2V7tFP/2229mdt74VKlSRUaNGmUmR7PKOWhgV7Nik/J+AAAAELq+/vprUw9Wa9HOnDnTXNGlJcBat24tNWrUsLt5AAAAcJgknfJ/5plnZNasWWbH1DprrxkUOqHWwIEDZfny5dK1a1fxFw3S1q5d29Tl0rq0WgtWa8h61pHVWW7nzZsnu3btMovWy9U2W5OeqcWLF0cro1CvXj0TkH3qqafMLL1ag3fQoEFmEoi4MmYBAACQfGnZA92/1CuwlixZYvYltWat7qdqjdgXXnjBTFYLAAAA+C2jtlevXmYysTZt2pgZbtUTTzxh6tVqyQMN0nbq1En8RbNcdQIxXWJOlOB5udfIkSPl4MGDEhERYQKyGljWLAfPEg67d+9239b6YsuWLZPu3bub7Nr06dNL+/btZcSIEX57LwAAAHC2lClTmjIIuly7ds2daTtjxgyZPHlykkqCAQAAIPlJUqBWs2ffe+89E8TUS7327NljJpDQkgiPPfaY1KxZU/xJ69jeqpattk2XxG6nYMGCZmIIAAAAILEuXrxoymhplu2VK1eoGQsAAAD/Bmot1atXN0tMN2/eNJd9tWvX7nY2DwAAAAQ9vUrrs88+M1m0a9euNRPrli1b1lyVpZOMAQAAAH4P1Mb033//mUzb119/XQ4fPkygFgAAACHrww8/lE8++cSU5dKSB1pq65VXXjHBWc95EAAAAACfTyams9mWKVNG0qZNK3nz5jW1anUCMb2k68033zRlA3TShIwZM8rs2bMTs2kAAADAUbTM1s6dO6Vv377y22+/yY4dO2To0KEEaQEAAODfjFrNGOjcubNkyJDBXMr1999/m8kRLl26JGfOnJHFixdLrVq15OWXX5YGDRokrTUAAACAQ2zcuFEiIyPtbgYAAACSW6BWg7IlSpSQdevWSfbs2U0d2o4dO8qsWbMkS5YssmzZMmnYsKF/WwsAAAAECYK0AAAAsKX0wfbt2+WZZ54xQVqVIkUKkz2rBg0aRJAWAAAAAAAAAPwdqL18+bLkyZMn2n25c+c2P7VuLQAAAAAAAAAgAJOJhYWFxXl/RITXFRQAAAAAAAAAADEkKsI6ceJEmTdvnvv29evXzc+BAwe6SyJ4BnWXLFmSmM0DAAAAAAAAQLLkdaC2QIECcvr0abN4KliwoBw7dsws3mTfAgAAAKFgxIgR0rx583jLgOkcD4sWLZIhQ4YEvG0AAAAI4dIHBw4ckP3793u97Nu3z78th7Fv9T5ZUHOB+QnnYNyciXFzHsbMmRg3Z0qO4zZs2DD5/fff431827ZtMnz48IC2CQAAAMmkRi2Ci8vlkjUD18jZPWfNT72N4Me4ORPj5jyMmTMxbs7EuMVNr0RLlSqV3c0AAACAQzALmIP9tfIvOfbr/0pO6E+9Xax+MbubhVtg3JyJcXMexsyZGDdnSk7j9v3338u3337rvv3ZZ5/J3r17Y6139uxZWbBggZQtWzbALQQAAIBTEah1KM1UWTt4rYSlCBPXTZf5qbeL1itKfeAgxrg5E+PmPIyZMzFuzpTcxm3t2rXucgb6/jRQq0tcSpcuLZMmTQpwCwEAAOBUlD5wKM1UObrxqDkgUvpTb+v9CF6MmzMxbs7DmDkT4+ZMyW3c+vXrJ6dOnZKTJ0+aIPW7775rbnsu//zzj1y+fNnUqK1cubLdTQYAAIBDkFEbApkrnuY9Ok/S5UgXkhksoTBul09djvMxxi14MW7Ow5g5E+MWWuMWylm1adOmNYvSCXRz5Mgh6dKls7tZAAAACAEEah2cuRKXqOtRcvHoxYC3CbeHcXMmxs15GDNnYtycxzOrNlRr1aqCBQva3QQAAACEkNsK1F69elU2b95sLv2qVq2aZM+e3XctQ6KzaS3hKcPJPArSjCMNNsSHcQs+jJvzMGbOxLiF5riFclatZx9Mnz5dZs6cKfv27ZMzZ87EWkff+40bN2xpHwAAAJJJoPbtt9+WYcOGyblz58ztVatWyYMPPmhqcpUsWVLGjx8vTz/9tC/biltk01r0gKnJrCYhncHiNHtX7JW5DeYmuA7jFnwYN+dhzJyJcQvNcUsOWbVar/b111+XcuXKSdu2bSVLlix2NwkAAADJLVA7e/ZseeGFF6R169ZSr169aAFZzarVgO38+fMJ1NqQTZtcMlichHFzJsbNeRgzZ2LcnIlx+5/3339fWrRoIZ988ondTQEAAEAICE/Kk1577TVp0qSJfPzxx/Loo4/GejwyMlK2b9/ui/YhgVmV4xPqsy07DePmTIyb8zBmzsS4ORPj9j///fef1K1b1+5mAAAAIDkHavfu3SsPP/xwvI9nzZpV/v3339tpF+LJXPF6xMLFrK/Pg30YN2di3JyHMXMmxs2ZGLf/U6dOHdm4caPdzQAAAEByDtRmzpzZ1KKNz44dOyR37ty30y7EcPPaTTl36JxI/POsRBclcv7wefM82IdxcybGzXkYM2di3JyJcfs/U6ZMkZ9//llGjx5NkgIAAADsqVHbsGFDM8Pts88+G+sxLXnw3nvvUZ/WxyJSR0jnjZ3N7MqeoqKi5PTp0yaLOTw8etw9fc705nmwD+PmTIyb8zBmzsS4ORPj9n9KlChh3vfgwYPNkiZNGkmRIkW0dbQ2rzX5LgAAAJCQJO0xv/rqq1K5cmUpU6aMqVGrO6A6mcKsWbNk0aJFkidPHhkyZEhSNo0EZMqfySye9OAgxckUkjNnzlgHRQgOjJszMW7Ow5g5E+PmTIzb/+hEYqE4SRoAAAAcFKjNmzevbNq0SV555RVZsGCBqTn24Ycfyh133CFt2rSRsWPHSvbs2X3fWgAAACBIzJkzx+4mAAAAIIQk+Ro0zZaYMWOGWU6dOmWyKHLkyJFsMigAAAAAAAAAwFd8ElXVAG2uXLkI0gIAACBZOXTokHTr1s3Uq82SJYt8//335n6deLdnz56yZcsWu5sIAACAUM6oHTFiRIKPa60unUwhX758UrNmTbnzzjuT2j4AAAAgKO3YsUNq1KhhrizT+Rv27t0rN27cMI9pGbAffvhBLl26JDNnzrS7qQAAAAjVQO2wYcPcEydofVpPMe/XmW87d+4skydPJuMWAAAAIaNfv36SOXNm+fnnn80+sJYG89SoUSMznwMAAADgjSRFTv/++2+55557pH379mZSsXPnzpnl119/lXbt2km5cuXkzz//lM2bN8uTTz4p06ZNk9GjRyflpQAAAICgpGUOunfvbsqAWckKngoUKCBHjhyxpW0AAABIJoHaZ599VkqWLCmzZs2S8uXLyx133GGWChUqyOzZs6V48eLSv39/E7DV2XDr168vH3zwge9bDwAAANhESx6kS5cu3sd1wt3UqVMHtE0AAABIZoHaNWvWSK1ateJ9XB9btWqV+3bDhg3NRAsAAABAqNAkhS+//DLOx7RW7fz58+X+++8PeLsAAACQjAK1mhmwYcOGeB/XOl2pUqWKtqOaIUOGpLUQAAAACEIDBgyQ5cuXm/IH27ZtM/edOHFCVq9eLfXq1ZOdO3eaq8wAAAAAv00m1qZNG3nnnXckW7ZsZse0cOHC5v79+/fLlClT5KOPPpLnnnvOvf7atWuldOnSSXkpAAAAICg9/PDDpsxXr169ZPr06ea+tm3bmkl1M2bMaEp/1axZ0+5mAgAAIJQDtePHjzfZAq+//rq88cYbEh4e7q7TpTumLVq0MOuoK1euSGRkpFStWtW3LQcAAABs9tRTT0nz5s1l5cqVsnfvXrM/XLRoUTNHg87hAAAAAPg1UJsmTRpZsGCBuZRLL/c6ePCgub9gwYJmp1TrdXmuO2TIkKS8DAAAABD00qdPL82aNbO7GQAAAEiOgVpL+fLlzQIAAAAkV9evX5cjR47ImTNnzNVlMXkmMQAAAAB+CdQCAAAAydXZs2flxRdflLlz58q1a9diPa5B27CwMLl586Yt7QMAAEAyCdR+/fXXpkbt5s2b5dy5c3FmD7BTCgAAgFDVoUMHWbp0qbRu3VoqV64smTJlsrtJAAAASG6B2kWLFsljjz0md999t9kxnTp1qjzxxBMmWLtkyRIpXry4NG3a1PetBQAAAIKETiDWs2dPM7kuAAAAcLvCk/KkMWPGSKVKlWTLli0yfPhwc9/TTz9tLvvatm2bHDt2TAoXLnzbjQMAAACCVbZs2aRYsWJ2NwMAAADJOVC7Y8cOk0mbIkUKiYiIcE+ioAoVKiTPPvusjBs3zrctBQAAAIJIly5dZP78+RIVFWV3UwAAAJBcSx+kS5dOUqVKZf6fOXNmSZ06tcmiteTKlUv279/vu1YCAAAAQWbw4MFy9epVqVixojz11FOSL18+k8gQU/PmzW1pHwAAAJJBoLZEiRImq9ZSrlw5+fDDD6Vt27Zy48YN+fjjj6VAgQK+bCcAAAAQVI4cOSJr1qyR3377zSxxCQsLY4JdAAAA+C9Q26xZM3n77bdl4sSJJpt24MCB0qRJE5Ndqzujly5dklmzZiVl0wAAAIAj6BwNmzdvlgEDBkjlypUlU6ZMdjcJAAAAyS1Q++KLL5rF8sgjj8i3334rn332mbncq1GjRvLAAw/4sp0AAABAUPnhhx/k5Zdfdk+uCwAAAAQ0UKt1uFasWGEmDbvnnnvc99eoUcMsAAAAQHKQO3duyZo1q93NAAAAQIgIT+wTdBKxVq1ayU8//eSfFgEAAAAO0LdvX5kxY4ZcvHjR7qYAAAAgOWbUag3a4sWLyz///OOfFgEAAAAOcOXKFUmZMqUUK1ZMHnvsMcmfP78pAxZz37l37962tREAAAAhXqP2lVdekT59+pjM2hIlSvi+VQAAAECQ85yzYfLkyXGuQ6AWAAAAfg3U/vzzz5ItWzYpU6aM1K5d29SrTZs2bayd0rfeeispmwcAAACC3v79++1uAgAAAJJ7oNYzY+Cbb76Jcx0CtQAAAAhlBQsWtLsJAAAASO6B2qioKN+3BAAAAHCgI0eOyPfffy8nT56UFi1aSL58+eTmzZty7tw5yZQpU6y6tQAAAEBcwuO8FwAAAECCXC6XmbehcOHC8uSTT5r///nnn+axixcvmvJgkyZNsruZAAAASA6BWq1VO2bMGDNBwp49e8x9ly9fls2bN5udUwAAACBUTZgwwZT60knFVq1aZQK3Fs2kbd68uSxatMjWNgIAACDEA7XXrl0zO57VqlWTgQMHyttvvy2HDx/+3wbDw6VevXrUpwUAAEBIe++996Rdu3YyevRoKVeuXKzH77nnHneGLQAAAOCXQO3gwYNl2bJlMnXqVNm9e3e07IE0adJIq1atZMmSJUnZNAAAAOAImqhQtWrVeB9Pnz69nD9/PqBtAgAAQDIL1M6bN0+6d+8uXbp0kaxZs8Z6vFSpUrJv3z5ftA8AAAAISjlz5nRfVRaXTZs2SYECBQLaJgAAACSzQK3OaFu2bNl4H9eZbbVWLQAAABCqtBTYu+++Gy1BISwszPxcuXKlzJkzx1xpBgAAAPgtUJs/f37ZtWtXvI//+OOPUqxYMfGXAwcOSKdOncwMu2nTppWiRYvK0KFDTe1cz3V0RznmohOgJSSu58yfP99v7wUAAADONHz4cMmTJ4+pT6u1anW/cdy4cVK9enV5+OGHTY3aV155xe5mAgAAIJQDtU888YRMmzZN1q9fHyt7QCdV+OSTT8zOqr9okDgqKsq0Yfv27fLGG2+YbIa4doRXr14tx44dcy+RkZG33P7s2bOjPadp06Z+eicAAABwqkyZMpkkgH79+smRI0fMXA3fffednD171iQRrFu3TtKlS2d3MwEAAOAQEUl50sCBA81Oac2aNU09Wg3S9u7dW06fPi1///23NGzY0Nz2lwYNGpjFUqRIETOpmU5uNnHixGjrZsuWTXLnzp2o7WfOnDnRzwEAAEDyo1d3DRo0yCwAAABAwDNqU6VKJcuXLzeZpxokLVmypFy9etVc3qW1uJYuXWrq1AbSuXPn4pzYrHHjxmaiB70E7YsvvvBqW88995xkz55dKlWqJLNmzRKXy+WHFgMAAMDJpkyZIqdOnbK7GQAAAEjOGbVKs2jbtm1rFrvt3btXJk2aFC2bNkOGDPLaa69JtWrVJDw8XBYtWmRKGHz++ecmeBufESNGyIMPPmguU9NJIJ599lm5ePGi9OzZM97naJBaF8v58+fNTy3PoIs/6fY1kOzv14FvMW7OxLg5D2PmTIybMwVy3ILls/H888/LCy+8ILVq1ZLWrVtLs2bN4kwcAAAAAPwWqNU6XG3atJHy5cuLL/Xv399MwJCQnTt3mgxei9YD0zIIOqNu586d3fdrRmyfPn3ct++77z45evSoTJgwIcFA7eDBg93/1/d36dIl85yEArVjxowxk0nEpBkWV65cEX8fqGg2sR4YaUAazsC4ORPj5jyMmTMxbs4UyHG7cOGCBAOdN0EnndX5GXQ/VE/w16lTx+wnN2nSRDJmzGh3EwEAABDqgVrNXtVsVS17oNkDjz32mJQtW/a2G9O3b1/p0KFDguvoa1o08PrAAw9I1apVZfr06bfcfuXKlWXVqlWJapM+Z+TIkSZjNnXq1HGuM2DAgGhBYc2ozZ8/v+TIkcPvO+h6UKTZzfpaHMw6B+PmTIyb8zBmzsS4OVMgx00n7QoGd911lwwZMsQsOsGtBm0XLlwo7du3N/uN9evXN/vKugAAAAB+CdSePHlSFi9eLAsWLJDx48fL6NGjTZarFbQtUaJEUjZrdux18YZm0mqQNjIy0tTK9eaA4LfffpM8efIkqk36nCxZssQbpFX6WFyPa5sCcYCpB0WBei34DuPmTIyb8zBmzsS4OVOgxi0YPxd33323Obmvy9atW03QVmvYLlu2jEAtAAAAvJKkvdw77rhD2rVrJ19++aWcOHHCZLPmy5fP7JiWLl1aypUrJ2PHjhV/0SBt7dq1pUCBAqYurZYYOH78uFks77//vsybN89ckqaLBpN1YrAePXq419Fgs2cZBZ0EbcaMGbJt2zZT93bq1KnmeZ7PAQAAAOLz+++/m1IIn376qSnRkNDJfgAAAMAnk4lZMmfOLJ06dTLLv//+Kx9++KEMHTpUBg4caGrO+oOWL9BAqi4aIPakddEsGjg+ePCgREREmICsZgC3bNnS/bjWUdu9e7f7dsqUKeWdd96R3r17m+0UK1ZMXn/99Wi1bwEAAABPO3bsMPuZGqD9888/zT6llj3QOQwSmhsBAAAA8GmgVl2/fl2+/vprs4OqWakXL140NVr9RevY3qqWrdYG0yUx29FJyXQBAAAAbkWTAjQ4q4HaFClSmInENFGhadOmkilTpoC1Q69yGzFihMnm1fq9tWrVks8//zxgrw8AAACbA7U3btyQlStXmuDskiVLzARaWv+1Y8eO8vjjj5sJvgAAAIBQpcFRDYr27NlTmjdvLtmyZQt4GxYtWmSu/tJyXQ8++KDZR9cyXgAAAEgmgVotc6Bn6c+cOSPZs2eXNm3amEkSatasaSaRAAAAAEKdzpuQM2dO215fg7K9evWSCRMmmP1zi84ZAQAAgGQSqNUgbbNmzUzmrJ6510u9YtIgbpYsWXzRRgAAACDoeAZptfyBzo2gChYsGJBg6ebNm02wODw8XMqXL28m1tVJfTVwW6ZMGb+/PgAAAIIgUHvixAkzQVdMV69elS+++ELmzp0ry5cvlytXrviijQAAAEBQ0hJgffr0kQMHDkS7v3DhwmZSWn9OJrZv3z7zc9iwYea1ChUqJK+99prUrl3bTGqWNWvWOPfXdbFo+TIVFRVlloDgCrzE8dW40O+J48vfB/o+ceh7e9Dv9qHv7RMVmH2fxOxjJSlQ6xmkdblc8s0335jg7OLFi83OXo4cOeSJJ55IyqYBAAAAR/jqq6+kRYsWJoNWa8SWKlXK3L9z506ZPn26qVu7bNmyRE9WqxOSjRs3LsF19DWsnf6BAweadqjZs2dLvnz5ZOHChdK1a9dYzxszZowMHz481v2nTp0KXJKFHycdDkknT/pmO/S7Pf2u6PvEoe/tQb/bh74Pjb5PwIULF8Tvk4lt2rTJBGfnz59vLrPS2rRap/b555+X+++/n1q1AAAACGkjR46Ue+65R9atWyfp06d3369ZtLpPXL16dRMUTWygtm/fvtKhQ4cE1ylSpIgcO3bM/N+zzELq1KnNY4cOHYrzeQMGDDAZwBZNssifP79JtMiYMaMExOHDgXmdUOGrOsj0e+L4sv40fZ849L096Hf70Pf2yRmYuQbSpEnjn0CtXl6lwVld9uzZI3feeac8+eSTUqlSJVOvVs/kV6lSJSltBgAAABzl999/N5m0nkFai96nwdZXXnkl0dvVoKkutxIZGWkCs7t37zZBYXX9+nVThkGzfOOi6+sSk9a51SUgXK7AvE6o8NW40O+J48vfB/o+ceh7e9Dv9qHv7RMemH2fxOxjeR2o1QDsL7/8ItmzZ5eWLVvKjBkz3DuEf/31V9JaCgAAADiUZkecPn063sf1scRkUCSWZsB269ZNhg4darJiNTirE4mpVq1a+e11AQAA4B9eB2o3bNjgnhShUaNGcU4mBgAAACQXDz74oLz11lumtEHMq8p03/ntt9+WevXq+bUNGpjV/fKnnnpK/vvvP6lcubKsWbNGsmTJ4tfXBQAAgO95HW2dPHmyfPzxx9KsWTMzg6yWOdCatDqrLAAAAJDcjB8/3gRo9SozLQVWokQJc7+WItAr0XLmzHnLScFuV8qUKWXixIlmAQAAgLN5XSTh2WeflR9++MGUOXjhhRfMpAl16tQxdWqHDBliJg9jAjEAAAAkF3q1mdap7dmzp5w5c0YWLFhgFv1/r169ZOvWrVKoUCG7mwkAAACHSHTVXN0hHTRokOzYsUM2btxosmq//fZbcblcJpjbpUsXWbZsmVy5csU/LQYAAABspvu6Wtpg165d8sYbb5ifWnpAF/2/lgvTjFoAAADAW7c1vZnONKs7oYcPH5aVK1dK/fr1TRZB48aNzaRjAAAAQCjSScJefvllU+YAAAAAsD1Q695IeLjUrVtX5syZIydOnJB58+aZsggAAABAqCpTpowcOHDA7mYAAAAgRPgkUBszu+Dxxx+XJUuW+HrTAAAAQNAYNWqUTJs2TVavXm13UwAAABACIuxuAAAAAOBEkydPlqxZs5ryXzqPgy5p06aNto5OtksCAwAAALxBoBYAAABIgt9//90EYgsUKCA3b96UvXv3xlpHHwcAAAC8QaAWAAAASALq0wIAACCoa9QCAAAAAAAAABKHjFoAAADgNixbtky++uord4ZtoUKFpGHDhvLII4/Y3TQAAAA4CIFaAAAAIAnOnj0rzZo1k++//15SpEghefLkMfevXr1apk2bJjVq1JDPP/9cMmfObHdTAQAA4ACUPgAAAACSoFevXrJu3ToZN26cnDlzRg4ePGgW/f/YsWPlhx9+MOsAAAAA3iCjFgAAAEgCzZZ99tln5cUXX4x2f/r06eWll16SQ4cOyQcffGBb+wAAAOAsZNQCAAAASZAyZUopUaJEvI+XLFnSrAMAAAB4g0AtAAAAkAQtWrSQhQsXys2bN2M9duPGDfnkk0+kVatWtrQNAAAAzkPpAwAAACAJ2rZtK88//7xUrVpVunTpIsWKFTP379mzR6ZPny7Xrl2TJ598UjZv3hzteRUqVLCpxQAAAAhmBGoBAACAJKhVq5b7/xs3bpSwsDDzf5fLFec6er+uE1cGLgAAAECgFgAAAEiC2bNn290EAAAAhBACtQAAAEAStG/f3u4mAAAAIIQwmRgAAAAAAAAA2IyMWgAAACCJDh48KO+//77s27dPzpw5E60+rdKatEuWLLGtfQAAAHAOArUAAABAEsybN8+UP7hx44ZkzpxZMmXKFGsda4IxAAAA4FYI1AIAAABJMGDAAClZsqR8+umnctddd9ndHAAAADgcNWoBAACAJPjnn3+kW7duBGkBAADgEwRqAQAAgCSoXLmyHDp0yO5mAAAAIEQQqAUAAACS4M0335SPPvrIlD4AAAAAbhc1agEAAIAkKFu2rIwaNUpat24t6dOnl3z58kmKFCliTSa2detW29oIAAAA5yBQCwAAACTBlClTpEePHpImTRopWrSoZMqUye4mAQAAwMEI1AIAAABJMHr0aKlataosW7aMIC0AAABuGzVqAQAAgCQ4d+6cPPnkkwRpAQAA4BMEagEAAIAkqFWrlvzxxx92NwMAAAAhgkAtAAAAkARTp06V7777TsaPHy///vuv3c0BAACAwxGoBQAAAJKgdOnSsn//fhkwYIDkzJlT0qdPLxkzZoy2UBYBAAAA3mIyMQAAACAJWrRoIWFhYXY3AwAAACGCQC0AAACQBHPmzLG7CQAAAAghlD4AAAAAAAAAAJuRUQsAAAB4afPmzYl+ToUKFfzSFgAAAIQWArUAAACAlypWrOh1XVqXy2XWvXnzpt/bBQAAAOcjUAsAAAB4afbs2XY3AQAAACGKQC0AAADgpfbt29vdBAAAAIQoJhMDAAAAAAAAAJsRqAUAAAAAAAAAmxGoBQAAAAAAAACbEagFAAAAAAAAAJsRqAUAAAAAAAAAmxGoBQAAAAAAAACbEagFAAAAAAAAAJsRqAUAAAAAAAAAmxGoBQAAAAAAAACbEagFAAAAAAAAAJsRqAUAAAAAAAAAmzkyUHvgwAHp1KmTFC5cWNKmTStFixaVoUOHyrVr16Kt53K5ZOLEiXLXXXdJ6tSp5c4775RRo0YluO3Tp0/Lk08+KRkzZpTMmTOb17l48aKf3xEAAAAAAACA5CxCHGjXrl0SFRUl06ZNk2LFism2bdukc+fOcunSJROYtfTq1UtWrlxp7itbtqwJwuqSEA3SHjt2TFatWiXXr1+Xjh07SpcuXeTjjz8OwDsDAAAAAAAAkBw5MlDboEEDs1iKFCkiu3fvlqlTp7oDtTt37jS3NYhbokQJc59m4CZEn7N8+XLZuHGjVKxY0dw3adIkadiwodlu3rx5/fq+AAAAAAAAACRPjgzUxuXcuXOSNWtW9+2lS5eaAO6yZctMUFfLINStW1fGjx8fbT1P69evN+UOrCCt0ueEh4fLhg0bpFmzZnE+7+rVq2axnD9/3vzUrF9d/Em3r+/N368D32LcnIlxcx7GzJkYN2cK5Ljx2QAAAEAoColA7d69e03mq2fZg3379snBgwdl4cKF8sEHH8jNmzeld+/e0rJlS1mzZk2c2zl+/LjkzJkz2n0REREmsKuPxWfMmDEyfPjwWPefOnVKrly5Iv4+UNEgtR4YaUAZzsC4ORPj5jyMmTMxbs4UyHG7cOGCX7cPAAAASHIP1Pbv31/GjRt3y/IEJUuWdN8+cuSIyZht1aqVqVPrebCgWa4apNXJxNTMmTMlMjLSlEmwyiH4woABA6RPnz7RMmrz588vOXLkMJOS+ZO+z7CwMPNaHMw6B+PmTIyb8zBmzsS4OVMgxy1NmjR+3T4AAAAgyT1Q27dvX+nQoUOC62g5A8vRo0flgQcekKpVq8r06dOjrZcnTx6TDWsFaVWpUqXMz0OHDsUZqM2dO7ecPHky2n03btwwE5DpY/FJnTq1WWLSg5RAHGDqQVGgXgu+w7g5E+PmPIyZMzFuzhSoceNzAQAAgFAUVIFazcDQxRuaSatBWs2QnT17dqwd9mrVqpkg619//SVFixY19/3555/mZ8GCBePcZpUqVeTs2bOyadMms12lZRI0Q6Ry5cq3+e4AAAAAAAAAIG6OTEfQIG3t2rWlQIECpi6t1oLVGrKedWR1ErAKFSrI008/LVu2bDHB165du8pDDz3kzrL95ZdfTBkF3Z6VcatlFLSEgj72448/yvPPPy+tW7eWvHnz2vZ+AQAAAAAAAIQ2RwZqV61aZSYQ++abbyRfvnymzIG1WDTDdunSpZI9e3apWbOmNGrUyARi58+f717n8uXLpl7t9evX3ffNnTvXBG/r1KkjDRs2lOrVq8cqqwAAAAAAAAAAIVv6wFtax/ZWtWyVZsEuWrQo3sc1K1dnJvaUNWtW+fjjj33STgAAAAAAAAAI2YxaAAAAAAAAAAglBGoBAAAAAAAAwGYEagEAAAAAAADAZgRqAQAAAAAAAMBmBGoBAAAAAAAAwGYEagEAAAAAAADAZgRqAQAAAAAAAMBmBGoBAAAAAAAAwGYEagEAAAAAAADAZgRqAQAAAAAAAMBmBGoBAAAAAAAAwGYEagEAAAAAAADAZgRqAQAAAAAAAMBmBGoBAAAAh/rzzz+lSZMmkj17dsmYMaNUr15d1q5da3ezAAAAkAQEagEAAACHeuSRR+TGjRuyZs0a2bRpk9x7773mvuPHj9vdNAAAACQSgVoAAADAgf755x/Zs2eP9O/fX+655x4pXry4jB07Vi5fvizbtm2zu3kAAABIpIjEPgEAAACA/bJlyyYlSpSQDz74QCpUqCCpU6eWadOmSc6cOSUyMjLO51y9etUslvPnz5ufUVFRZgmIsLDAvE6o8NW40O+J48vfB/o+ceh7e9Dv9qHv7RMVmH2fxOxjEagFAAAAHCgsLExWr14tTZs2lTvuuEPCw8NNkHb58uWSJUuWOJ8zZswYGT58eKz7T506JVeuXAlAq0Ukf/7AvE6oOHnSN9uh3+3pd0XfJw59bw/63T70fWj0fQIuXLgg3iJQCwAAAAQRLWUwbty4BNfZuXOnyaZ97rnnTHB23bp1kjZtWpkxY4Y8+uijsnHjRsmTJ0+s5w0YMED69OkTLaM2f/78kiNHDjMZWUAcPhyY1wkVOXP6Zjv0uz39ruj7xKHv7UG/24e+D42+T0CaNGnEWwRqAQAAgCDSt29f6dChQ4LrFClSxEwgtmzZMjlz5ow7yDplyhRZtWqVvP/++ybgG5OWR9AlJs3G1SUgXK7AvE6o8NW40O+J48vfB/o+ceh7e9Dv9qHv7RMemH2fxOxjEagFAAAAgohmt+pyKzppWFw7/3o7YPVmAQAA4DMBOm0OAAAAwJeqVKliatG2b99etm7dKn/++ae89NJLsn//fmnUqJHdzQMAAEAiEagFAAAAHCh79uxm4rCLFy/Kgw8+KBUrVpQffvhBlixZIvfee6/dzQMAAEAiUfoAAAAAcCgNzq5YscLuZgAAAMAHyKgFAAAAAAAAAJsRqAUAAAAAAAAAmxGoBQAAAAAAAACbEagFAAAAAAAAAJsRqAUAAAAAAAAAmxGoBQAAAAAAAACbEagFAAAAAAAAAJsRqAUAAAAAAAAAmxGoBQAAAAAAAACbEagFAAAAAAAAAJsRqAUAAAAAAAAAmxGoBQAAAAAAAACbEagFAAAAAAAAAJsRqAUAAAAAAAAAmxGoBQAAAAAAAACbEagFAAAAAAAAAJsRqAUAAAAAAAAAmxGoBQAAAAAAAACbEagFAAAAAAAAAJsRqAUAAAAAAAAAmxGoBQAAAAAAAACbEagFAAAAAAAAAJsRqAUAAAAAAAAAmxGoBQAAAAAAAACbEagFAAAAAAAAAJsRqAUAAAAAAAAAmxGoBQAAAAAAAACbEagFAAAAAAAAAJsRqAUAAAAAAAAAm0XY3QAAAAAAycjSpXa3IHmi3+1D39uHvrcH/W4f+t7xyKgFAAAAAAAAAJsRqAUAAAAAAAAAmxGoBQAAAAAAAACbEagFAAAAAAAAAJsRqAUAAAAAAAAAmxGoBQAAAAAAAACbEagFAAAAAAAAAJs5MlB74MAB6dSpkxQuXFjSpk0rRYsWlaFDh8q1a9eiredyuWTixIly1113SerUqeXOO++UUaNGJbjtQoUKSVhYWLRl7Nixfn5HAAAAAAAAAJKzCHGgXbt2SVRUlEybNk2KFSsm27Ztk86dO8ulS5dMYNbSq1cvWblypbmvbNmycvr0abPcyogRI8z2LHfccYff3gsAAAAAAAAAODJQ26BBA7NYihQpIrt375apU6e6A7U7d+40tzWIW6JECXOfZuB6QwOzuXPn9lPrAQAAAAAAACAEArVxOXfunGTNmtV9e+nSpSaAu2zZMhPU1TIIdevWlfHjx0dbLy5a6mDkyJFSoEABeeKJJ6R3794SERF/V129etUslvPnz5ufmvWriz/p9vW9+ft14FuMmzMxbs7DmDkT4+ZMgRw3PhsAAAAIRSERqN27d69MmjQpWtmDffv2ycGDB2XhwoXywQcfyM2bN03AtWXLlrJmzZp4t9WzZ0+pUKGCCeb+9NNPMmDAADl27Ji8/vrr8T5nzJgxMnz48Fj3nzp1Sq5cuSL+PlDRILUeGIWHO7LkcLLEuDkT4+Y8jJkzMW7OFMhxu3Dhgl+3DwAAANghzKV700Gif//+Mm7cuATX0ZIGJUuWdN8+cuSI1KpVS2rXri0zZsxw39+lSxd57733TEkEnUxMbd68WSIjI02NW6scwq3MmjVLunbtKhcvXjQTknmbUZs/f345c+aMZMyYUfx9UKQB4Rw5cnAw6yCMmzMxbs7DmDkT4+ZMgRw33dfKkiWLCQz7e18r1GlfZsqUib4EAAAIgv2toMqo7du3r3To0CHBdbScgeXo0aPywAMPSNWqVWX69OnR1suTJ48pV2AFaVWpUqXMz0OHDnkdqK1cubLcuHFDDhw4EO9zNIAbVxBXD1ICcYAZFhYWsNeC7zBuzsS4OQ9j5kyMmzMFatz4XAAAACAUBVWgVjMwdPGGZtJqkFYzZGfPnh1rh71atWomwPrXX39J0aJFzX1//vmn+VmwYEGv2/Tbb7+ZbefMmTNR7wUAAAAAAAAAvOXIdAQN0mqpA53sS+vS6mV2x48fN4tFJw7TWrNPP/20bNmyRTZt2mRKGDz00EPuLNtffvnFlFHQ7an169fLm2++KVu3bjU1bufOnWvq2rZt29ZcXgcAAAAAAAAAIZ9R661Vq1aZCcR0yZcvX7THrJK7mgW7dOlS6dGjh9SsWVPSp08vDz/8sLz22mvudS9fvmxq2F6/ft3c1vIF8+fPl2HDhpmas4ULF7ImeLgAACnwSURBVDaB2j59+iSqfVYbtAZFIOrB6YQaadKk4TJAB2HcnIlxcx7GzJkYN2cK5LhZ+1hBNNWCYwVyvxUAACA5Op+IfdegmkwsVPz9999mMjEAAAD4z+HDh2OdtEfisN8KAAAQPPuuBGr9lFGiE53dcccdZlINf0fldedaB5uZep2DcXMmxs15GDNnYtycKZDjpruvmr2bN29esq4dtN8azPjesQf9bh/63j70vT3od/vQ95KofVdHlj4Idtrpgc7u0A97cv3AOxnj5kyMm/MwZs7EuDlToMYtU6ZMfn+N5MCO/dZgxveOPeh3+9D39qHv7UG/2ye5930mL/ddSUEAAAAAAAAAAJsRqAUAAAAAAAAAmxGodbjUqVPL0KFDzU84B+PmTIyb8zBmzsS4ORPjBifj82sP+t0+9L196Ht70O/2oe8Th8nEAAAAAAAAAMBmZNQCAAAAAAAAgM0I1AIAAAAAAACAzQjUAgAAAAAAAIDNCNQCAAAAAAAAgM0I1AbYmDFj5L777pM77rhDcubMKU2bNpXdu3dHW+fKlSvy3HPPSbZs2SRDhgzSokULOXHiRLR1Dh06JI0aNZJ06dKZ7bz00kty48aNaOt8++23UqFCBTOzXrFixWTOnDmx2vPOO+9IoUKFJE2aNFK5cmX55Zdf/PTOQ8vYsWMlLCxMXnjhBfd9jFtwOnLkiLRt29aMS9q0aaVs2bLy66+/uh/X+RSHDBkiefLkMY/XrVtX9uzZE20bp0+flieffFIyZswomTNnlk6dOsnFixejrfP7779LjRo1zJjkz59fxo8fH6stCxculJIlS5p1tB1fffWVH9+5M928eVMGDx4shQsXNuNRtGhRGTlypBknC2Nmv++//14effRRyZs3r/ku/Pzzz6M9Hkxj5E1bkouExu369evy8ssvmz5Mnz69Waddu3Zy9OjRaNtg3AAAAAA/ciGg6tev75o9e7Zr27Ztrt9++83VsGFDV4ECBVwXL150r9OtWzdX/vz5Xd98843r119/dd1///2uqlWruh+/ceOGq0yZMq66deu6tmzZ4vrqq69c2bNndw0YMMC9zr59+1zp0qVz9enTx7Vjxw7XpEmTXClSpHAtX77cvc78+fNdqVKlcs2aNcu1fft2V+fOnV2ZM2d2nThxIoA94jy//PKLq1ChQq577rnH1atXL/f9jFvwOX36tKtgwYKuDh06uDZs2GD6d8WKFa69e/e61xk7dqwrU6ZMrs8//9y1detWV+PGjV2FCxd2/ffff+51GjRo4Lr33ntdP//8s2vdunWuYsWKudq0aeN+/Ny5c65cuXK5nnzySfO7PW/ePFfatGld06ZNc6/z448/mrEcP368GdtBgwa5UqZM6frjjz8C2CPBb9SoUa5s2bK5li1b5tq/f79r4cKFrgwZMrjeeust9zqMmf30+2vgwIGuzz77TCPorsWLF0d7PJjGyJu2JBcJjdvZs2fN36cFCxa4du3a5Vq/fr2rUqVKrsjIyGjbYNwAAAAA/yFQa7OTJ0+ag6XvvvvOfaCkBysanLDs3LnTrKMHTdaBVnh4uOv48ePudaZOnerKmDGj6+rVq+Z2v379XHfffXe013r88cdNoNiiB2DPPfec+/bNmzddefPmdY0ZM8aP79jZLly44CpevLhr1apVrlq1arkDtYxbcHr55Zdd1atXj/fxqKgoV+7cuV0TJkxw36djmTp1ahNcUBpE0HHcuHGje52vv/7aFRYW5jpy5Ii5PWXKFFeWLFnc42i9dokSJdy3H3vsMVejRo2ivX7lypVdXbt29dG7DQ3aR08//XS0+5o3b26CPooxCz4xA37BNEbetCW5iivAHteJSV3v4MGD5jbjhuRCP4NKT/AisOh7++l3vSaYILDo9+D47kHg0fexUfrAZufOnTM/s2bNan5u2rTJXH6ol/hZ9NLAAgUKyPr1681t/amXCebKlcu9Tv369eX8+fOyfft29zqe27DWsbZx7do181qe64SHh5vb1jqITUsbaOmCmH3LuAWnL774QipWrCitWrUypSbKly8v7733nvvx/fv3y/Hjx6P1Z6ZMmUw5Cc9x08t7dTsWXV/7fcOGDe51atasKalSpYo2blrW5MyZM16NLf6natWq8s0338iff/5pbm/dulV++OEHefjhh81txiz4BdMYedMWJLyPoiUSdKwU44bkQj/3+pl+5JFHzOfWs/wO/Iu+D3zJqZila/T7OGb5NvgW/R48rDKE+t2zcuVKmTBhgt1NSjbo+/gRqLVRVFSUqXFarVo1KVOmjLlPD0z04MY6KLJocE8fs9bxDPZZj1uPJbSOBgX/++8/+eeff8wfiLjWsbaB6ObPny+bN282dYZjYtyC0759+2Tq1KlSvHhxWbFihXTv3l169uwp77//vnnc6rOE+lN/apDXU0REhDm54ouxZdyi69+/v7Ru3dqc6EiZMqUJruv3pNbEVIxZ8AumMfKmLYib1l3XmrVt2rQx9WgV44ZQpft2r7zySrT7jh07ZuaUyJIli9lnh3/Q9/bR+uEdO3Y03/eeJ+i077VOecxgInyDfg8OVp1+3Y+5evWq+f+oUaPMPDHwL/r+1gjU2pyduW3bNhMARHA7fPiw9OrVS+bOnWsmPoEz6M69Tsw2evRoE/Dr0qWLdO7cWd599127m4Z4fPLJJ+b37OOPPzYnRjSoPnHiRHdwHYD/6RUijz32mMlk05NdQKjvK+i+nU4Uq/sLlpMnT5oThipFihQ2tjB00ff2KlGihMybN09efPFFuXz5srnv7Nmz7mAJfe8f9Lv9du7caZJAdF9HWX2vGZ46KTj8h773DoFamzz//POybNkyWbt2reTLl899f+7cuc3l7fpl7Ukvg9DHrHViXhZh3b7VOpoVo7MnZ8+e3fwRiGsdaxv4P1puQHcaNeinZ350+e677+Ttt982/9csH8Yt+Ohs4aVLl452X6lSpeTQoUPm/1afJdSf+lPH3pP+IdGZz30xtoxbdC+99JI7q1ZLhTz11FPSu3dvdyY7Yxb8gmmMvGkL4g7SHjx4UFatWuXOplWMG0KRlu7Q5Ak9iTtkyBAZOXKkuV9PVFgBE+vyTPgWfW+vJk2amOPRmTNnSt++fc19mt2mlyEryk74B/1uv4IFC8qMGTNk48aN5sohi/a9FSzU/SHGwvfoe+8QqA0w/cBpkHbx4sWyZs0aKVy4cLTHIyMjzRlkrdFo0bpuGliqUqWKua0///jjj2gHS9bBlBWU0nU8t2GtY21DL9PX1/JcR89q621rHfyfOnXqmD7/7bff3IvW6NOzQdb/Gbfgo2VFdBw8ae1T/QOh9PdPD/o9+1PLTGhtNM9x0wC8Bust+rur/a71Eq11vv/+e/NHxXPc9Iy5XrbnzdjifzSzQA/cPOnBmnXpI2MW/IJpjLxpC2IHaffs2SOrV6+WbNmyRXuccUOoiHk5ve5f6YnBSZMmyfDhw82J+Bw5cpjPrM4jsHfvXvn333/NJfk///xztEuWkTj0vX3iKiOhdVEXLVokc+bMMeVuNDCuySH6Pf7TTz+Zvwc6Dl999RWlZ5KIfg8eVvAvXbp00rhxY5MIonNhWNmdesxh1djXY3sreG5dno+ko+8TKY4JxuBH3bt3d2XKlMn17bffuo4dO+ZeLl++7F6nW7durgIFCrjWrFnj+vXXX11VqlQxi0VngyxTpoyrXr16rt9++821fPlyV44cOVwDBgxwr6MzpaZLl8710ksvuXbu3Ol65513XClSpDDrWubPn29mUJ4zZ46ZZbJLly6uzJkzu44fPx7AHnGuWrVquXr16uW+zbgFH52xPCIiwjVq1CjXnj17XHPnzjX9+9FHH7nXGTt2rOm/JUuWuH7//XdXkyZNXIULF3b9999/7nUaNGjgKl++vGvDhg2uH374wVW8eHFXmzZtos1GnitXLtdTTz3l2rZtmxkjfZ1p06a51/nxxx9NWyZOnGjGdujQoa6UKVO6/vjjjwD2SPBr3769684773QtW7bMtX//ftdnn33myp49u6tfv37udRgz+124cMG1ZcsWs+iuxOuvv27+f/DgwaAbI2/aklwkNG7Xrl1zNW7c2JUvXz7zN8pzH+Xq1avubTBucLqbN2+an0ePHjWf46+//tp9n5o8ebLZ99L9df1858+f35U1a1ZXoUKFzGdb/0b9/fffNr4D56Lv7WP186FDh1wrVqxwffjhh67Tp0+7v1OXLl3qSpMmjStDhgzmu1b7PGfOnGYctN9z587tOnDggM3vwnno9+AahytXrkT7efHiRbOfkidPHrOfcc8997gqVarkatGihevhhx92NW3a1CzPPPNMtO8qeI++TxoCtQGmB0ZxLbNnz3avo1/czz77rCtLlizm4KZZs2bmQMmTfmHrBzht2rQmiNG3b1/X9evXo62zdu1aV7ly5VypUqVyFSlSJNprWCZNmmSCi7qO/mL8/PPPfnz3oR2oZdyCk+4AaYBcg9slS5Z0TZ8+PdrjUVFRrsGDB5sDAF2nTp06rt27d0db599//zWBCN2Jypgxo6tjx44m4OFp69atrurVq5tt6I6VBhli+uSTT1x33XWXGbe7777b9eWXX/rpXTvX+fPnze+Vfr51x1V/BwYOHBgtUMSY2U+/p+L6W6aB9mAbI2/aklwkNG56YiS+fRR9noVxg5Pp58r6jBYsWNB8BjUoWKJECde8efPMiQY1Y8YM8/l+4oknzH1//fWX688//zQnfTkxnjT0fXD0vQb+ypYta/pYA+GvvvqqCSIqDSTqCTINjuh9J06cMEFF/XnmzBmb34Xz0O/BwQry6cljPT6vW7euq379+iZxzkqm0oChHi+GhYWZfZaRI0e6evfubRJF+vTp49q+fbvN78KZ6PukC9N/EpuFCwAAAABOc+rUKalZs6Y0b95cOnXqZCaz6tOnj2zdutXUR9cSZVr2Y9q0adK9e3czQ7tO+oPbR9/b58yZM1K3bl2zaF1UnfeiX79+sm7dOilZsqQpO1GoUCH5+uuvpVmzZtKtWzfT/9alyEga+j04aCkJLVWo3zOZMmWS/fv3m9ITgwcPlmeffdaMy8KFC02tbP2O0hqq8A36PoluI8gLAAAAAI6h2Tl6ebGWqfL08ssvm6ye8ePHm0sz9Yqnd99912T5TJgwwbb2hhL63j5a4kYzmVevXh3rKr3777/flOc7efKkuU9LUmjf65V/VlYokoZ+t5fVj4MGDTLlBz1pqZVs2bKZkoNWOQrN7tTvqIceeijWNpA49P3tiUhqgBcAAAAAnEQnutOJe3TySvXff/+ZSXzGjh1r/j9lyhQz0c8999xjJrnSzLb777/f7mY7dhIlzwlCdVIY+t4eOg46ic/Ro0fNbR2HiIgIk8WsE7TNnDnT9H2TJk2kQYMGsnLlSsmXL597Qh8kDf1uL6sf9fvFYo3Bc889Z35qVr9OYqpZ/I0aNTLfUxMmTJAjR47InXfeyVgkEX1/eyh9AAAAACDk6GFOXAd6lSpVkgwZMsiaNWvMbT04TJ06tfn/fffdJ0WLFpX58+cHvL2hGKQ9duyYufy7dOnS7v6944476PsA9L0GxDUYYl1Gr8HAw4cPy9q1a80lyFbQRDVs2NAEVPQx+ObEhOXRRx81gSf63T5vv/22DBo0SHbt2iV58+aVa9euuX8vRowYYcpNbN++XQoWLGgC6HpCT7+ncPsmTZokAwcOpO8TKfY3CQAAAAA4PGiiQdpLly7JhQsX5Pz58+7HtAaqHhg+8cQT5rYGCjV4orRGnpXxiaTTgJUGp8qWLWsCJD///LO5/7333pM//viDvvdzsHDbtm3y2GOPmX7X3wGl2Ztnz56VVq1amWCJFSxUmtV58+ZNsyDp/f7333/LJ598Ip999pls2bLFPDZ79mz6PYDjEBet/Vu+fHlp0aKF/PvvvyZQqEFB1aVLF8maNats2rTJ3Nba2QQKfdf3zzzzjERGRtL3iUSgFgAAAEDIBU127NhhJq6qVauWlCpVSubOnWse1/+/9dZbsmrVKhM80QweKxPu5MmTkj59ehM85MLD259E5ty5c2aZOnWqCVyVK1dOJk+eLMuXLzeTJ9H3vqV9qSchatSoYS6h18uKtU+VTtrz8ccfm8fr1atnxscKmGjwXAMkBAyT/n2jfVi9enVz6bZOkjR06FD5888/3f2+c+dO+j0A46B9/vLLL0vHjh3N97z2twYHdTx0nccff1xOnz5tgoLWySL9HWECt9vve50o7I033jAT5y1YsMA8pv2st/XEKX3vPUofAAAAAAipcgcapNUMzXbt2pkZpzVjRy/B3LBhg8ms0szNb775xgRUtAyCzsCuB4tffvmlyUIsU6aM3W/F8fSAXIMlWntQs5i1j4cNGybFixeXJUuWyCuvvGICVBo4p+99Q7Nn9eSElpDQmr9KLznWwKAGDDV4q4FazbbVIHmWLFkkT5485nfhxx9/NPWBkXgHDx6UatWqmdrKmkH+/fffy9NPP20+51pqRdHv/qff+1WrVpUqVaqYAODq1atNNmeHDh3M2CxbtkxGjhwpp06dknfffVdSpkxpyrDMmDHD/G0oUKCA3W/B0ScqtJRHiRIlTDkP/S4fPXq0CZrr97xmmWsQ9/jx4/S9FwjUAgAAAAipAGGbNm1MYFAzqiwPPPCAuRRf6xVatCzCq6++6s7y0UlNrHqqSDo9MNc+1QxDPRj/5ZdfZMyYMSYgtXfvXsmVK5c5QNcahXpZOH3vG1rzt27duuYzrn2tQXIdB83mvPvuu6Vz587SqVMns66euNBJrjSrTX9fNMCCpJk+fbrMmzfPfNatutja91oXWPtX62/Wrl3b3E+/+56GtDQArp9tnaBQx0Ppd40Gzvft22cuwddL7fV3QYO1GsTVgLkGDD/44AOpUKGC3W/D0Scq9HtHTxLp97wGbmfNmmVOxn333XfmM65j9Pvvv5uMc500j75P2P8VSAEAAAAAh9MDdg3+tWzZMlrGj14GrkErpQeNuuhlx+PGjYu2Hm6f9mOOHDnMBGFaL1XLHGhgqn379ia788033zR9rwftir73Df3c7969W/755x956aWXzH0aENfAoAYRNWiVLl06EyDs0aOH3c0NGfpdcujQIfntt99Mxv6oUaPk66+/NjVpdUz0MT0hpIFy+t33NDiuWfknTpww3/PWmBQrVsxMVqVlDzQgmD9/fnn44YdNKQrNNM+YMaN5nmabI2n0u1sngNS+1sCs9T2u3/0aiPUco3vvvVc++ugj+t4L/DUEgCTQS2gKFSqUpOfqZX9xzUIdTPS96XsEAMBpNFtTDwa1Tqey6j/eeeed7oNI/Tus//ecZCzY/zY7idWXKVKkkG+//db8Xy991bHQS1x/+ukn9wRjnuvj9uTMmVPq1KkjX3zxhanN2bt3b5NZ26BBA+nZs6fJetPL8rUOsDX5DxfY3j6tPZs7d25T2kBPEA0ePFgWL15sMge1pEfr1q1NcFAD6PS77+n3ip6g09IeejJOM8uV9rV+3+h46P/nzJnjfo5meebNm5dA4W3Sv6NaakLrj2fKlMl9v2bw68R5x44di/UcvdqFvk8YgVoAIUV39L1ZrIOG5ELfr7d9E+y0rqAGu5PbGAIAvKd1UJUenFtZPRoY0QmrLHqJpmYbatBKOeFvoFNYQagHH3zQZNJqLeCvvvrK1ArWzEK9HPb99993B1Toe9/QftSJe2bPnm0ChJrRadEglp7E0DqeGkD3PGmB26NZnHpySDNptcayznCvZQ+0bzV4rkGpM2fOmHrY9Pvts4Ld1kk4/Tzr97xm7GuAXGtiWyfjdJ0iRYqY7/tPP/3U1ApW9L9v+l5pPXjt35gnILSPNYBu0ZrMWh8Yt0bpAwAh5cMPP4x2Wy9z0VmdY96vE1fcjvfee8/9hyqx9LKz/v37SyDp+43ZBwMGDDA7jAMHDoy1vl42F6yXIGqgdvjw4eb/Vr0vAADion/LrAnGrNtqyJAhJmC4ZcsWk/UD37L6WwNYOqGYBgh1Ih+9rYt1GawGceFbOnmeXnZfq1YtU6tTg1Sa3aY0aHLXXXeZkxOelyXj9lmfbT358+uvv5oguTWbvV6Sr1ereQa3kDRWmZQ///xTli5dKk888YSZmE3pZ15L2WgmuZb40Lq0GsRVWmpFs2h1kjH4vu+tv7O66PeLnoTTvtcSB0rLIowdO1b+/vtvm9+FM7BXAiCktG3bNtptvaxOA7Ux748r+Kd/0L11Ozu3ekAY6INCPUCK2Qf6x1IvOYmrbzhwAgCECusAUv/2ao3CiRMnmrqFGkzRYCH8Ry+J1cCVBg/1EnxrLJo2bWp300Kalv3QK4+0Fu3TTz9tJtHTwKGWRPjhhx8I0vpR1apV5cUXXzQTGWo5BK3RrBnOWnKCIOHt00ChThKm3y2apfzvv/9Knz593JfR66SEly5dMhOH6SRXOsGVTua2cOFCc6KCMfBP33tmKOt6GqTV73v9u6uTt+kEhxs2bDDZ5bi14EyXAgA/0ixMvSxJL7/TSzU0QKtn+dSSJUvMLK36R0SDlUWLFjV/XGKeAY9Zo/bAgQPmD5Qe/Gn2gj5Pn6+F1Ddu3HjLGrV6+/nnn5fPP//ctE2fq9kPy5cvj9V+3fHWAx6dIVlfRy/v8XXd25g1arWmk25fd+61xplOEJI5c2bp2rWre6KEdu3amRk8denXr1+s2lt6FlYnD9H3pW3X4LE+X//Qe9ID5/r165s/+jpzq2Yn6EGG1c/62kqzaq0zt/r+LVqgXuuDZc2a1byO9pUemHiy3o/uNGsbsmXLZs746ntITHsAAMHPyqLV4JReEaOZtPr3jJmm/U/7XPcnNEiruNw4cHQfVycQ0/qpGrDSq6j0c6/7mfCf0qVLuy+/12OIX375xZT60GA5bp8GYfUy+8aNG8vkyZNN4omeeLMuqdfjOr16Uff19STRo48+KtWqVTNXWS5YsMB9HAHf9b3WXo75N1ePwfTYSgPn+jdXj1/1uBjeIaMWQLKkZwB11k8t7q8ZpRo0VPpHXXdk9eyg/tQdXL08UicbsWYmTohOFHDhwgUT/NODEf3jpWdy9+3bd8vsBd151ok2tI6bXp6jZx61xpXOFKuBRKWXaOqEEHqZiQYqNYA8YsSIgO106Ey1mh2gr63ZyhqU1oCtTgqixfpHjx5tatBpX+mBgAY+Ldon2r96CaQGe/fv32/+yOt7+vHHH03/aO1APaDQ96PlIXTbGpzVflF6/9SpU80ffZ1BWvtWWQeAWndKd8Z0whh9vp41/+STT0zmzqJFi8xzPGlwXF9DA71a7kG3rQczVk3fW7UHAOAcetJNJ5XRv1kaTEFgBGsppeRAL/XWYKFVrouxCIwHHnjABGg1g1OTL3T/Eb6hn+HIyEhzbPT444+bRAo9nlMvvfSS2WfXdfQYRE9W6HGUXjmpgXI9PoB/+l6TdKysZj0+PXfunDn+vXjxojnW40RFIrkAIIQ999xzmtYZ7b5atWqZ+959991Y61++fDnWfV27dnWlS5fOdeXKFfd97du3dxUsWNB9e//+/Wab2bJlc50+fdp9/5IlS8z9S5cudd83dOjQWG3S26lSpXLt3bvXfd/WrVvN/ZMmTXLf9+ijj5q2HDlyxH3fnj17XBEREbG2eSt333236Yu46HvT92iZPXu22X79+vVdUVFR7vurVKniCgsLc3Xr1s19340bN1z58uWLtu1169aZ58+dOzfa6yxfvjza/YsXLza3N27cGG+7T506ZdbRfoypTp06rrJly0YbK21v1apVXcWLF4/1fiIjI13Xrl1z3z9+/Hhzv46bt+0BADjHxYsX7W4CAMCH3+Pz5883xyMvvviiOU5Q169fdx08eNCmFibPvv/nn3/cfa/joMd527Zts6mlzsYpNQDJkp7d1szOmPTSdotmxuqlHFrnS8/E6iX1t6JnF/XSf4s+V+kZxVupW7euKWVg0SxRvWTEeq6enVy9erXJDvWs71OsWDGTHRwInTp1inbZYuXKlU2JA73fojWJtNyA53vWulCZMmWShx56yPSptehZWc1cXrt2rVnPyjjQCUc8Zwn1xunTp00G9GOPPeYeO100e1qzqPbs2SNHjhyJ9hytX+WZ6ayZulpLSbOCb7c9AIDgQ31CAAiN73E9NtLjED3+0qsaX3vtNXM149GjR02Gp04qppfrxyzHBv/0vU7kZvW9HmPpcbA1kSESh9IHAJIlvfTFmonVk146r3WNNOCn5Q486SUct6KX/3uygrYx655681zr+dZz9TL8//77zwRmY4rrPn+I2UYNviqdnCXm/Z7vWYOk2n85c+aMc7v63qzZWrXcg5ZWeOONN0w9YQ1M66yit5rgTIvb6w6DXtaqS3yv43nZU/HixaM9rkFjLSuh5Q1utz0AAAAA/MOasEpLe+gl+JpM8tRTT5m5Kf766y8zTwgn5wLf93pMpnN8JGaibkRHoBZAsuSZOWvRCbE0MKdZrFr3VbNbtRD65s2b5eWXX3bX97rVH624eHMm93aeGyjxtTGu+z3brX2nQdq5c+fG+Xyrxq7+kf/0009N/dulS5fKihUrzMRdepZW79NAanys8dGZdjWDNi6JDWjfTnsAAAAA+I91pZ+V3anzZ/z222/m+I26qPb0PTVpbx+BWgD4/3QCKb1MXieK0uLzFp30KhhooFMDx3qWMqa47gsmGvTWsg060VdcQfKY7r//frOMGjXKXE7z5JNPyvz58+WZZ56Jd8boIkWKmJ9aykDLSHhDM311wgeLFrw/duyYNGzY0Ov2AAAAALCHHhvopfg6mZiWU9NgIYHCwKDv/YMatQAQIyvUMxP02rVrMmXKFAmW9mkA8vPPPzf1fzyDtF9//bUEM60bq3/EdebhmG7cuGGymZWWS4iZQVyuXDnz8+rVq+andRmN9RzPQLaWJpg2bZoJtsZ06tSpWPfpmV/P2rNTp0417bFq/nrTHgAAAAD20nqomkmr83wgsOh73yKjFgD+v6pVq5qasO3bt5eePXuaM4QffvhhUJUeGDZsmKxcudJkpurEVxr8nDx5spQpU8acwQxWWlKia9euMmbMGNPOevXqmcxXzWjVicbeeustadmypbz//vsmMN6sWTOThauTgr333numHIWV5aoZuaVLl5YFCxbIXXfdJVmzZjXvX5d33nlHqlevbs7kdu7c2WTZnjhxQtavXy9///23bN26NVq7NBBfp04dE0jevXu3eW19fuPGjc3j3rQHAAAAgL0JLVqeLL4r7+A/9L3vEagFgP8vW7ZssmzZMunbt6+ZUEyDtm3btjWBvPhqngZaZGSkyZ7VOqw6YZZO4qX1dHfu3Cm7du2SYPbuu++a9mvG6yuvvCIRERFSqFAh08caeLYCur/88ospK6ABVp2UrFKlSqa2beHChd3bmjFjhvTo0cPM5qrB1qFDh5pArQZwtXi9Tv41Z84cU8pCM23Lly8vQ4YMidUmDXLrtvUxzaxt06aNvP322+4dDW/bAwAAAMA+BArtQ9/7VpgrmFLFAABJ0rRpU9m+fbvJUMWtaRC3Y8eOZjbYihUr2t0cAAAAAACoUQsATvPff/9Fu63B2a+++srUZwUAAAAAAM5E6QMAcBitu9qhQwfz8+DBg2YCrFSpUkm/fv3sbhoAAAAAAEgiArUA4DANGjSQefPmyfHjxyV16tRSpUoVGT16tBQvXtzupgEAAAAAgCSiRi0AAAAAAAAA2IwatQAAAAAAAABgMwK1AAAAAADglsLCwuT5558P6GseOHDAvO7EiRMl0HReiEKFCgX8dQEkXwRqAQAAAABI5v766y/p2rWrmbA2TZo0kjFjRqlWrZq89dZb8t9//9ndPMf56quvZNiwYXY3A4DDMJkYAAAAAADJ2JdffimtWrUyE9W2a9dOypQpI9euXZMffvhBXnrpJdm+fbtMnz5dkpv33ntPoqKikhyofeeddwjWAkgUArUAAAAAACRT+/fvl9atW0vBggVlzZo1kidPHvdjzz33nOzdu9cEcpOjlClT2t0EAMkMpQ8AAAAAAEimxo8fLxcvXpSZM2dGC9JaihUrJr169Yp23+eff26ybjUD9+6775bly5fHet6RI0fk6aeflly5crnXmzVrVqz1rly5YrJO77rrLlNyQdvQvHlzU4ohPi6XS7p06SKpUqWSzz77zNw3Z84cU8v2+++/NyUcsmXLZso3aIbwmTNnYm1jypQppk3atrx585qg9NmzZxOsUetZL1czjIsWLWqef99998nGjRujPU+zaZWuby0AcCtk1AIAAAAAkEwtXbrU1KWtWrWqV+trOQQNjj777LNyxx13yNtvvy0tWrSQQ4cOmeCoOnHihNx///3uycdy5MghX3/9tXTq1EnOnz8vL7zwglnv5s2b8sgjj8g333xjsno1IHzhwgVZtWqVbNu2zQRCY9LnaAB4wYIFsnjxYmnUqFG0x/X1MmfObIK/u3fvlqlTp8rBgwfl22+/dQdL9bHhw4dL3bp1pXv37u71NNj6448/3jKT9uOPPzbt1ICwblOD3Rpc3rdvn3mu3n/06FHzPj788EOvxwIACNQCAAAAAJAMadBUM1+bNGni9XN27twpO3bscAdRH3jgAbn33ntl3rx5JkiqBg4caAKqf/zxhzt4261bN2nTpo0JkmogM23atPLBBx+YIO3rr78uvXv3dr9G//79TdZsTDdu3JC2bdvKF198YZZ69erFWkezbHWbVrBVSzr069fPBKQbN24sp06dkjFjxpjnavA4PPx/FxqXLFnStP+jjz6Sjh07JtgHGpTes2ePZMmSxdwuUaKE6cMVK1aYwHOVKlVMhrAGarW9AOAtSh8AAAAAAJBMA7VKM2O9pVmonpmu99xzjykxoNmkSgOsixYtkkcffdT8/59//nEv9evXl3PnzsnmzZvNurpe9uzZpUePHrFeJ2apAJ3cTCc8W7ZsmZmoK64grdKSCJ4ZsZoxGxERYZ6jVq9ebbalWb1WkFZ17tzZvA9v6vE+/vjj7iCtqlGjhvlp9QEAJBUZtQAAAAAAJEMamFR6Gb+3ChQoEOs+DVpadWA1Y1VrvWoNV13icvLkSfNT69BqNqoGUm9Fs2C1lq5mwdauXTve9YoXLx7tdoYMGUzdW60vq7QMgtLXjZmJqyUgrMcT0wdW0DauWrgAkBgEagEAAAAASKaBWp1IS+vBeitFihRx3m+VKoiKijI/9ZL/9u3bx7muZuEmlmbj6qRlWg9WA7U68ZhdbtUHAJBUlD4AAAAAACCZ0pqqmtm6fv16n2xPJw7TUgpao1bLJMS15MyZ06yrJRR0Iq/r16/fcrs6Odnnn38uP/30kymBoPVq46K1Yz1pFu6xY8ekUKFC7pq1Sl/Xk5ZD2L9/v/vx2xWzdAMAeINALQAAAAAAyZROtJU+fXp55pln5MSJE7Ee1yDuW2+9lahs0xYtWpj6s3Fl6mppBIuup7VrJ0+e7FV2qgZ558+fbzJrn3rqKXf2rictt+AZ+J06daoJ6j788MPubWiZg7fffjvaa8ycOdPUz23UqJH4gvap0jIQAOAtSh8AAAAAAJBMaVbrxx9/bCbIKlWqlLRr107KlCljMkw1e3XhwoXSoUOHRG1z7NixsnbtWqlcubKZpKt06dJy+vRpM4mYTual/1f6Wh988IH06dNHfvnlFzMp16VLl8w6zz77rDRp0iTWtps2bSqzZ882z9XSDdOmTYv2uLa7Tp068thjj5ms2SlTpkj16tWlcePG7ozfAQMGyPDhw6VBgwbmfmu9++67z5Rs8IXIyEjzs2fPnqZsgwawW7du7ZNtAwhdBGoBAAAAAEjGNFj5+++/y4QJE2TJkiUmCzV16tSmluxrr71mgq2JkStXLhN4HTFihHz22WcmCJotWza5++67Zdy4ce71NHj51VdfyahRo0ywWLNwdT0NrJYtWzbe7WswVSdA02CuBmu13RbNzp07d64MGTLEZNa2adPGZM96liIYNmyYCdjqur1795asWbNKly5dZPTo0ZIyZUrxhebNm0uPHj1MBvBHH31ksncJ1AK4lTAX1a4BAAAAAICDzZkzRzp27CgbN26UihUr2t0cAEgSatQCAAAAAAAAgM0I1AIAAAAAAACAzQjUAgAAAAAAAIDNqFELAAAAAAAAADYjoxYAAAAAAAAAbEagFgAAAAAAAABsRqAWAAAAAAAAAGxGoBYAAAAAAAAAbEagFgAAAAAAAABsRqAWAAAAAAAAAGxGoBYAAAAAAAAAbEagFgAAAAAAAABsRqAWAAAAAAAAAMRe/w+qPL5yXNJwNwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1400x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize training progress\n",
    "if 'training_history' in locals() and len(training_history['timesteps']) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Plot 1: Validation MAE over time\n",
    "    ax1 = axes[0, 0]\n",
    "    ax1.plot(training_history['timesteps'], training_history['val_mae'], \n",
    "             marker='o', linewidth=2, markersize=8, label='Validation MAE')\n",
    "    ax1.axhline(y=llm_val_mae, color='r', linestyle='--', \n",
    "                linewidth=2, label=f'LLM Baseline: {llm_val_mae:.4f}')\n",
    "    ax1.set_xlabel('Training Timesteps', fontsize=12)\n",
    "    ax1.set_ylabel('MAE', fontsize=12)\n",
    "    ax1.set_title('Validation MAE During Training', fontsize=14, fontweight='bold')\n",
    "    ax1.legend(fontsize=10)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Validation MAPE over time\n",
    "    ax2 = axes[0, 1]\n",
    "    ax2.plot(training_history['timesteps'], training_history['val_mape'], \n",
    "             marker='s', linewidth=2, markersize=8, color='green', label='Validation MAPE')\n",
    "    ax2.axhline(y=llm_val_mape, color='r', linestyle='--', \n",
    "                linewidth=2, label=f'LLM Baseline: {llm_val_mape:.2f}%')\n",
    "    ax2.set_xlabel('Training Timesteps', fontsize=12)\n",
    "    ax2.set_ylabel('MAPE (%)', fontsize=12)\n",
    "    ax2.set_title('Validation MAPE During Training', fontsize=14, fontweight='bold')\n",
    "    ax2.legend(fontsize=10)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Average Reward over time\n",
    "    ax3 = axes[1, 0]\n",
    "    ax3.plot(training_history['timesteps'], training_history['val_reward'], \n",
    "             marker='^', linewidth=2, markersize=8, color='purple', label='Avg Reward')\n",
    "    ax3.set_xlabel('Training Timesteps', fontsize=12)\n",
    "    ax3.set_ylabel('Average Reward', fontsize=12)\n",
    "    ax3.set_title('Validation Reward During Training', fontsize=14, fontweight='bold')\n",
    "    ax3.legend(fontsize=10)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Improvement percentage over time\n",
    "    ax4 = axes[1, 1]\n",
    "    improvements = [((llm_val_mae - mae) / llm_val_mae * 100) for mae in training_history['val_mae']]\n",
    "    colors = ['green' if imp > 0 else 'red' for imp in improvements]\n",
    "    ax4.bar(range(len(improvements)), improvements, color=colors, alpha=0.7)\n",
    "    ax4.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
    "    ax4.set_xlabel('Checkpoint', fontsize=12)\n",
    "    ax4.set_ylabel('Improvement vs LLM (%)', fontsize=12)\n",
    "    ax4.set_title('Performance Improvement Over Baseline', fontsize=14, fontweight='bold')\n",
    "    ax4.set_xticks(range(len(improvements)))\n",
    "    ax4.set_xticklabels([f\"{ts//1000}k\" for ts in training_history['timesteps']], rotation=45)\n",
    "    ax4.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/ppo_training_progress.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"üìä Training progress visualization saved to ../results/ppo_training_progress.png\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No training history available to plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf16ed7",
   "metadata": {},
   "source": [
    "## 10. Apply PPO to Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "41a21fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data prepared: 2477 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>recent_prices</th>\n",
       "      <th>llm_prediction</th>\n",
       "      <th>actual_price</th>\n",
       "      <th>llm_likelihood</th>\n",
       "      <th>llm_justification</th>\n",
       "      <th>justification_pos_ratio</th>\n",
       "      <th>justification_neg_ratio</th>\n",
       "      <th>justification_risk_ratio</th>\n",
       "      <th>justification_polarity</th>\n",
       "      <th>justification_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HSBC</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>[31.07, 31.03, 31.21, 31.16, 31.63]</td>\n",
       "      <td>31.63</td>\n",
       "      <td>32.680000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Based on recent closing prices, technical indi...</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>3.891820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0700.HK</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>[304.1191, 309.8178, 318.3658, 317.226, 327.8636]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>342.870056</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PEP</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>[183.07, 181.75, 181.98, 180.66, 179.41]</td>\n",
       "      <td>181.00</td>\n",
       "      <td>178.970001</td>\n",
       "      <td>0.7</td>\n",
       "      <td>The stock price is likely to remain stable due...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.995732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>[130.03, 126.04, 129.61, 129.93, 125.07]</td>\n",
       "      <td>130.03</td>\n",
       "      <td>126.360001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>The predicted close price of 130.0300 is likel...</td>\n",
       "      <td>0.019355</td>\n",
       "      <td>0.038710</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>-0.019355</td>\n",
       "      <td>5.049856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7203.T</td>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>[1817.5, 1819.0, 1817.0, 1812.5, 1799.0]</td>\n",
       "      <td>1817.50</td>\n",
       "      <td>1807.500000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>The predicted close price is 1817.5. The likel...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.056338</td>\n",
       "      <td>4.276666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker        date                                      recent_prices  \\\n",
       "0     HSBC  2023-01-03                [31.07, 31.03, 31.21, 31.16, 31.63]   \n",
       "1  0700.HK  2023-01-03  [304.1191, 309.8178, 318.3658, 317.226, 327.8636]   \n",
       "2      PEP  2023-01-03           [183.07, 181.75, 181.98, 180.66, 179.41]   \n",
       "3     AAPL  2023-01-03           [130.03, 126.04, 129.61, 129.93, 125.07]   \n",
       "4   7203.T  2023-01-04           [1817.5, 1819.0, 1817.0, 1812.5, 1799.0]   \n",
       "\n",
       "   llm_prediction  actual_price  llm_likelihood  \\\n",
       "0           31.63     32.680000             0.8   \n",
       "1            0.00    342.870056             0.0   \n",
       "2          181.00    178.970001             0.7   \n",
       "3          130.03    126.360001             0.5   \n",
       "4         1817.50   1807.500000             0.8   \n",
       "\n",
       "                                   llm_justification  justification_pos_ratio  \\\n",
       "0  Based on recent closing prices, technical indi...                 0.041667   \n",
       "1                                                                    0.000000   \n",
       "2  The stock price is likely to remain stable due...                 0.000000   \n",
       "3  The predicted close price of 130.0300 is likel...                 0.019355   \n",
       "4  The predicted close price is 1817.5. The likel...                 0.000000   \n",
       "\n",
       "   justification_neg_ratio  justification_risk_ratio  justification_polarity  \\\n",
       "0                 0.000000                  0.000000                0.041667   \n",
       "1                 0.000000                  0.000000                0.000000   \n",
       "2                 0.000000                  0.052632                0.000000   \n",
       "3                 0.038710                  0.006452               -0.019355   \n",
       "4                 0.056338                  0.000000               -0.056338   \n",
       "\n",
       "   justification_length  \n",
       "0              3.891820  \n",
       "1              0.000000  \n",
       "2              2.995732  \n",
       "3              5.049856  \n",
       "4              4.276666  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare test data\n",
    "test_parsed = []\n",
    "for idx, item in enumerate(test_data):\n",
    "    parsed = parse_prompt_data(item['prompt'])\n",
    "    response = json.loads(item['response'])\n",
    "    llm_output = test_llm_results[idx] if idx < len(test_llm_results) else {}\n",
    "\n",
    "    if isinstance(llm_output, dict) and llm_output.get('predicted_close') is not None:\n",
    "        parsed['llm_prediction'] = safe_float(llm_output.get('predicted_close'), response['predicted_close'])\n",
    "    elif idx < len(test_llm_predictions):\n",
    "        parsed['llm_prediction'] = test_llm_predictions[idx]\n",
    "    else:\n",
    "        parsed['llm_prediction'] = response['predicted_close']\n",
    "\n",
    "    if idx < len(test_actual_prices):\n",
    "        parsed['actual_price'] = test_actual_prices[idx]\n",
    "    else:\n",
    "        parsed['actual_price'] = response['predicted_close']\n",
    "\n",
    "    llm_likelihood = safe_float(llm_output.get('likelihood') if isinstance(llm_output, dict) else None, response.get('likelihood', 0.5))\n",
    "    parsed['llm_likelihood'] = llm_likelihood\n",
    "\n",
    "    justification_text = llm_output.get('justification', '') if isinstance(llm_output, dict) else ''\n",
    "    parsed['llm_justification'] = justification_text\n",
    "    parsed.update(extract_justification_features(justification_text))\n",
    "\n",
    "    test_parsed.append(parsed)\n",
    "\n",
    "test_df = pd.DataFrame(test_parsed)\n",
    "\n",
    "# Ensure all required columns\n",
    "if 'recent_prices' not in test_df.columns:\n",
    "    test_df['recent_prices'] = test_df['llm_prediction'].apply(\n",
    "        lambda x: [float(x)] * 5 if pd.notna(x) else [0.0] * 5\n",
    "    )\n",
    "\n",
    "print(f\"Test data prepared: {len(test_df)} samples\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ce47fe37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying PPO adjustments to test set...\n",
      "‚úÖ PPO adjustments applied!\n",
      "‚úÖ PPO adjustments applied!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>llm_prediction</th>\n",
       "      <th>ppo_adjusted_prediction</th>\n",
       "      <th>actual_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HSBC</td>\n",
       "      <td>31.630</td>\n",
       "      <td>31.630000</td>\n",
       "      <td>32.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0700.HK</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>342.870056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PEP</td>\n",
       "      <td>181.000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>178.970001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>130.030</td>\n",
       "      <td>130.030000</td>\n",
       "      <td>126.360001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7203.T</td>\n",
       "      <td>1817.500</td>\n",
       "      <td>1817.500000</td>\n",
       "      <td>1807.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HSBC</td>\n",
       "      <td>31.630</td>\n",
       "      <td>32.262599</td>\n",
       "      <td>33.759998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PEP</td>\n",
       "      <td>181.750</td>\n",
       "      <td>185.384997</td>\n",
       "      <td>177.100006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>123.456</td>\n",
       "      <td>125.925118</td>\n",
       "      <td>125.019997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0700.HK</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>347.799988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>129.610</td>\n",
       "      <td>132.202198</td>\n",
       "      <td>129.619995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker  llm_prediction  ppo_adjusted_prediction  actual_price\n",
       "0     HSBC          31.630                31.630000     32.680000\n",
       "1  0700.HK           0.000                 0.000000    342.870056\n",
       "2      PEP         181.000               181.000000    178.970001\n",
       "3     AAPL         130.030               130.030000    126.360001\n",
       "4   7203.T        1817.500              1817.500000   1807.500000\n",
       "5     HSBC          31.630                32.262599     33.759998\n",
       "6      PEP         181.750               185.384997    177.100006\n",
       "7     AAPL         123.456               125.925118    125.019997\n",
       "8  0700.HK           0.000                 0.000000    347.799988\n",
       "9     AAPL         129.610               132.202198    129.619995"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply PPO adjustments to test predictions\n",
    "def apply_ppo_adjustment(model, test_df):\n",
    "    \"\"\"Apply trained PPO model to adjust predictions\"\"\"\n",
    "    adjusted_predictions = []\n",
    "    \n",
    "    env = StockPredictionEnv(test_df, window_size=5)\n",
    "    obs, _ = env.reset()\n",
    "    \n",
    "    for idx in range(len(test_df)):\n",
    "        if idx < env.window_size:\n",
    "            # For early samples, use LLM prediction as-is\n",
    "            adjusted_predictions.append(test_df.iloc[idx]['llm_prediction'])\n",
    "            continue\n",
    "        \n",
    "        # Get PPO action\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        \n",
    "        # Apply adjustment\n",
    "        llm_pred = test_df.iloc[idx]['llm_prediction']\n",
    "        adjusted_pred = llm_pred * (1 + action[0])\n",
    "        adjusted_predictions.append(adjusted_pred)\n",
    "        \n",
    "        # Step environment\n",
    "        if idx < len(test_df) - 1:\n",
    "            obs, _, terminated, _, _ = env.step(action)\n",
    "            if terminated:\n",
    "                break\n",
    "    \n",
    "    return adjusted_predictions\n",
    "\n",
    "print(\"Applying PPO adjustments to test set...\")\n",
    "test_df['ppo_adjusted_prediction'] = apply_ppo_adjustment(model, test_df)\n",
    "print(\"‚úÖ PPO adjustments applied!\")\n",
    "\n",
    "# Display results\n",
    "test_df[['ticker', 'llm_prediction', 'ppo_adjusted_prediction', 'actual_price']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc834473",
   "metadata": {},
   "source": [
    "## 11. Save and Evaluate Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c729ae95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Test predictions with PPO adjustments saved to ../results/test_predictions_with_ppo.csv\n",
      "\n",
      "üìä Quick Comparison:\n",
      "LLM MAE: 62.1152\n",
      "LLM-PPO MAE: 66.9459\n",
      "Improvement: -7.78%\n"
     ]
    }
   ],
   "source": [
    "# Save test predictions with PPO adjustments\n",
    "test_df.to_csv('../results/test_predictions_with_ppo.csv', index=False)\n",
    "print(f\"‚úÖ Test predictions with PPO adjustments saved to ../results/test_predictions_with_ppo.csv\")\n",
    "\n",
    "# Quick comparison\n",
    "llm_mae = np.mean(np.abs(test_df['llm_prediction'] - test_df['actual_price']))\n",
    "ppo_mae = np.mean(np.abs(test_df['ppo_adjusted_prediction'] - test_df['actual_price']))\n",
    "\n",
    "print(f\"\\nüìä Quick Comparison:\")\n",
    "print(f\"LLM MAE: {llm_mae:.4f}\")\n",
    "print(f\"LLM-PPO MAE: {ppo_mae:.4f}\")\n",
    "print(f\"Improvement: {((llm_mae - ppo_mae) / llm_mae * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220ecbb0",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "‚úÖ **What We Did:**\n",
    "1. Prepared training and validation datasets\n",
    "2. Trained PPO with validation-based early stopping\n",
    "3. Selected best model based on validation MAE\n",
    "4. Applied PPO adjustments to test predictions\n",
    "5. Saved results and training history\n",
    "\n",
    "üìä **Key Features:**\n",
    "- **Validation Monitoring**: Evaluates model every 20k timesteps\n",
    "- **Early Stopping**: Stops training if no improvement for 3 checkpoints (patience=3)\n",
    "- **Best Model Selection**: Saves and loads the model with lowest validation MAE\n",
    "- **Training Visualization**: Plots showing MAE, MAPE, reward, and improvement trends\n",
    "\n",
    "üéØ **Next Steps:**\n",
    "1. Load predictions in main notebook for detailed evaluation\n",
    "2. Compare with baseline models\n",
    "3. Analyze per-stock performance\n",
    "4. Calculate risk-adjusted metrics (Sharpe ratio, Sortino ratio, Max Drawdown)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
