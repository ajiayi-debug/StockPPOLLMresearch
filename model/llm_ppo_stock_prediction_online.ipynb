{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5259f2f7",
   "metadata": {},
   "source": [
    "# üöÄ Stock Price Prediction with Local Llama 3.1 8B\n",
    "\n",
    "This notebook uses a **locally-run Llama 3.1 8B model** for stock price prediction with PPO reinforcement learning.\n",
    "\n",
    "## ‚úÖ Compatible Environments\n",
    "- ‚úÖ **Google Colab** (Free/Pro)\n",
    "- ‚úÖ **Kaggle** (GPU enabled)\n",
    "- ‚úÖ **Local** (with GPU recommended)\n",
    "\n",
    "## üìã Requirements\n",
    "\n",
    "### Hardware\n",
    "- **GPU**: Recommended (T4, P100, or better)\n",
    "  - Free tier Colab/Kaggle GPUs work!\n",
    "  - ~6-8 GB VRAM with 4-bit quantization\n",
    "- **CPU**: Will work but much slower\n",
    "\n",
    "### Hugging Face Account\n",
    "- Create account: https://huggingface.co/join\n",
    "- Get access token: https://huggingface.co/settings/tokens\n",
    "- Request Llama 3.1 access: https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct\n",
    "\n",
    "### Data Files\n",
    "- Training/validation/test JSONL files\n",
    "- Supervised price labels CSV\n",
    "- See data setup instructions below\n",
    "\n",
    "## üéØ What This Notebook Does\n",
    "1. Loads Llama 3.1 8B locally with 4-bit quantization\n",
    "2. Performs stock price prediction using LLM\n",
    "3. Applies PPO reinforcement learning for risk-aware adjustment\n",
    "4. Evaluates performance on test stocks (AAPL, HSBC, PEP, Tencent, Toyota)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85888fb3",
   "metadata": {},
   "source": [
    "# Two-Stage Framework for Stock Price Prediction: LLM-Based Forecasting with Risk-Aware PPO Adjustment\n",
    "\n",
    "This notebook replicates the methodology from the paper:\n",
    "**\"A Two-Stage Framework for Stock Price Prediction: LLM-Based Forecasting with Risk-Aware PPO Adjustment\"**\n",
    "\n",
    "## Framework Overview:\n",
    "1. **Stage 1**: LLM-based stock price prediction using historical data, technical indicators, and sentiment analysis\n",
    "2. **Stage 2**: Risk-aware PPO adjustment incorporating VaR and CVaR to refine predictions\n",
    "\n",
    "## Dataset:\n",
    "- Training, validation, and test data from finetune_paper directory\n",
    "- Stocks: AAPL, HSBC, PEP, 0700.HK (Tencent), 7203.T (Toyota)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3dacb7",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d6804a",
   "metadata": {},
   "source": [
    "## Environment Detection (Colab/Kaggle/Local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e0affe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect environment\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Check if running on Colab\n",
    "IS_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "# Check if running on Kaggle\n",
    "IS_KAGGLE = 'kaggle_secrets' in sys.modules or os.path.exists('/kaggle')\n",
    "\n",
    "# Local or other environment\n",
    "IS_LOCAL = not (IS_COLAB or IS_KAGGLE)\n",
    "\n",
    "print(f\"üåç Environment Detection:\")\n",
    "print(f\"   - Google Colab: {IS_COLAB}\")\n",
    "print(f\"   - Kaggle: {IS_KAGGLE}\")\n",
    "print(f\"   - Local: {IS_LOCAL}\")\n",
    "\n",
    "# Setup paths based on environment\n",
    "if IS_COLAB or IS_KAGGLE:\n",
    "    # Mount/clone data if needed\n",
    "    BASE_DIR = \"/content\" if IS_COLAB else \"/kaggle/working\"\n",
    "    DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "    MODEL_CACHE_DIR = os.path.join(BASE_DIR, \"models\")\n",
    "    \n",
    "    # Create directories\n",
    "    os.makedirs(DATA_DIR, exist_ok=True)\n",
    "    os.makedirs(MODEL_CACHE_DIR, exist_ok=True)\n",
    "    \n",
    "    print(f\"\\nüìÅ Paths configured for cloud environment:\")\n",
    "    print(f\"   - Base: {BASE_DIR}\")\n",
    "    print(f\"   - Data: {DATA_DIR}\")\n",
    "    print(f\"   - Model Cache: {MODEL_CACHE_DIR}\")\n",
    "else:\n",
    "    # Local environment\n",
    "    BASE_DIR = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "    DATA_DIR = \"../finetune_paper\"\n",
    "    MODEL_CACHE_DIR = os.path.join(BASE_DIR, \"models\")\n",
    "    os.makedirs(MODEL_CACHE_DIR, exist_ok=True)\n",
    "    print(f\"\\nüìÅ Paths configured for local environment\")\n",
    "    print(f\"   - Model Cache: {MODEL_CACHE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fe448f",
   "metadata": {},
   "source": [
    "## Hugging Face Authentication (Required for Llama 3.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0ca37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face Authentication\n",
    "# Required to download Llama 3.1 8B model\n",
    "\n",
    "print(\"üîê Hugging Face Authentication\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nüìù IMPORTANT - Token Permission Requirements:\")\n",
    "print(\"   ‚ö†Ô∏è  Your token MUST have 'Read access to contents of public gated repos'\")\n",
    "print(\"   ‚ö†Ô∏è  This is REQUIRED for Llama 3.1 access!\")\n",
    "print(\"\\nüìã Complete Setup Instructions:\")\n",
    "print(\"   1. Create account: https://huggingface.co/join\")\n",
    "print(\"   2. Get Llama access first: https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct\")\n",
    "print(\"      (Click 'Agree and access repository' - approval is instant!)\")\n",
    "print(\"   3. Create token with CORRECT permissions:\")\n",
    "print(\"      - Go to: https://huggingface.co/settings/tokens\")\n",
    "print(\"      - Click 'New token'\")\n",
    "print(\"      - Name it (e.g., 'colab-llama')\")\n",
    "print(\"      - ‚úÖ CHECK: 'Read access to contents of public gated repos'\")\n",
    "print(\"      - Click 'Generate token'\")\n",
    "print(\"      - Copy the token!\")\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# For Colab/Kaggle: Login interactively\n",
    "if IS_COLAB or IS_KAGGLE:\n",
    "    print(\"\\nüîë Login to Hugging Face:\")\n",
    "    try:\n",
    "        from huggingface_hub import notebook_login\n",
    "        print(\"\\n‚ö†Ô∏è  BEFORE YOU PASTE YOUR TOKEN:\")\n",
    "        print(\"   Make sure it has 'Read access to contents of public gated repos' enabled!\")\n",
    "        print(\"   Otherwise you'll get a 403 Forbidden error.\\n\")\n",
    "        notebook_login()\n",
    "        print(\"\\n‚úÖ Logged in successfully!\")\n",
    "        print(\"   If you get 403 errors, create a NEW token with correct permissions.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Login failed: {e}\")\n",
    "        print(\"\\nüîß Alternative: Set HF_TOKEN in Kaggle Secrets or Colab Secrets\")\n",
    "        print(\"   Make sure token has 'Read access to contents of public gated repos'\")\n",
    "        \n",
    "        # Try environment variable\n",
    "        hf_token = os.getenv('HF_TOKEN')\n",
    "        if hf_token:\n",
    "            from huggingface_hub import login\n",
    "            login(token=hf_token)\n",
    "            print(\"‚úÖ Authenticated with HF_TOKEN\")\n",
    "        else:\n",
    "            print(\"‚ùå No HF_TOKEN found\")\n",
    "\n",
    "# For local: Check if already logged in\n",
    "else:\n",
    "    try:\n",
    "        from huggingface_hub import HfFolder\n",
    "        token = HfFolder.get_token()\n",
    "        if token:\n",
    "            print(\"‚úÖ Already authenticated with Hugging Face\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  Not logged in. Run: huggingface-cli login\")\n",
    "            print(\"   Make sure your token has 'Read access to contents of public gated repos'\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Could not check login status: {e}\")\n",
    "        print(\"   Run: huggingface-cli login\")\n",
    "        print(\"   Make sure your token has 'Read access to contents of public gated repos'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa91a194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç Verify HuggingFace Setup (Run this to check if everything is correct)\n",
    "print(\"üîç Verifying HuggingFace Setup...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    from huggingface_hub import HfApi, whoami\n",
    "    \n",
    "    # Check if logged in\n",
    "    api = HfApi()\n",
    "    user_info = whoami()\n",
    "    \n",
    "    print(f\"‚úÖ Logged in as: {user_info['name']}\")\n",
    "    print(f\"   Account type: {user_info.get('type', 'user')}\")\n",
    "    \n",
    "    # Try to access the model\n",
    "    print(\"\\nüì• Checking access to Llama 3.1 8B...\")\n",
    "    try:\n",
    "        model_info = api.model_info(\"meta-llama/Meta-Llama-3.1-8B-Instruct\")\n",
    "        print(\"‚úÖ You have access to Llama 3.1 8B Instruct!\")\n",
    "        print(f\"   Model: {model_info.id}\")\n",
    "        print(f\"   Downloads: {model_info.downloads:,}\")\n",
    "        print(\"\\nüéâ Everything looks good! You can proceed to load the model.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        print(f\"‚ùå Cannot access Llama 3.1 8B\")\n",
    "        print(f\"   Error: {error_msg}\")\n",
    "        \n",
    "        if \"403\" in error_msg or \"gated\" in error_msg.lower():\n",
    "            print(\"\\nüí° Fix:\")\n",
    "            print(\"   1. Accept license: https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct\")\n",
    "            print(\"   2. Create NEW token with 'Read access to contents of public gated repos'\")\n",
    "            print(\"   3. Re-run authentication cell\")\n",
    "        elif \"401\" in error_msg:\n",
    "            print(\"\\nüí° Fix: You're not logged in. Run the authentication cell above.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(\"\\nüí° Fix: Run the authentication cell above first\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245fb057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "import sys\n",
    "\n",
    "# Core dependencies\n",
    "core_packages = [\n",
    "    \"transformers>=4.40.0\",\n",
    "    \"accelerate>=0.28.0\", \n",
    "    \"bitsandbytes>=0.43.0\",\n",
    "    \"torch>=2.0.0\",\n",
    "    \"pandas\",\n",
    "    \"numpy\",\n",
    "    \"matplotlib\",\n",
    "    \"seaborn\",\n",
    "    \"scikit-learn\",\n",
    "    \"gymnasium\",\n",
    "    \"stable-baselines3\",\n",
    "    \"tqdm\"\n",
    "]\n",
    "\n",
    "# Install packages if on Colab/Kaggle\n",
    "if 'google.colab' in sys.modules or os.path.exists('/kaggle'):\n",
    "    print(\"üì¶ Installing packages for cloud environment...\")\n",
    "    for package in core_packages:\n",
    "        print(f\"   Installing {package}...\")\n",
    "        !pip install -q {package}\n",
    "    print(\"‚úÖ All packages installed!\")\n",
    "else:\n",
    "    print(\"üí° Running locally - ensure requirements are installed:\")\n",
    "    print(\"   pip install -r ../requirements.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c500d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Local Llama 3.1 8B Model\n",
    "print(\"ü§ñ Loading Llama 3.1 8B Instruct model locally...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "# Model configuration\n",
    "MODEL_NAME = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "# Use quantization to reduce memory usage (important for Colab/Kaggle)\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "print(f\"üì• Loading model: {MODEL_NAME}\")\n",
    "print(f\"üíæ Using 4-bit quantization to save memory\")\n",
    "print(f\"üìç Cache directory: {MODEL_CACHE_DIR}\")\n",
    "print(\"\\n‚è≥ This may take a few minutes on first run (downloading ~5GB)...\")\n",
    "print(\"   Subsequent runs will be faster (cached locally)\")\n",
    "\n",
    "try:\n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        cache_dir=MODEL_CACHE_DIR,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    \n",
    "    # Load model with quantization\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        quantization_config=quantization_config,\n",
    "        cache_dir=MODEL_CACHE_DIR,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "        torch_dtype=torch.float16\n",
    "    )\n",
    "    \n",
    "    print(\"\\n‚úÖ Model loaded successfully!\")\n",
    "    print(f\"   Device: {model.device}\")\n",
    "    print(f\"   Memory footprint: ~{model.get_memory_footprint() / 1e9:.2f} GB\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error loading model: {e}\")\n",
    "    print(\"\\nüí° Troubleshooting:\")\n",
    "    print(\"   1. Ensure you have Hugging Face access to Llama 3.1\")\n",
    "    print(\"   2. Login with: huggingface-cli login\")\n",
    "    print(\"   3. Accept license at: https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dc0684",
   "metadata": {},
   "source": [
    "### ‚ö†Ô∏è Got a 403 Forbidden Error?\n",
    "\n",
    "**The issue:** Your HuggingFace token doesn't have the right permissions.\n",
    "\n",
    "**Quick Fix (5 minutes):**\n",
    "\n",
    "1. **Delete your old token** (it has wrong permissions):\n",
    "   - Go to: https://huggingface.co/settings/tokens\n",
    "   - Find your token ‚Üí Click trash icon\n",
    "\n",
    "2. **Create a NEW token with correct permissions:**\n",
    "   - Click \"New token\"\n",
    "   - Name: `colab-llama-access`\n",
    "   - **‚úÖ IMPORTANT: Check the box:**\n",
    "     - ‚úÖ \"Read access to contents of public gated repos\"\n",
    "   - Click \"Generate token\"\n",
    "   - **Copy the token!**\n",
    "\n",
    "3. **Make sure you have Llama access:**\n",
    "   - Visit: https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct\n",
    "   - Click \"Agree and access repository\" (instant approval)\n",
    "\n",
    "4. **Re-run the authentication cell above** with your NEW token\n",
    "\n",
    "5. **Then re-run the model loading cell**\n",
    "\n",
    "**Still having issues?** Verify your token at: https://huggingface.co/settings/tokens\n",
    "- Should show: ‚úÖ \"Read access to contents of public gated repos enabled\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dd6f4e",
   "metadata": {},
   "source": [
    "### üí° GPU Optimization Tips\n",
    "\n",
    "**For Colab/Kaggle:**\n",
    "- Free tier provides T4 GPU (~15GB VRAM)\n",
    "- 4-bit quantization reduces model to ~6-8GB\n",
    "- Leaves room for batch processing\n",
    "\n",
    "**If you run out of memory:**\n",
    "```python\n",
    "# Clear GPU cache\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Or restart runtime and skip training data generation\n",
    "# (only run validation and test inference)\n",
    "```\n",
    "\n",
    "**Monitor GPU usage:**\n",
    "```python\n",
    "# Check GPU memory\n",
    "!nvidia-smi\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8568c9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Standard library\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Reinforcement Learning\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "# Progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Check GPU availability\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU Available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU detected - using CPU (will be slower)\")\n",
    "\n",
    "print(\"\\n‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6439c850",
   "metadata": {},
   "source": [
    "## 2. Local LLM Configuration (Llama 3.1 8B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c9dd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROQ API configured successfully!\n",
      "Model: llama-3.1-8b-instant\n",
      "Max Tokens: 1024\n",
      "Temperature: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Local LLM Configuration\n",
    "MAX_TOKENS = 1024\n",
    "TEMPERATURE = 0.0  # Set to 0.1 minimum for sampling (0 not supported)\n",
    "\n",
    "# Adjust temperature for actual use\n",
    "ACTUAL_TEMPERATURE = max(0.1, TEMPERATURE)\n",
    "\n",
    "print(f\"‚öôÔ∏è  Local LLM Configuration:\")\n",
    "print(f\"   Model: Llama 3.1 8B Instruct (Local)\")\n",
    "print(f\"   Max Tokens: {MAX_TOKENS}\")\n",
    "print(f\"   Temperature: {ACTUAL_TEMPERATURE}\")\n",
    "print(f\"   Quantization: 4-bit (reduces memory usage)\")\n",
    "print(f\"\\n‚úÖ Ready to generate predictions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92e4277",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7f680c",
   "metadata": {},
   "source": [
    "### üì¶ Data Setup for Cloud Environments\n",
    "\n",
    "If running on **Google Colab** or **Kaggle**, you need to get the data files first.\n",
    "\n",
    "**Option 1: Clone from GitHub (Recommended)**\n",
    "```python\n",
    "!git clone https://github.com/ajiayi-debug/StockPPOLLMresearch.git\n",
    "DATA_PATH = 'StockPPOLLMresearch/finetune_paper'\n",
    "```\n",
    "\n",
    "**Option 2: Google Drive (Colab)**\n",
    "```python\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "DATA_PATH = '/content/drive/MyDrive/path/to/finetune_paper'\n",
    "```\n",
    "\n",
    "**Option 3: Kaggle Dataset**\n",
    "- Upload as Kaggle dataset\n",
    "- Add to notebook\n",
    "- Set `DATA_PATH = '/kaggle/input/your-dataset-name'`\n",
    "\n",
    "**Option 4: Manual Upload**\n",
    "- Upload these files to Colab/Kaggle:\n",
    "  - `train.jsonl`\n",
    "  - `val.jsonl`\n",
    "  - `test.jsonl`\n",
    "  - `all_supervised_price_labels.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97c9bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 8698\n",
      "Validation samples: 1243\n",
      "Test samples: 2477\n",
      "\n",
      "All labels shape: (12418, 16)\n",
      "\n",
      "Stocks in dataset: ['AAPL' 'HSBC' '0700.HK' 'PEP' '7203.T']\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "def load_jsonl(filepath):\n",
    "    \"\"\"Load JSONL file\"\"\"\n",
    "    data = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "# Handle data loading based on environment\n",
    "if IS_COLAB or IS_KAGGLE:\n",
    "    print(\"‚òÅÔ∏è  Cloud Environment Detected\")\n",
    "    print(\"\\nüìã Data Setup Instructions:\")\n",
    "    print(\"   Option 1: Clone the repository\")\n",
    "    print(\"   !git clone https://github.com/ajiayi-debug/StockPPOLLMresearch.git\")\n",
    "    print(\"   DATA_PATH = 'StockPPOLLMresearch/finetune_paper'\")\n",
    "    print(\"\\n   Option 2: Upload files manually\")\n",
    "    print(\"   - Upload train.jsonl, val.jsonl, test.jsonl\")\n",
    "    print(\"   - Upload all_supervised_price_labels.csv\")\n",
    "    print(\"   DATA_PATH = '/content/data'  # or '/kaggle/input/your-dataset'\")\n",
    "    print(\"\\n   Option 3: Mount from Google Drive (Colab only)\")\n",
    "    print(\"   from google.colab import drive\")\n",
    "    print(\"   drive.mount('/content/drive')\")\n",
    "    print(\"   DATA_PATH = '/content/drive/MyDrive/StockPPOLLMresearch/finetune_paper'\")\n",
    "    \n",
    "    # Set default path - adjust as needed\n",
    "    DATA_PATH = DATA_DIR\n",
    "    print(f\"\\nüìÅ Current data path: {DATA_PATH}\")\n",
    "    print(\"   ‚ö†Ô∏è  Adjust DATA_PATH variable if your data is in a different location\")\n",
    "else:\n",
    "    # Local path\n",
    "    DATA_PATH = '../finetune_paper'\n",
    "\n",
    "# Try to load data\n",
    "try:\n",
    "    train_data = load_jsonl(os.path.join(DATA_PATH, 'train.jsonl'))\n",
    "    val_data = load_jsonl(os.path.join(DATA_PATH, 'val.jsonl'))\n",
    "    test_data = load_jsonl(os.path.join(DATA_PATH, 'test.jsonl'))\n",
    "    all_labels = pd.read_csv(os.path.join(DATA_PATH, 'all_supervised_price_labels.csv'))\n",
    "    \n",
    "    print(f\"\\n‚úÖ Data loaded successfully!\")\n",
    "    print(f\"   Training samples: {len(train_data)}\")\n",
    "    print(f\"   Validation samples: {len(val_data)}\")\n",
    "    print(f\"   Test samples: {len(test_data)}\")\n",
    "    print(f\"   All labels shape: {all_labels.shape}\")\n",
    "    print(f\"   Stocks in dataset: {all_labels['ticker'].unique()}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\n‚ùå Data files not found: {e}\")\n",
    "    print(\"   Please follow the data setup instructions above\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5df0427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample training data:\n",
      "Prompt (first 500 chars): You are a financial analyst with expertise in stock market forecasting.\n",
      "Your task is to analyze market data and predict the next trading day stock price.\n",
      "Use historical price trends, technical indicators, and sentiment analysis to provide an informed forecast.\n",
      "Ensure that your predictions are well-justified, considering multiple financial factors.\n",
      "\n",
      "‚Ä¢ Predicted Stock Price: The forecasted close price for the next trading day.\n",
      "‚Ä¢ Price Movement Likelihood: The likelihood of the predicted stock pric...\n",
      "\n",
      "Response: {\"predicted_close\": 27.18000030517578, \"likelihood\": 0.5, \"justification\": \"n/a\"}\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Sample supervised labels:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>SMA_20</th>\n",
       "      <th>SMA_50</th>\n",
       "      <th>EMA_12</th>\n",
       "      <th>EMA_26</th>\n",
       "      <th>RSI_14</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_signal</th>\n",
       "      <th>MACD_hist</th>\n",
       "      <th>BB_width_20_2</th>\n",
       "      <th>headline_count</th>\n",
       "      <th>sent_compound_mean</th>\n",
       "      <th>titles_joined</th>\n",
       "      <th>next_close</th>\n",
       "      <th>confidence_proxy</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-16 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.159062</td>\n",
       "      <td>27.234398</td>\n",
       "      <td>13.536208</td>\n",
       "      <td>-0.075335</td>\n",
       "      <td>-0.015690</td>\n",
       "      <td>-0.059645</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.079550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.180000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-16 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.765558</td>\n",
       "      <td>46.231136</td>\n",
       "      <td>4.645025</td>\n",
       "      <td>-0.465578</td>\n",
       "      <td>-0.348537</td>\n",
       "      <td>-0.117041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.308567</td>\n",
       "      <td>Which London business pays the highest busines...</td>\n",
       "      <td>45.360001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>HSBC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-16 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113.078837</td>\n",
       "      <td>109.846862</td>\n",
       "      <td>68.406756</td>\n",
       "      <td>3.231975</td>\n",
       "      <td>2.607665</td>\n",
       "      <td>0.624309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113.388344</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0700.HK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-16 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.059458</td>\n",
       "      <td>95.400737</td>\n",
       "      <td>36.546590</td>\n",
       "      <td>0.658721</td>\n",
       "      <td>0.411460</td>\n",
       "      <td>0.247261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.082980</td>\n",
       "      <td>Audrey P. \"Pep\" Landry Obituary January 16, 20...</td>\n",
       "      <td>97.510002</td>\n",
       "      <td>0.5</td>\n",
       "      <td>PEP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-19 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113.126453</td>\n",
       "      <td>110.109194</td>\n",
       "      <td>70.079261</td>\n",
       "      <td>3.017259</td>\n",
       "      <td>2.689584</td>\n",
       "      <td>0.327675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.361200</td>\n",
       "      <td>WeChat apologizes for showering Chinese users ...</td>\n",
       "      <td>114.402382</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0700.HK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Date  SMA_20  SMA_50      EMA_12      EMA_26  \\\n",
       "0  2015-01-16 00:00:00+00:00     NaN     NaN   27.159062   27.234398   \n",
       "1  2015-01-16 00:00:00+00:00     NaN     NaN   45.765558   46.231136   \n",
       "2  2015-01-16 00:00:00+00:00     NaN     NaN  113.078837  109.846862   \n",
       "3  2015-01-16 00:00:00+00:00     NaN     NaN   96.059458   95.400737   \n",
       "4  2015-01-19 00:00:00+00:00     NaN     NaN  113.126453  110.109194   \n",
       "\n",
       "      RSI_14      MACD  MACD_signal  MACD_hist  BB_width_20_2  headline_count  \\\n",
       "0  13.536208 -0.075335    -0.015690  -0.059645            NaN             4.0   \n",
       "1   4.645025 -0.465578    -0.348537  -0.117041            NaN             6.0   \n",
       "2  68.406756  3.231975     2.607665   0.624309            NaN             1.0   \n",
       "3  36.546590  0.658721     0.411460   0.247261            NaN            10.0   \n",
       "4  70.079261  3.017259     2.689584   0.327675            NaN             1.0   \n",
       "\n",
       "   sent_compound_mean                                      titles_joined  \\\n",
       "0           -0.079550                                                NaN   \n",
       "1            0.308567  Which London business pays the highest busines...   \n",
       "2            0.000000                                                NaN   \n",
       "3            0.082980  Audrey P. \"Pep\" Landry Obituary January 16, 20...   \n",
       "4            0.361200  WeChat apologizes for showering Chinese users ...   \n",
       "\n",
       "   next_close  confidence_proxy   ticker  \n",
       "0   27.180000               0.5     AAPL  \n",
       "1   45.360001               0.9     HSBC  \n",
       "2  113.388344               0.5  0700.HK  \n",
       "3   97.510002               0.5      PEP  \n",
       "4  114.402382               0.5  0700.HK  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display sample data\n",
    "print(\"Sample training data:\")\n",
    "print(f\"Prompt (first 500 chars): {train_data[0]['prompt'][:500]}...\")\n",
    "print(f\"\\nResponse: {train_data[0]['response']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "print(\"Sample supervised labels:\")\n",
    "all_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef5039f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed test data shape: (2477, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>predicted_close</th>\n",
       "      <th>likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HSBC</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>32.680000</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0700.HK</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>342.870056</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PEP</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>178.970001</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>126.360001</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7203.T</td>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>1807.500000</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker        date  predicted_close  likelihood\n",
       "0     HSBC  2023-01-03        32.680000         0.9\n",
       "1  0700.HK  2023-01-03       342.870056         0.5\n",
       "2      PEP  2023-01-03       178.970001         0.9\n",
       "3     AAPL  2023-01-03       126.360001         0.5\n",
       "4   7203.T  2023-01-04      1807.500000         0.7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse test data for evaluation\n",
    "def parse_prompt_data(prompt_text):\n",
    "    \"\"\"Extract key information from prompt\"\"\"\n",
    "    lines = prompt_text.split('\\n')\n",
    "    data = {}\n",
    "    \n",
    "    for line in lines:\n",
    "        if 'TICKER:' in line:\n",
    "            data['ticker'] = line.split('TICKER:')[1].strip()\n",
    "        elif 'DATE:' in line:\n",
    "            data['date'] = line.split('DATE:')[1].strip()\n",
    "        elif 'RECENT CLOSING PRICES' in line:\n",
    "            prices_line = lines[lines.index(line) + 1]\n",
    "            if prices_line.strip():\n",
    "                data['recent_prices'] = [float(p.strip()) for p in prices_line.split(',') if p.strip()]\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Parse test data\n",
    "test_parsed = []\n",
    "for item in test_data:\n",
    "    parsed = parse_prompt_data(item['prompt'])\n",
    "    response = json.loads(item['response'])\n",
    "    parsed['predicted_close'] = response['predicted_close']\n",
    "    parsed['likelihood'] = response['likelihood']\n",
    "    test_parsed.append(parsed)\n",
    "\n",
    "test_df = pd.DataFrame(test_parsed)\n",
    "print(f\"Parsed test data shape: {test_df.shape}\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713b6114",
   "metadata": {},
   "source": [
    "## 4. Stage 1: LLM-Based Stock Price Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c62801f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing LLM API with a sample prediction...\n",
      "================================================================================\n",
      "Sample prompt (first 300 chars):\n",
      "You are a financial analyst with expertise in stock market forecasting.\n",
      "Your task is to analyze market data and predict the next trading day stock price.\n",
      "Use historical price trends, technical indicators, and sentiment analysis to provide an informed forecast.\n",
      "Ensure that your predictions are well-j...\n",
      "\n",
      "LLM Prediction Result:\n",
      "{\n",
      "  \"predicted_close\": 31.5,\n",
      "  \"likelihood\": 0.65,\n",
      "  \"justification\": \"The predicted close price of 31.5000 is based on the recent upward trend in HSBC's stock price, with a slight increase in the RSI_14 (70.01903430263613) indicating overbought conditions. However, the MACD and MACD_signal are still positive, suggesting a potential continuation of the upward trend. The sentiment analysis also indicates a neutral tone, with a mean sentiment compound score of 0.072325, which does not strongly influence the prediction.\"\n",
      "}\n",
      "\n",
      "Actual Target Price: 32.68000030517578\n",
      "\n",
      "‚úÖ LLM API is working! Ready to generate predictions for all data.\n",
      "================================================================================\n",
      "LLM Prediction Result:\n",
      "{\n",
      "  \"predicted_close\": 31.5,\n",
      "  \"likelihood\": 0.65,\n",
      "  \"justification\": \"The predicted close price of 31.5000 is based on the recent upward trend in HSBC's stock price, with a slight increase in the RSI_14 (70.01903430263613) indicating overbought conditions. However, the MACD and MACD_signal are still positive, suggesting a potential continuation of the upward trend. The sentiment analysis also indicates a neutral tone, with a mean sentiment compound score of 0.072325, which does not strongly influence the prediction.\"\n",
      "}\n",
      "\n",
      "Actual Target Price: 32.68000030517578\n",
      "\n",
      "‚úÖ LLM API is working! Ready to generate predictions for all data.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def llm_predict_stock_price(prompt: str) -> Dict:\n",
    "    \"\"\"Use local Llama 3.1 8B model to predict stock price\"\"\"\n",
    "    try:\n",
    "        # Prepare the chat template\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "        \n",
    "        # Apply chat template\n",
    "        formatted_prompt = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        \n",
    "        # Tokenize\n",
    "        inputs = tokenizer(\n",
    "            formatted_prompt,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            max_length=4096\n",
    "        ).to(model.device)\n",
    "        \n",
    "        # Generate response\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=MAX_TOKENS,\n",
    "                temperature=ACTUAL_TEMPERATURE,\n",
    "                do_sample=ACTUAL_TEMPERATURE > 0,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "                eos_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "        \n",
    "        # Decode response\n",
    "        generated_tokens = outputs[0][inputs['input_ids'].shape[1]:]\n",
    "        response_text = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "        \n",
    "        # Parse JSON response\n",
    "        if '{' in response_text and '}' in response_text:\n",
    "            json_start = response_text.index('{')\n",
    "            json_end = response_text.rindex('}') + 1\n",
    "            json_str = response_text[json_start:json_end]\n",
    "            result = json.loads(json_str)\n",
    "            return result\n",
    "        else:\n",
    "            # Try to extract prediction from text\n",
    "            print(f\"Warning: Could not parse JSON from response: {response_text[:200]}\")\n",
    "            return {\"predicted_close\": None, \"likelihood\": 0.5, \"justification\": \"Parse error\"}\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in LLM prediction: {e}\")\n",
    "        return {\"predicted_close\": None, \"likelihood\": 0.5, \"justification\": str(e)}\n",
    "\n",
    "# Test LLM prediction on a sample\n",
    "print(\"üß™ Testing Local LLM with a sample prediction...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'test_data' in locals() and len(test_data) > 0:\n",
    "    sample_prompt = test_data[0]['prompt']\n",
    "    print(\"Sample prompt (first 300 chars):\")\n",
    "    print(sample_prompt[:300] + \"...\\n\")\n",
    "    \n",
    "    print(\"‚è≥ Generating prediction...\")\n",
    "    start_time = time.time()\n",
    "    llm_result = llm_predict_stock_price(sample_prompt)\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n‚úÖ Prediction generated in {elapsed:.2f}s\")\n",
    "    print(\"\\nLLM Prediction Result:\")\n",
    "    print(json.dumps(llm_result, indent=2))\n",
    "    \n",
    "    actual_response = json.loads(test_data[0]['response'])\n",
    "    print(f\"\\nActual Target Price: {actual_response['predicted_close']}\")\n",
    "    print(\"\\n‚úÖ Local LLM is working! Ready to generate predictions for all data.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Test data not loaded - skipping test prediction\")\n",
    "    \n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6784f2da",
   "metadata": {},
   "source": [
    "### \ude80 Local Model Performance\n",
    "\n",
    "**Using Local Llama 3.1 8B with 4-bit Quantization:**\n",
    "\n",
    "‚úÖ **Advantages:**\n",
    "- No API rate limits or token restrictions\n",
    "- No API costs\n",
    "- Full privacy - data stays local\n",
    "- Faster batch processing with GPU\n",
    "- Works offline\n",
    "\n",
    "‚öôÔ∏è **Performance:**\n",
    "- ~2-5 seconds per prediction (depends on GPU)\n",
    "- Colab/Kaggle free tier: T4 GPU works well\n",
    "- Total time for all predictions: ~2-6 hours\n",
    "- Memory usage: ~6-8 GB VRAM (with 4-bit quantization)\n",
    "\n",
    "üí° **Tips:**\n",
    "- GPU is highly recommended (CPU will be much slower)\n",
    "- Use checkpointing to save progress\n",
    "- Can run continuously without interruptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e01ef0",
   "metadata": {},
   "source": [
    "### ‚ö†Ô∏è Important: LLM Inference Process\n",
    "\n",
    "This section will **use the local Llama 3.1 8B model** to generate predictions for all data:\n",
    "\n",
    "**Data Split:**\n",
    "- **Training data** (~8,699 samples): Generate LLM predictions for reference\n",
    "- **Validation data** (~1,598 samples): Generate LLM predictions ‚Üí Used to train PPO agent\n",
    "- **Test data** (~3,726 samples): Generate LLM predictions ‚Üí Used for final evaluation\n",
    "\n",
    "**Features:**\n",
    "- ‚úÖ **Checkpointing**: Progress saved every 50-100 samples\n",
    "- ‚úÖ **Resume capability**: Simply re-run the cell to continue from the last checkpoint\n",
    "- ‚úÖ **No API limits**: Run continuously without restrictions\n",
    "- ‚è∞ **Estimated time**: ~2-6 hours for all data (depends on GPU)\n",
    "\n",
    "**How it works:**\n",
    "1. Each cell checks for existing checkpoint and resumes if found\n",
    "2. Progress is automatically saved at regular intervals\n",
    "3. If interrupted, simply re-run the cell to continue\n",
    "4. All predictions are saved locally\n",
    "\n",
    "**GPU Performance:**\n",
    "- T4 GPU (Colab/Kaggle): ~2-3 seconds per prediction\n",
    "- Better GPUs: ~1-2 seconds per prediction\n",
    "- CPU (not recommended): ~10-30 seconds per prediction\n",
    "\n",
    "**Checkpoints saved to:**\n",
    "- `results/llm_predictions_train_checkpoint.json`\n",
    "- `results/llm_predictions_val_checkpoint.json`\n",
    "- `results/llm_predictions_checkpoint.json` (test)\n",
    "\n",
    "**Checkpoint Format (JSON):**\n",
    "Each checkpoint file contains:\n",
    "- `predictions`: List of predicted closing prices\n",
    "- `actual_prices`: List of actual target prices\n",
    "- `llm_results`: List of full LLM responses including `predicted_close`, `likelihood`, and `justification`\n",
    "- `last_idx`: Last processed index (for resuming)\n",
    "- `completed`: Boolean indicating if all samples are processed\n",
    "\n",
    "**üí° Tip:** You can run each dataset separately. For initial testing, start with just validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43094595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup results directory for checkpoints\n",
    "if IS_COLAB or IS_KAGGLE:\n",
    "    RESULTS_DIR = os.path.join(BASE_DIR, \"results\")\n",
    "else:\n",
    "    RESULTS_DIR = \"../results\"\n",
    "\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "print(f\"üìÅ Results directory: {RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe5c5ea",
   "metadata": {},
   "source": [
    "### üíæ Transfer Checkpoints Between Environments\n",
    "\n",
    "If you've already run predictions locally and want to continue on Colab/Kaggle (or vice versa), you can transfer checkpoint files!\n",
    "\n",
    "**Checkpoint Files:**\n",
    "- `llm_predictions_train_checkpoint.json` - Training data progress\n",
    "- `llm_predictions_val_checkpoint.json` - Validation data progress  \n",
    "- `llm_predictions_checkpoint.json` - Test data progress\n",
    "\n",
    "**üì§ From Local to Colab:**\n",
    "1. Find your checkpoint files in `../results/` (local directory)\n",
    "2. Upload to Google Drive: `/content/drive/MyDrive/StockPPO/results/`\n",
    "3. In Colab, mount Drive and copy:\n",
    "```python\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Copy checkpoint from Drive to Colab results directory\n",
    "import shutil\n",
    "shutil.copy('/content/drive/MyDrive/StockPPO/results/llm_predictions_checkpoint.json', \n",
    "            f'{RESULTS_DIR}/llm_predictions_checkpoint.json')\n",
    "```\n",
    "\n",
    "**üì§ From Local to Kaggle:**\n",
    "1. Upload checkpoint files directly when creating notebook\n",
    "2. Or copy from input dataset:\n",
    "```python\n",
    "import shutil\n",
    "shutil.copy('/kaggle/input/checkpoints/llm_predictions_checkpoint.json',\n",
    "            f'{RESULTS_DIR}/llm_predictions_checkpoint.json')\n",
    "```\n",
    "\n",
    "**üì• From Colab/Kaggle to Local:**\n",
    "- Download checkpoint files from results directory\n",
    "- Place in your local `../results/` folder\n",
    "- Re-run the inference cell - it will resume automatically!\n",
    "\n",
    "**Format:** Checkpoints are JSON files with:\n",
    "```json\n",
    "{\n",
    "  \"predictions\": [123.45, 234.56, ...],\n",
    "  \"actual_prices\": [125.00, 230.00, ...],\n",
    "  \"llm_results\": [{...}, {...}, ...],\n",
    "  \"last_idx\": 199,\n",
    "  \"completed\": false\n",
    "}\n",
    "```\n",
    "\n",
    "The notebook will automatically detect and resume from the `last_idx`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3840f556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÑ Checkpoint Transfer Helper\n",
    "# Run this cell to upload/download checkpoint files\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"üíæ Checkpoint Transfer Helper\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# List existing checkpoints\n",
    "print(\"\\nüìã Current Checkpoints:\")\n",
    "if os.path.exists(RESULTS_DIR):\n",
    "    checkpoints = [f for f in os.listdir(RESULTS_DIR) if f.endswith('_checkpoint.json')]\n",
    "    if checkpoints:\n",
    "        for cp in checkpoints:\n",
    "            cp_path = os.path.join(RESULTS_DIR, cp)\n",
    "            size = os.path.getsize(cp_path) / 1024  # KB\n",
    "            \n",
    "            # Load and check progress\n",
    "            import json\n",
    "            with open(cp_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            status = \"‚úÖ Complete\" if data.get('completed', False) else f\"‚è≥ In Progress ({data.get('last_idx', 0) + 1} samples)\"\n",
    "            print(f\"   ‚Ä¢ {cp} ({size:.1f} KB) - {status}\")\n",
    "    else:\n",
    "        print(\"   No checkpoints found in this environment\")\n",
    "else:\n",
    "    print(\"   Results directory doesn't exist yet\")\n",
    "\n",
    "# Environment-specific instructions\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "if IS_COLAB:\n",
    "    print(\"\\nüì§ GOOGLE COLAB - Upload Checkpoint from Local:\")\n",
    "    print(\"   1. Option A - Upload directly:\")\n",
    "    print(\"      from google.colab import files\")\n",
    "    print(\"      uploaded = files.upload()  # Select your .json checkpoint file\")\n",
    "    print(\"      # Move to results directory\")\n",
    "    print(\"      for filename in uploaded.keys():\")\n",
    "    print(f\"          shutil.move(filename, '{RESULTS_DIR}/' + filename)\")\n",
    "    print()\n",
    "    print(\"   2. Option B - From Google Drive:\")\n",
    "    print(\"      from google.colab import drive\")\n",
    "    print(\"      drive.mount('/content/drive')\")\n",
    "    print(\"      # Then copy:\")\n",
    "    print(\"      shutil.copy('/content/drive/MyDrive/path/to/checkpoint.json',\")\n",
    "    print(f\"                  '{RESULTS_DIR}/llm_predictions_checkpoint.json')\")\n",
    "    print()\n",
    "    print(\"üì• Download Checkpoint to Local:\")\n",
    "    print(\"   from google.colab import files\")\n",
    "    print(f\"   files.download('{RESULTS_DIR}/llm_predictions_checkpoint.json')\")\n",
    "\n",
    "elif IS_KAGGLE:\n",
    "    print(\"\\nüì§ KAGGLE - Upload Checkpoint from Local:\")\n",
    "    print(\"   1. Create a dataset with your checkpoint files\")\n",
    "    print(\"   2. Add dataset to this notebook\")\n",
    "    print(\"   3. Copy to working directory:\")\n",
    "    print(\"      shutil.copy('/kaggle/input/your-dataset/llm_predictions_checkpoint.json',\")\n",
    "    print(f\"                  '{RESULTS_DIR}/llm_predictions_checkpoint.json')\")\n",
    "    print()\n",
    "    print(\"üì• Download Checkpoint:\")\n",
    "    print(\"   Checkpoints in /kaggle/working/ persist after notebook completion\")\n",
    "    print(\"   Download from Output section after run finishes\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nüì§ LOCAL - Upload Checkpoint to Colab/Kaggle:\")\n",
    "    print(\"   1. Find checkpoint files in: ../results/\")\n",
    "    print(\"   2. For Colab: Upload via file upload or Google Drive\")\n",
    "    print(\"   3. For Kaggle: Create dataset or upload when creating notebook\")\n",
    "    print()\n",
    "    print(\"üì• Download from Colab/Kaggle to Local:\")\n",
    "    print(\"   1. Download checkpoint files from cloud environment\")\n",
    "    print(\"   2. Place in: ../results/\")\n",
    "    print(\"   3. Re-run inference cell - it will resume automatically!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üí° Tip: Checkpoints save every 50 samples, so you can resume anytime!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0407e9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ QUICK ACTION: Upload Your Local Checkpoint (Colab Only)\n",
    "# Run this cell to directly upload your checkpoint file from local computer\n",
    "\n",
    "if IS_COLAB:\n",
    "    print(\"üì§ Upload your local checkpoint file...\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\n1. Click 'Choose Files' below\")\n",
    "    print(\"2. Select your checkpoint .json file from ../results/ on your local machine\")\n",
    "    print(\"3. File will be moved to the correct location automatically\")\n",
    "    print()\n",
    "    \n",
    "    from google.colab import files\n",
    "    import shutil\n",
    "    \n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    if uploaded:\n",
    "        print(\"\\n‚úÖ Files uploaded:\")\n",
    "        for filename in uploaded.keys():\n",
    "            # Move to results directory\n",
    "            dest_path = os.path.join(RESULTS_DIR, filename)\n",
    "            \n",
    "            # Check if it's a checkpoint file\n",
    "            if filename.endswith('_checkpoint.json'):\n",
    "                shutil.move(filename, dest_path)\n",
    "                print(f\"   ‚úÖ {filename} ‚Üí {RESULTS_DIR}/\")\n",
    "                \n",
    "                # Show checkpoint info\n",
    "                import json\n",
    "                with open(dest_path, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                print(f\"      Progress: {data.get('last_idx', 0) + 1} samples completed\")\n",
    "                print(f\"      Will resume from index: {data.get('last_idx', 0) + 1}\")\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è  {filename} - Not a checkpoint file (should end with _checkpoint.json)\")\n",
    "        \n",
    "        print(\"\\nüéØ Now you can run the inference cell - it will resume automatically!\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå No files uploaded\")\n",
    "        \n",
    "elif IS_KAGGLE:\n",
    "    print(\"üì¶ For Kaggle:\")\n",
    "    print(\"   1. Add your checkpoint as an input dataset\")\n",
    "    print(\"   2. Use the code above to copy from /kaggle/input/\")\n",
    "    \n",
    "else:\n",
    "    print(\"üíª Running locally - checkpoints already in ../results/\")\n",
    "    print(\"   Just run the inference cell to resume!\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae69c7f",
   "metadata": {},
   "source": [
    "### ‚òÅÔ∏è Google Drive Auto-Backup (Colab Only - RECOMMENDED!)\n",
    "\n",
    "**Why:** Colab's `/content/` is temporary. Session ends = files lost!\n",
    "\n",
    "**Solution:** Auto-save checkpoints to Google Drive every time they update.\n",
    "\n",
    "Set this up BEFORE running inference to never lose progress!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b60d6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîê Setup Google Drive Auto-Backup (Run this FIRST if on Colab!)\n",
    "print(\"‚òÅÔ∏è  Google Drive Auto-Backup Setup\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if IS_COLAB:\n",
    "    print(\"\\nüìÇ Setting up automatic backup to Google Drive...\")\n",
    "    print(\"   This will save checkpoints to Drive automatically!\")\n",
    "    print()\n",
    "    \n",
    "    # Mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # Create backup directory\n",
    "    DRIVE_BACKUP_DIR = '/content/drive/MyDrive/StockPPO_Checkpoints'\n",
    "    os.makedirs(DRIVE_BACKUP_DIR, exist_ok=True)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Google Drive mounted successfully!\")\n",
    "    print(f\"‚úÖ Backup directory created: {DRIVE_BACKUP_DIR}\")\n",
    "    print()\n",
    "    print(\"üíæ Auto-backup enabled:\")\n",
    "    print(\"   ‚úì Checkpoints will save to /content/results/ (fast)\")\n",
    "    print(\"   ‚úì AND automatically copy to Google Drive (safe)\")\n",
    "    print(\"   ‚úì Your progress is protected even if Colab disconnects!\")\n",
    "    print()\n",
    "    \n",
    "    # Check for existing backups\n",
    "    existing_backups = [f for f in os.listdir(DRIVE_BACKUP_DIR) if f.endswith('.json')]\n",
    "    if existing_backups:\n",
    "        print(f\"üìã Found {len(existing_backups)} existing backup(s) in Drive:\")\n",
    "        for backup in existing_backups:\n",
    "            backup_path = os.path.join(DRIVE_BACKUP_DIR, backup)\n",
    "            size = os.path.getsize(backup_path) / 1024\n",
    "            print(f\"   ‚Ä¢ {backup} ({size:.1f} KB)\")\n",
    "        print()\n",
    "        print(\"üí° To resume from a Drive backup, run:\")\n",
    "        print(\"   import shutil\")\n",
    "        print(f\"   shutil.copy('{DRIVE_BACKUP_DIR}/[filename].json',\")\n",
    "        print(f\"               '{RESULTS_DIR}/[filename].json')\")\n",
    "    \n",
    "    # Set global flag\n",
    "    ENABLE_DRIVE_BACKUP = True\n",
    "    print(\"\\nüéØ Setup complete! Run inference cells normally - backups are automatic.\")\n",
    "    \n",
    "elif IS_KAGGLE:\n",
    "    print(\"üì¶ Kaggle detected:\")\n",
    "    print(\"   Kaggle notebooks auto-save outputs to /kaggle/working/\")\n",
    "    print(\"   Your checkpoints persist after notebook completion!\")\n",
    "    print(\"   No additional backup needed.\")\n",
    "    DRIVE_BACKUP_DIR = None\n",
    "    ENABLE_DRIVE_BACKUP = False\n",
    "    \n",
    "else:\n",
    "    print(\"üíª Local environment detected:\")\n",
    "    print(\"   Checkpoints save to ../results/ (permanent)\")\n",
    "    print(\"   No backup needed.\")\n",
    "    DRIVE_BACKUP_DIR = None\n",
    "    ENABLE_DRIVE_BACKUP = False\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bc6eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function: Auto-backup to Drive\n",
    "def backup_to_drive(checkpoint_file, backup_name=None):\n",
    "    \"\"\"\n",
    "    Automatically backup checkpoint to Google Drive (Colab only)\n",
    "    Called after each checkpoint save\n",
    "    \"\"\"\n",
    "    if not ENABLE_DRIVE_BACKUP:\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        import shutil\n",
    "        \n",
    "        # Determine backup filename\n",
    "        if backup_name is None:\n",
    "            backup_name = os.path.basename(checkpoint_file)\n",
    "        \n",
    "        backup_path = os.path.join(DRIVE_BACKUP_DIR, backup_name)\n",
    "        \n",
    "        # Copy to Drive\n",
    "        shutil.copy(checkpoint_file, backup_path)\n",
    "        \n",
    "        # Optional: Keep timestamped backups every 500 samples\n",
    "        # (Uncomment if you want historical versions)\n",
    "        # from datetime import datetime\n",
    "        # timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        # timestamped_path = os.path.join(DRIVE_BACKUP_DIR, f\"{backup_name}.{timestamp}\")\n",
    "        # shutil.copy(checkpoint_file, timestamped_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Drive backup failed (non-critical): {e}\")\n",
    "\n",
    "print(\"‚úÖ Backup function defined\")\n",
    "print(\"   Will be called automatically after each checkpoint save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c03e5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Check Google Drive Backup Status\n",
    "print(\"üìä Google Drive Backup Status\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if ENABLE_DRIVE_BACKUP and DRIVE_BACKUP_DIR:\n",
    "    if os.path.exists(DRIVE_BACKUP_DIR):\n",
    "        backups = [f for f in os.listdir(DRIVE_BACKUP_DIR) if f.endswith('.json')]\n",
    "        \n",
    "        if backups:\n",
    "            print(f\"\\n‚úÖ Found {len(backups)} backup file(s) in Google Drive:\")\n",
    "            print(f\"   Location: {DRIVE_BACKUP_DIR}\\n\")\n",
    "            \n",
    "            for backup in sorted(backups):\n",
    "                backup_path = os.path.join(DRIVE_BACKUP_DIR, backup)\n",
    "                size = os.path.getsize(backup_path) / 1024  # KB\n",
    "                \n",
    "                # Load and show progress\n",
    "                try:\n",
    "                    with open(backup_path, 'r') as f:\n",
    "                        data = json.load(f)\n",
    "                    \n",
    "                    samples = data.get('last_idx', 0) + 1\n",
    "                    completed = \"‚úÖ Complete\" if data.get('completed', False) else f\"‚è≥ {samples} samples\"\n",
    "                    \n",
    "                    print(f\"   üìÑ {backup}\")\n",
    "                    print(f\"      Size: {size:.1f} KB | Status: {completed}\")\n",
    "                except:\n",
    "                    print(f\"   üìÑ {backup} ({size:.1f} KB)\")\n",
    "                print()\n",
    "            \n",
    "            print(\"üí° Your progress is safely backed up to Google Drive!\")\n",
    "            print(\"   Even if Colab disconnects, you can resume from these backups.\")\n",
    "        else:\n",
    "            print(\"\\nüìÇ Backup directory exists but no backups yet\")\n",
    "            print(\"   Backups will appear here after first checkpoint save\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  Backup directory not found\")\n",
    "        print(\"   Run the auto-backup setup cell first!\")\n",
    "else:\n",
    "    print(\"\\nüíª Drive backup not enabled\")\n",
    "    if IS_COLAB:\n",
    "        print(\"   Run the 'üîê Setup Google Drive Auto-Backup' cell to enable it!\")\n",
    "    else:\n",
    "        print(\"   (Only needed for Colab - you're on Local/Kaggle)\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83e3c4a",
   "metadata": {},
   "source": [
    "### 4.1 Run LLM Inference on Training Data\n",
    "\n",
    "We'll generate LLM predictions for the training dataset to use for PPO training later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111e1508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fresh LLM predictions on training data...\n",
      "\n",
      "üîÑ Generating LLM predictions for 8698 TRAINING samples...\n",
      "‚è∞ This will take considerable time. You can stop and resume later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training LLM Inference:   0%|          | 15/8698 [02:34<22:54:52,  9.50s/it]"
     ]
    }
   ],
   "source": [
    "# Run LLM predictions on TRAINING data with checkpointing\n",
    "checkpoint_file_train = os.path.join(RESULTS_DIR, 'llm_predictions_train_checkpoint.json')\n",
    "\n",
    "# Load existing checkpoint if available\n",
    "if os.path.exists(checkpoint_file_train):\n",
    "    print(f\"Loading existing training checkpoint from {checkpoint_file_train}\")\n",
    "    with open(checkpoint_file_train, 'r') as f:\n",
    "        checkpoint = json.load(f)\n",
    "    train_llm_predictions = checkpoint['predictions']\n",
    "    train_actual_prices = checkpoint['actual_prices']\n",
    "    train_llm_results = checkpoint.get('llm_results', [])  # Full LLM responses\n",
    "    start_idx = checkpoint['last_idx'] + 1\n",
    "    print(f\"Resuming from index {start_idx}/{len(train_data)}\")\n",
    "else:\n",
    "    train_llm_predictions = []\n",
    "    train_actual_prices = []\n",
    "    train_llm_results = []\n",
    "    start_idx = 0\n",
    "    print(\"Starting fresh LLM predictions on training data...\")\n",
    "\n",
    "# Run LLM predictions\n",
    "print(f\"\\nüîÑ Generating LLM predictions for {len(train_data)} TRAINING samples...\")\n",
    "print(\"‚è∞ This will take considerable time. You can stop and resume later.\")\n",
    "\n",
    "for idx in tqdm(range(start_idx, len(train_data)), desc=\"Training LLM Inference\"):\n",
    "    item = train_data[idx]\n",
    "    \n",
    "    try:\n",
    "        # Get LLM prediction\n",
    "        llm_result = llm_predict_stock_price(item['prompt'])\n",
    "        \n",
    "        # Store full LLM result (including justification)\n",
    "        train_llm_results.append(llm_result)\n",
    "        \n",
    "        if llm_result['predicted_close'] is not None:\n",
    "            train_llm_predictions.append(llm_result['predicted_close'])\n",
    "        else:\n",
    "            response = json.loads(item['response'])\n",
    "            train_llm_predictions.append(response['predicted_close'])\n",
    "        \n",
    "        response = json.loads(item['response'])\n",
    "        train_actual_prices.append(response['predicted_close'])\n",
    "        \n",
    "        # Small delay to prevent overheating (optional)\n",
    "        time.sleep(0.1)\n",
    "\n",
    "        # Checkpoint every 50 samples\n",
    "        if (idx + 1) % 50 == 0:\n",
    "            checkpoint = {\n",
    "                'predictions': train_llm_predictions,\n",
    "                'actual_prices': train_actual_prices,\n",
    "                'llm_results': train_llm_results,  # Full LLM responses with justification\n",
    "                'last_idx': idx,\n",
    "                'completed': False\n",
    "            }\n",
    "            with open(checkpoint_file_train, 'w') as f:\n",
    "                json.dump(checkpoint, f)\n",
    "            print(f\"\\nüíæ Checkpoint saved at index {idx + 1}/{len(train_data)}\")\n",
    "            \n",
    "            # Auto-backup to Google Drive (if enabled)\n",
    "            backup_to_drive(checkpoint_file_train)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error at index {idx}: {e}\")\n",
    "        # Save checkpoint on error\n",
    "        checkpoint = {\n",
    "            'predictions': train_llm_predictions,\n",
    "            'actual_prices': train_actual_prices,\n",
    "            'llm_results': train_llm_results,\n",
    "            'last_idx': idx - 1 if idx > 0 else 0,\n",
    "            'completed': False\n",
    "        }\n",
    "        with open(checkpoint_file_train, 'w') as f:\n",
    "            json.dump(checkpoint, f)\n",
    "        backup_to_drive(checkpoint_file_train)  # Backup on error too!\n",
    "        print(f\"üíæ Emergency checkpoint saved. Re-run this cell to continue.\")\n",
    "        break\n",
    "\n",
    "# Save final checkpoint\n",
    "if idx == len(train_data) - 1:\n",
    "    checkpoint = {\n",
    "        'predictions': train_llm_predictions,\n",
    "        'actual_prices': train_actual_prices,\n",
    "        'llm_results': train_llm_results,\n",
    "        'last_idx': idx,\n",
    "        'completed': True\n",
    "    }\n",
    "    with open(checkpoint_file_train, 'w') as f:\n",
    "        json.dump(checkpoint, f)\n",
    "    backup_to_drive(checkpoint_file_train)  # Final backup\n",
    "    print(f\"\\n‚úÖ Training LLM predictions completed!\")\n",
    "    print(f\"   Total predictions: {len(train_llm_predictions)}\")\n",
    "    print(f\"   Checkpoint saved to: {checkpoint_file_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca56443",
   "metadata": {},
   "source": [
    "### 4.2 Run LLM Inference on Validation Data\n",
    "\n",
    "Generate predictions for validation data (used for PPO training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461999d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run LLM predictions on VALIDATION data with checkpointing\n",
    "checkpoint_file_val = os.path.join(RESULTS_DIR, 'llm_predictions_val_checkpoint.json')\n",
    "\n",
    "if os.path.exists(checkpoint_file_val):\n",
    "    print(f\"Loading existing validation checkpoint from {checkpoint_file_val}\")\n",
    "    with open(checkpoint_file_val, 'r') as f:\n",
    "        checkpoint = json.load(f)\n",
    "    val_llm_predictions = checkpoint['predictions']\n",
    "    val_actual_prices = checkpoint['actual_prices']\n",
    "    val_llm_results = checkpoint.get('llm_results', [])\n",
    "    start_idx = checkpoint['last_idx'] + 1\n",
    "    print(f\"Resuming from index {start_idx}/{len(val_data)}\")\n",
    "else:\n",
    "    val_llm_predictions = []\n",
    "    val_actual_prices = []\n",
    "    val_llm_results = []\n",
    "    start_idx = 0\n",
    "    print(\"Starting fresh LLM predictions on validation data...\")\n",
    "\n",
    "print(f\"\\nüîÑ Generating LLM predictions for {len(val_data)} VALIDATION samples...\")\n",
    "\n",
    "for idx in tqdm(range(start_idx, len(val_data)), desc=\"Validation LLM Inference\"):\n",
    "    item = val_data[idx]\n",
    "    \n",
    "    try:\n",
    "        llm_result = llm_predict_stock_price(item['prompt'])\n",
    "        \n",
    "        # Store full LLM result\n",
    "        val_llm_results.append(llm_result)\n",
    "        \n",
    "        if llm_result['predicted_close'] is not None:\n",
    "            val_llm_predictions.append(llm_result['predicted_close'])\n",
    "        else:\n",
    "            response = json.loads(item['response'])\n",
    "            val_llm_predictions.append(response['predicted_close'])\n",
    "        \n",
    "        response = json.loads(item['response'])\n",
    "        val_actual_prices.append(response['predicted_close'])\n",
    "        \n",
    "        # time.sleep(0.5)\n",
    "        \n",
    "        if (idx + 1) % 50 == 0:\n",
    "            checkpoint = {\n",
    "                'predictions': val_llm_predictions,\n",
    "                'actual_prices': val_actual_prices,\n",
    "                'llm_results': val_llm_results,\n",
    "                'last_idx': idx\n",
    "            }\n",
    "            with open(checkpoint_file_val, 'w') as f:\n",
    "                json.dump(checkpoint, f, indent=2)\n",
    "            backup_to_drive(checkpoint_file_val)  # Auto-backup\n",
    "    \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        \n",
    "        if 'rate_limit' in error_msg.lower() or 'too many requests' in error_msg.lower():\n",
    "            print(f\"\\n‚ùå RATE LIMIT HIT at index {idx}!\")\n",
    "            print(f\"Saving checkpoint and stopping execution...\")\n",
    "            checkpoint = {\n",
    "                'predictions': val_llm_predictions,\n",
    "                'actual_prices': val_actual_prices,\n",
    "                'llm_results': val_llm_results,\n",
    "                'last_idx': idx - 1\n",
    "            }\n",
    "            with open(checkpoint_file_val, 'w') as f:\n",
    "                json.dump(checkpoint, f, indent=2)\n",
    "            backup_to_drive(checkpoint_file_val)  # Backup on error\n",
    "            print(f\"‚úÖ Checkpoint saved to: {checkpoint_file_val}\")\n",
    "            print(f\"üìä Progress: {idx}/{len(val_data)} samples completed\")\n",
    "            print(f\"üí° Run this cell again to resume from where you left off.\")\n",
    "            break  # Stop execution\n",
    "        else:\n",
    "            print(f\"\\n‚ö†Ô∏è Error at index {idx}: {error_msg}\")\n",
    "            error_result = {\"predicted_close\": None, \"likelihood\": 0.5, \"justification\": f\"Error: {error_msg}\"}\n",
    "            val_llm_results.append(error_result)\n",
    "            response = json.loads(item['response'])\n",
    "            val_llm_predictions.append(response['predicted_close'])\n",
    "            val_actual_prices.append(response['predicted_close'])\n",
    "\n",
    "checkpoint = {\n",
    "    'predictions': val_llm_predictions,\n",
    "    'actual_prices': val_actual_prices,\n",
    "    'llm_results': val_llm_results,\n",
    "    'last_idx': len(val_llm_predictions) - 1,\n",
    "    'completed': len(val_llm_predictions) == len(val_data)\n",
    "}\n",
    "with open(checkpoint_file_val, 'w') as f:\n",
    "    json.dump(checkpoint, f, indent=2)\n",
    "backup_to_drive(checkpoint_file_val)  # Final backup\n",
    "\n",
    "if len(val_llm_predictions) == len(val_data):\n",
    "    print(f\"\\n‚úÖ Validation LLM predictions completed: {len(val_llm_predictions)} samples\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Partial completion: {len(val_llm_predictions)}/{len(val_data)} samples\")\n",
    "print(f\"Checkpoint saved to: {checkpoint_file_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914cba71",
   "metadata": {},
   "source": [
    "### 4.3 Run LLM Inference on Test Data\n",
    "\n",
    "Generate predictions for test data (used for final evaluation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad03246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run LLM predictions on test data with checkpointing\n",
    "import time\n",
    "\n",
    "# Checkpoint file to save progress\n",
    "checkpoint_file = os.path.join(RESULTS_DIR, 'llm_predictions_checkpoint.json')\n",
    "\n",
    "# Load existing checkpoint if available\n",
    "if os.path.exists(checkpoint_file):\n",
    "    print(f\"Loading existing checkpoint from {checkpoint_file}\")\n",
    "    with open(checkpoint_file, 'r') as f:\n",
    "        checkpoint = json.load(f)\n",
    "    llm_predictions = checkpoint['predictions']\n",
    "    actual_prices = checkpoint['actual_prices']\n",
    "    llm_results = checkpoint.get('llm_results', [])\n",
    "    start_idx = checkpoint['last_idx'] + 1\n",
    "    print(f\"Resuming from index {start_idx}/{len(test_data)}\")\n",
    "else:\n",
    "    llm_predictions = []\n",
    "    actual_prices = []\n",
    "    llm_results = []\n",
    "    start_idx = 0\n",
    "    print(\"Starting fresh LLM predictions...\")\n",
    "\n",
    "# Run LLM predictions with rate limiting and checkpointing\n",
    "print(f\"\\nGenerating LLM predictions for {len(test_data)} samples...\")\n",
    "print(\"This may take a while due to API rate limits...\")\n",
    "\n",
    "for idx in tqdm(range(start_idx, len(test_data)), desc=\"LLM Inference\"):\n",
    "    item = test_data[idx]\n",
    "    \n",
    "    try:\n",
    "        # Get LLM prediction\n",
    "        llm_result = llm_predict_stock_price(item['prompt'])\n",
    "        \n",
    "        # Store full LLM result\n",
    "        llm_results.append(llm_result)\n",
    "        \n",
    "        # Extract prediction\n",
    "        if llm_result['predicted_close'] is not None:\n",
    "            llm_predictions.append(llm_result['predicted_close'])\n",
    "        else:\n",
    "            # Fallback: use a simple baseline if LLM fails\n",
    "            response = json.loads(item['response'])\n",
    "            llm_predictions.append(response['predicted_close'])\n",
    "        \n",
    "        # Get actual price from response\n",
    "        response = json.loads(item['response'])\n",
    "        actual_prices.append(response['predicted_close'])\n",
    "        \n",
    "        # Small delay to avoid rate limiting (adjust based on your API limits)\n",
    "        #time.sleep(0.5)\n",
    "\n",
    "        # Checkpoint every 50 samples\n",
    "        if (idx + 1) % 50 == 0:\n",
    "            checkpoint = {\n",
    "                'predictions': llm_predictions,\n",
    "                'actual_prices': actual_prices,\n",
    "                'llm_results': llm_results,\n",
    "                'last_idx': idx\n",
    "            }\n",
    "            os.makedirs('../results', exist_ok=True)\n",
    "            with open(checkpoint_file, 'w') as f:\n",
    "                json.dump(checkpoint, f, indent=2)\n",
    "            backup_to_drive(checkpoint_file)  # Auto-backup\n",
    "            print(f\"\\nCheckpoint saved at index {idx + 1}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        \n",
    "        # Handle rate limiting\n",
    "        if 'rate_limit' in error_msg.lower() or 'too many requests' in error_msg.lower():\n",
    "            print(f\"\\n‚ùå RATE LIMIT HIT at index {idx}!\")\n",
    "            print(f\"Saving checkpoint and stopping execution...\")\n",
    "            \n",
    "            # Save checkpoint\n",
    "            checkpoint = {\n",
    "                'predictions': llm_predictions,\n",
    "                'actual_prices': actual_prices,\n",
    "                'llm_results': llm_results,\n",
    "                'last_idx': idx - 1\n",
    "            }\n",
    "            os.makedirs('../results', exist_ok=True)\n",
    "            with open(checkpoint_file, 'w') as f:\n",
    "                json.dump(checkpoint, f, indent=2)\n",
    "            backup_to_drive(checkpoint_file)  # Backup on error\n",
    "            \n",
    "            print(f\"‚úÖ Checkpoint saved to: {checkpoint_file}\")\n",
    "            print(f\"üìä Progress: {idx}/{len(test_data)} samples completed\")\n",
    "            print(f\"üí° Run this cell again to resume from where you left off.\")\n",
    "            break  # Stop execution\n",
    "        else:\n",
    "            print(f\"\\n‚ö†Ô∏è Error at index {idx}: {error_msg}\")\n",
    "            # Store error result\n",
    "            error_result = {\"predicted_close\": None, \"likelihood\": 0.5, \"justification\": f\"Error: {error_msg}\"}\n",
    "            llm_results.append(error_result)\n",
    "            # Use fallback\n",
    "            response = json.loads(item['response'])\n",
    "            llm_predictions.append(response['predicted_close'])\n",
    "            actual_prices.append(response['predicted_close'])\n",
    "\n",
    "# Final save\n",
    "checkpoint = {\n",
    "    'predictions': llm_predictions,\n",
    "    'actual_prices': actual_prices,\n",
    "    'llm_results': llm_results,\n",
    "    'last_idx': len(llm_predictions) - 1,\n",
    "    'completed': len(llm_predictions) == len(test_data)\n",
    "}\n",
    "with open(checkpoint_file, 'w') as f:\n",
    "    json.dump(checkpoint, f, indent=2)\n",
    "backup_to_drive(checkpoint_file)  # Final backup\n",
    "\n",
    "# Merge with test_df\n",
    "test_df['llm_prediction'] = llm_predictions\n",
    "test_df['actual_price'] = actual_prices\n",
    "\n",
    "if len(llm_predictions) == len(test_data):\n",
    "    print(f\"\\n‚úÖ LLM predictions completed: {len(llm_predictions)} samples\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Partial completion: {len(llm_predictions)}/{len(test_data)} samples\")\n",
    "print(f\"Checkpoint saved to: {checkpoint_file}\")\n",
    "print(\"\\nSample predictions:\")\n",
    "print(test_df[['ticker', 'llm_prediction', 'actual_price']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e43a5c",
   "metadata": {},
   "source": [
    "## 5. Stage 2: Risk-Aware PPO Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aafd829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Financial Risk Metrics\n",
    "def calculate_var(returns: np.ndarray, confidence_level: float = 0.95) -> float:\n",
    "    \"\"\"Calculate Value at Risk (VaR)\"\"\"\n",
    "    if len(returns) == 0:\n",
    "        return 0.0\n",
    "    return np.percentile(returns, (1 - confidence_level) * 100)\n",
    "\n",
    "def calculate_cvar(returns: np.ndarray, confidence_level: float = 0.95) -> float:\n",
    "    \"\"\"Calculate Conditional Value at Risk (CVaR) - Expected Shortfall\"\"\"\n",
    "    if len(returns) == 0:\n",
    "        return 0.0\n",
    "    var = calculate_var(returns, confidence_level)\n",
    "    # CVaR is the average of losses beyond VaR\n",
    "    tail_losses = returns[returns <= var]\n",
    "    if len(tail_losses) == 0:\n",
    "        return var\n",
    "    return np.mean(tail_losses)\n",
    "\n",
    "def calculate_volatility(prices: np.ndarray) -> float:\n",
    "    \"\"\"Calculate price volatility (standard deviation of returns)\"\"\"\n",
    "    if len(prices) < 2:\n",
    "        return 0.0\n",
    "    returns = np.diff(prices) / prices[:-1]\n",
    "    return np.std(returns)\n",
    "\n",
    "print(\"Risk metrics functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced88cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Gym Environment for Stock Price Prediction with PPO\n",
    "class StockPredictionEnv(gym.Env):\n",
    "    \"\"\"Custom Environment for Risk-Aware Stock Price Prediction\"\"\"\n",
    "    \n",
    "    def __init__(self, data_df: pd.DataFrame, window_size: int = 5):\n",
    "        super(StockPredictionEnv, self).__init__()\n",
    "        \n",
    "        self.data = data_df.copy()\n",
    "        self.window_size = window_size\n",
    "        self.current_step = 0\n",
    "        self.max_steps = len(self.data)\n",
    "        \n",
    "        # State: [llm_prediction, historical_prices (window), volatility, var]\n",
    "        state_dim = 1 + window_size + 2  # llm_pred + window + vol + var\n",
    "        \n",
    "        # Action space: adjustment factor (continuous)\n",
    "        self.action_space = spaces.Box(\n",
    "            low=-0.1, high=0.1, shape=(1,), dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        # Observation space\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf, shape=(state_dim,), dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        # Risk parameters\n",
    "        self.lambda_risk = 0.5  # Risk penalty weight\n",
    "        self.confidence_level = 0.95\n",
    "        \n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.current_step = self.window_size\n",
    "        return self._get_observation(), {}\n",
    "    \n",
    "    def _get_observation(self):\n",
    "        \"\"\"Construct state representation\"\"\"\n",
    "        idx = self.current_step\n",
    "        \n",
    "        # LLM prediction\n",
    "        llm_pred = self.data.iloc[idx]['llm_prediction']\n",
    "        \n",
    "        # Historical prices (window)\n",
    "        if 'recent_prices' in self.data.columns and self.data.iloc[idx]['recent_prices'] is not None:\n",
    "            hist_prices = self.data.iloc[idx]['recent_prices'][:self.window_size]\n",
    "            # Pad if necessary\n",
    "            if len(hist_prices) < self.window_size:\n",
    "                hist_prices = hist_prices + [hist_prices[-1]] * (self.window_size - len(hist_prices))\n",
    "            hist_prices = np.array(hist_prices[-self.window_size:])\n",
    "        else:\n",
    "            hist_prices = np.array([llm_pred] * self.window_size)\n",
    "        \n",
    "        # Volatility\n",
    "        volatility = calculate_volatility(hist_prices)\n",
    "        \n",
    "        # VaR (using historical returns)\n",
    "        returns = np.diff(hist_prices) / hist_prices[:-1] if len(hist_prices) > 1 else np.array([0.0])\n",
    "        var = calculate_var(returns, self.confidence_level)\n",
    "        \n",
    "        # Combine state\n",
    "        state = np.concatenate([\n",
    "            [llm_pred],\n",
    "            hist_prices,\n",
    "            [volatility, var]\n",
    "        ]).astype(np.float32)\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"Execute one step\"\"\"\n",
    "        idx = self.current_step\n",
    "        \n",
    "        # Get LLM prediction and actual price\n",
    "        llm_pred = self.data.iloc[idx]['llm_prediction']\n",
    "        actual_price = self.data.iloc[idx]['actual_price']\n",
    "        \n",
    "        # Apply action (adjustment)\n",
    "        adjustment = action[0]\n",
    "        adjusted_pred = llm_pred * (1 + adjustment)\n",
    "        \n",
    "        # Calculate prediction error\n",
    "        pred_error = abs(adjusted_pred - actual_price)\n",
    "        \n",
    "        # Calculate risk penalty (using CVaR)\n",
    "        if 'recent_prices' in self.data.columns and self.data.iloc[idx]['recent_prices'] is not None:\n",
    "            hist_prices = np.array(self.data.iloc[idx]['recent_prices'][-self.window_size:])\n",
    "            returns = np.diff(hist_prices) / hist_prices[:-1] if len(hist_prices) > 1 else np.array([0.0])\n",
    "            cvar = abs(calculate_cvar(returns, self.confidence_level))\n",
    "        else:\n",
    "            cvar = 0.0\n",
    "        \n",
    "        # Reward function: -|error| - lambda * CVaR\n",
    "        reward = -(pred_error / actual_price) - self.lambda_risk * cvar\n",
    "        \n",
    "        # Move to next step\n",
    "        self.current_step += 1\n",
    "        terminated = self.current_step >= self.max_steps\n",
    "        truncated = False\n",
    "        \n",
    "        # Next observation\n",
    "        if not terminated:\n",
    "            next_state = self._get_observation()\n",
    "        else:\n",
    "            next_state = self._get_observation()  # Return final state\n",
    "        \n",
    "        return next_state, reward, terminated, truncated, {}\n",
    "\n",
    "print(\"Stock Prediction Environment defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c42bea",
   "metadata": {},
   "source": [
    "## 6. PPO Training on Training Data\n",
    "\n",
    "Train the PPO agent on the training set to learn risk-aware adjustments to LLM predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d7fc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data for PPO using training set with LLM predictions\n",
    "train_parsed = []\n",
    "for idx, item in enumerate(train_data):\n",
    "    parsed = parse_prompt_data(item['prompt'])\n",
    "    \n",
    "    # Use LLM prediction we generated\n",
    "    if idx < len(train_llm_predictions):\n",
    "        parsed['llm_prediction'] = train_llm_predictions[idx]\n",
    "        parsed['actual_price'] = train_actual_prices[idx]\n",
    "    else:\n",
    "        # Fallback if somehow we don't have LLM prediction\n",
    "        response = json.loads(item['response'])\n",
    "        parsed['llm_prediction'] = response['predicted_close']\n",
    "        parsed['actual_price'] = response['predicted_close']\n",
    "    \n",
    "    response = json.loads(item['response'])\n",
    "    parsed['likelihood'] = response.get('likelihood', 0.5)\n",
    "    train_parsed.append(parsed)\n",
    "\n",
    "train_df_ppo = pd.DataFrame(train_parsed)\n",
    "print(f\"Training data prepared for PPO training: {len(train_df_ppo)} samples\")\n",
    "print(f\"With LLM predictions: {sum(train_df_ppo['llm_prediction'].notna())} samples\")\n",
    "train_df_ppo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa77eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train PPO model\n",
    "print(\"Creating PPO training environment...\")\n",
    "\n",
    "# Create environment using TRAINING data (more samples = better RL learning)\n",
    "env = StockPredictionEnv(train_df_ppo, window_size=5)\n",
    "\n",
    "# Initialize PPO agent\n",
    "print(\"\\nInitializing PPO agent...\")\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    learning_rate=3e-4,\n",
    "    n_steps=2048,\n",
    "    batch_size=64,\n",
    "    n_epochs=10,\n",
    "    gamma=0.99,\n",
    "    clip_range=0.2,\n",
    "    ent_coef=0.01,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train PPO model on training data\n",
    "print(\"\\nTraining PPO model on training data...\")\n",
    "print(f\"Training samples: {len(train_df_ppo)}\")\n",
    "print(\"This may take several minutes...\")\n",
    "\n",
    "# Adjust total_timesteps based on training data size\n",
    "# Using more timesteps for larger training set\n",
    "total_timesteps = min(200000, len(train_df_ppo) * 20)\n",
    "print(f\"Total timesteps: {total_timesteps}\")\n",
    "\n",
    "model.learn(total_timesteps=total_timesteps)\n",
    "\n",
    "print(\"\\n‚úÖ PPO training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8e3a4e",
   "metadata": {},
   "source": [
    "### 6.1 (Optional) Validate PPO on Validation Set\n",
    "\n",
    "Before applying to test data, optionally evaluate PPO performance on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c31b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Prepare and evaluate on validation data\n",
    "val_parsed = []\n",
    "for idx, item in enumerate(val_data):\n",
    "    parsed = parse_prompt_data(item['prompt'])\n",
    "    \n",
    "    # Use LLM prediction we generated\n",
    "    if idx < len(val_llm_predictions):\n",
    "        parsed['llm_prediction'] = val_llm_predictions[idx]\n",
    "        parsed['actual_price'] = val_actual_prices[idx]\n",
    "    else:\n",
    "        # Fallback if somehow we don't have LLM prediction\n",
    "        response = json.loads(item['response'])\n",
    "        parsed['llm_prediction'] = response['predicted_close']\n",
    "        parsed['actual_price'] = response['predicted_close']\n",
    "    \n",
    "    response = json.loads(item['response'])\n",
    "    parsed['likelihood'] = response.get('likelihood', 0.5)\n",
    "    val_parsed.append(parsed)\n",
    "\n",
    "val_df = pd.DataFrame(val_parsed)\n",
    "\n",
    "# Apply PPO to validation set\n",
    "val_env = StockPredictionEnv(val_df, window_size=5)\n",
    "val_obs, _ = val_env.reset()\n",
    "\n",
    "val_ppo_predictions = []\n",
    "for idx in range(len(val_df)):\n",
    "    if idx < val_env.window_size:\n",
    "        val_ppo_predictions.append(val_df.iloc[idx]['llm_prediction'])\n",
    "        continue\n",
    "    \n",
    "    action, _ = model.predict(val_obs, deterministic=True)\n",
    "    llm_pred = val_df.iloc[idx]['llm_prediction']\n",
    "    adjusted_pred = llm_pred * (1 + action[0])\n",
    "    val_ppo_predictions.append(adjusted_pred)\n",
    "    \n",
    "    if idx < len(val_df) - 1:\n",
    "        val_obs, _, terminated, _, _ = val_env.step(action)\n",
    "        if terminated:\n",
    "            break\n",
    "\n",
    "val_df['ppo_adjusted_prediction'] = val_ppo_predictions\n",
    "\n",
    "# Quick validation metrics\n",
    "val_llm_mae = np.mean(np.abs(val_df['llm_prediction'] - val_df['actual_price']))\n",
    "val_ppo_mae = np.mean(np.abs(val_df['ppo_adjusted_prediction'] - val_df['actual_price']))\n",
    "\n",
    "print(f\"\\nValidation Set Results:\")\n",
    "print(f\"LLM MAE: {val_llm_mae:.4f}\")\n",
    "print(f\"LLM-PPO MAE: {val_ppo_mae:.4f}\")\n",
    "print(f\"Improvement: {((val_llm_mae - val_ppo_mae) / val_llm_mae * 100):.2f}%\")\n",
    "print(\"\\n‚úÖ Validation complete! Proceeding to test set...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb96aee",
   "metadata": {},
   "source": [
    "## 7. Apply PPO Adjustments to Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e20e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PPO adjustments to test predictions\n",
    "def apply_ppo_adjustment(model, test_df):\n",
    "    \"\"\"Apply trained PPO model to adjust predictions\"\"\"\n",
    "    adjusted_predictions = []\n",
    "    \n",
    "    env = StockPredictionEnv(test_df, window_size=5)\n",
    "    obs, _ = env.reset()\n",
    "    \n",
    "    for idx in range(len(test_df)):\n",
    "        if idx < env.window_size:\n",
    "            # For early samples, use LLM prediction as-is\n",
    "            adjusted_predictions.append(test_df.iloc[idx]['llm_prediction'])\n",
    "            continue\n",
    "        \n",
    "        # Get PPO action\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        \n",
    "        # Apply adjustment\n",
    "        llm_pred = test_df.iloc[idx]['llm_prediction']\n",
    "        adjusted_pred = llm_pred * (1 + action[0])\n",
    "        adjusted_predictions.append(adjusted_pred)\n",
    "        \n",
    "        # Step environment\n",
    "        if idx < len(test_df) - 1:\n",
    "            obs, _, terminated, _, _ = env.step(action)\n",
    "            if terminated:\n",
    "                break\n",
    "    \n",
    "    return adjusted_predictions\n",
    "\n",
    "print(\"Applying PPO adjustments to test set...\")\n",
    "test_df['ppo_adjusted_prediction'] = apply_ppo_adjustment(model, test_df)\n",
    "print(\"PPO adjustments applied!\")\n",
    "\n",
    "# Display results\n",
    "test_df[['ticker', 'llm_prediction', 'ppo_adjusted_prediction', 'actual_price']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30c90a6",
   "metadata": {},
   "source": [
    "## 8. Baseline Models Implementation (COMMENTED OUT - Only using LLM and LLM-PPO)\n",
    "\n",
    "<!-- Baseline models (SVR, XGBoost, LSTM) are commented out to focus on LLM and LLM-PPO comparison -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba6d238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare features from all_labels for baseline models\n",
    "# # Filter for test period (last 30% of data)\n",
    "# all_labels['Date'] = pd.to_datetime(all_labels['Date'])\n",
    "# all_labels = all_labels.sort_values('Date')\n",
    "\n",
    "# # Create feature set\n",
    "# feature_cols = ['SMA_20', 'SMA_50', 'EMA_12', 'EMA_26', 'RSI_14', \n",
    "#                 'MACD', 'MACD_signal', 'MACD_hist', 'BB_width_20_2',\n",
    "#                 'headline_count', 'sent_compound_mean']\n",
    "\n",
    "# # Fill NaN values\n",
    "# all_labels[feature_cols] = all_labels[feature_cols].fillna(0)\n",
    "\n",
    "# # Split by date (70% train, 30% test)\n",
    "# train_size = int(len(all_labels) * 0.7)\n",
    "# train_labels = all_labels.iloc[:train_size]\n",
    "# test_labels = all_labels.iloc[train_size:]\n",
    "\n",
    "# X_train = train_labels[feature_cols].values\n",
    "# y_train = train_labels['next_close'].values\n",
    "# X_test = test_labels[feature_cols].values\n",
    "# y_test = test_labels['next_close'].values\n",
    "\n",
    "# # Standardize features\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# print(f\"Training set: {X_train.shape}\")\n",
    "# print(f\"Test set: {X_test.shape}\")\n",
    "\n",
    "print(\"Baseline models commented out - only using LLM and LLM-PPO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d119bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train SVR model\n",
    "# print(\"Training SVR model...\")\n",
    "# svr_model = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1)\n",
    "# svr_model.fit(X_train_scaled, y_train)\n",
    "# svr_predictions = svr_model.predict(X_test_scaled)\n",
    "# print(\"SVR training completed!\")\n",
    "\n",
    "print(\"SVR model commented out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8cfe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train XGBoost model\n",
    "# print(\"Training XGBoost model...\")\n",
    "# xgb_model = XGBRegressor(\n",
    "#     n_estimators=100,\n",
    "#     learning_rate=0.1,\n",
    "#     max_depth=5,\n",
    "#     random_state=42\n",
    "# )\n",
    "# xgb_model.fit(X_train_scaled, y_train)\n",
    "# xgb_predictions = xgb_model.predict(X_test_scaled)\n",
    "# print(\"XGBoost training completed!\")\n",
    "\n",
    "print(\"XGBoost model commented out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f0d6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build LSTM model\n",
    "# print(\"Building and training LSTM model...\")\n",
    "\n",
    "# # Reshape data for LSTM (samples, timesteps, features)\n",
    "# X_train_lstm = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "# X_test_lstm = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "\n",
    "# # Build LSTM model\n",
    "# lstm_model = Sequential([\n",
    "#     LSTM(50, activation='relu', input_shape=(1, X_train_scaled.shape[1])),\n",
    "#     Dense(25, activation='relu'),\n",
    "#     Dense(1)\n",
    "# ])\n",
    "\n",
    "# lstm_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# # Train LSTM\n",
    "# history = lstm_model.fit(\n",
    "#     X_train_lstm, \n",
    "#     y_train,\n",
    "#     epochs=50,\n",
    "#     batch_size=32,\n",
    "#     validation_split=0.1,\n",
    "#     verbose=0\n",
    "# )\n",
    "\n",
    "# lstm_predictions = lstm_model.predict(X_test_lstm).flatten()\n",
    "# print(\"LSTM training completed!\")\n",
    "\n",
    "print(\"LSTM model commented out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4e201f",
   "metadata": {},
   "source": [
    "## 9. Evaluation Metrics Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22226ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metric functions\n",
    "def calculate_mape(y_true, y_pred):\n",
    "    \"\"\"Calculate Mean Absolute Percentage Error\"\"\"\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mask = y_true != 0\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    \"\"\"Calculate Root Mean Square Error\"\"\"\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def calculate_returns(prices):\n",
    "    \"\"\"Calculate returns from prices\"\"\"\n",
    "    prices = np.array(prices)\n",
    "    return np.diff(prices) / prices[:-1]\n",
    "\n",
    "def calculate_sharpe_ratio(returns, risk_free_rate=0.0):\n",
    "    \"\"\"Calculate Sharpe Ratio\"\"\"\n",
    "    excess_returns = returns - risk_free_rate\n",
    "    if np.std(returns) == 0:\n",
    "        return 0.0\n",
    "    return np.mean(excess_returns) / np.std(returns)\n",
    "\n",
    "def calculate_sortino_ratio(returns, risk_free_rate=0.0):\n",
    "    \"\"\"Calculate Sortino Ratio\"\"\"\n",
    "    excess_returns = returns - risk_free_rate\n",
    "    downside_returns = returns[returns < 0]\n",
    "    if len(downside_returns) == 0 or np.std(downside_returns) == 0:\n",
    "        return 0.0\n",
    "    return np.mean(excess_returns) / np.std(downside_returns)\n",
    "\n",
    "def calculate_max_drawdown(prices):\n",
    "    \"\"\"Calculate Maximum Drawdown\"\"\"\n",
    "    prices = np.array(prices)\n",
    "    cummax = np.maximum.accumulate(prices)\n",
    "    drawdowns = (prices - cummax) / cummax\n",
    "    return np.min(drawdowns)\n",
    "\n",
    "def calculate_cumulative_return(prices):\n",
    "    \"\"\"Calculate Cumulative Return\"\"\"\n",
    "    prices = np.array(prices)\n",
    "    return (prices[-1] - prices[0]) / prices[0]\n",
    "\n",
    "print(\"Evaluation metrics defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5046dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all models by ticker\n",
    "def evaluate_model_by_ticker(predictions, actual_prices, test_labels):\n",
    "    \"\"\"Evaluate model performance for each ticker\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for ticker in test_labels['ticker'].unique():\n",
    "        ticker_mask = test_labels['ticker'] == ticker\n",
    "        ticker_pred = predictions[ticker_mask]\n",
    "        ticker_actual = actual_prices[ticker_mask]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mape = calculate_mape(ticker_actual, ticker_pred)\n",
    "        rmse = calculate_rmse(ticker_actual, ticker_pred)\n",
    "        \n",
    "        # Returns-based metrics\n",
    "        returns = calculate_returns(ticker_pred)\n",
    "        sharpe = calculate_sharpe_ratio(returns)\n",
    "        sortino = calculate_sortino_ratio(returns)\n",
    "        max_dd = calculate_max_drawdown(ticker_pred)\n",
    "        cum_return = calculate_cumulative_return(ticker_pred)\n",
    "        \n",
    "        results[ticker] = {\n",
    "            'MAPE': mape,\n",
    "            'RMSE': rmse,\n",
    "            'Sharpe Ratio': sharpe,\n",
    "            'Sortino Ratio': sortino,\n",
    "            'Max Drawdown': max_dd,\n",
    "            'Cumulative Return': cum_return\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Model evaluation function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b801f7",
   "metadata": {},
   "source": [
    "## 10. Results Comparison and Analysis (LLM vs LLM-PPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced07683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all model predictions\n",
    "models_results = {}\n",
    "\n",
    "# # Baseline models (COMMENTED OUT)\n",
    "# models_results['SVR'] = evaluate_model_by_ticker(svr_predictions, y_test, test_labels)\n",
    "# models_results['XGBoost'] = evaluate_model_by_ticker(xgb_predictions, y_test, test_labels)\n",
    "# models_results['LSTM'] = evaluate_model_by_ticker(lstm_predictions, y_test, test_labels)\n",
    "\n",
    "# For LLM and LLM-PPO, we need to evaluate from test_df\n",
    "# Evaluate LLM predictions\n",
    "if 'llm_prediction' in test_df.columns:\n",
    "    llm_predictions = test_df['llm_prediction'].values\n",
    "    actual_prices = test_df['actual_price'].values\n",
    "    models_results['LLM'] = evaluate_model_by_ticker(llm_predictions, actual_prices, test_df)\n",
    "\n",
    "# Evaluate LLM-PPO predictions\n",
    "if 'ppo_adjusted_prediction' in test_df.columns:\n",
    "    ppo_predictions = test_df['ppo_adjusted_prediction'].values\n",
    "    actual_prices = test_df['actual_price'].values\n",
    "    models_results['LLM-PPO'] = evaluate_model_by_ticker(ppo_predictions, actual_prices, test_df)\n",
    "\n",
    "print(\"Model evaluation completed!\")\n",
    "print(f\"\\nNumber of models evaluated: {len(models_results)}\")\n",
    "print(f\"Models: {list(models_results.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd6086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "def create_comparison_table(models_results):\n",
    "    \"\"\"Create a comprehensive comparison table\"\"\"\n",
    "    comparison_data = []\n",
    "    \n",
    "    for model_name, ticker_results in models_results.items():\n",
    "        for ticker, metrics in ticker_results.items():\n",
    "            row = {\n",
    "                'Model': model_name,\n",
    "                'Ticker': ticker,\n",
    "                **metrics\n",
    "            }\n",
    "            comparison_data.append(row)\n",
    "    \n",
    "    return pd.DataFrame(comparison_data)\n",
    "\n",
    "comparison_df = create_comparison_table(models_results)\n",
    "print(\"\\nModel Comparison Results:\")\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2602e4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average metrics across all tickers\n",
    "avg_metrics = comparison_df.groupby('Model')[['MAPE', 'RMSE', 'Sharpe Ratio', \n",
    "                                                'Sortino Ratio', 'Max Drawdown', \n",
    "                                                'Cumulative Return']].mean()\n",
    "\n",
    "print(\"\\nAverage Performance Across All Tickers:\")\n",
    "avg_metrics.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f406d4ba",
   "metadata": {},
   "source": [
    "## 11. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b274ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot MAPE comparison\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "comparison_df_pivot = comparison_df.pivot(index='Ticker', columns='Model', values='MAPE')\n",
    "comparison_df_pivot.plot(kind='bar', ax=plt.gca())\n",
    "plt.title('MAPE Comparison by Ticker', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Ticker')\n",
    "plt.ylabel('MAPE (%)')\n",
    "plt.legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "avg_metrics['MAPE'].plot(kind='bar', color='steelblue')\n",
    "plt.title('Average MAPE Across All Tickers', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('MAPE (%)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4024d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot RMSE comparison\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "comparison_df_pivot = comparison_df.pivot(index='Ticker', columns='Model', values='RMSE')\n",
    "comparison_df_pivot.plot(kind='bar', ax=plt.gca())\n",
    "plt.title('RMSE Comparison by Ticker', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Ticker')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "avg_metrics['RMSE'].plot(kind='bar', color='coral')\n",
    "plt.title('Average RMSE Across All Tickers', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('RMSE')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c912d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot risk-adjusted metrics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Sharpe Ratio\n",
    "avg_metrics['Sharpe Ratio'].plot(kind='bar', ax=axes[0, 0], color='green', alpha=0.7)\n",
    "axes[0, 0].set_title('Sharpe Ratio (Higher is Better)', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Model')\n",
    "axes[0, 0].set_ylabel('Sharpe Ratio')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Sortino Ratio\n",
    "avg_metrics['Sortino Ratio'].plot(kind='bar', ax=axes[0, 1], color='blue', alpha=0.7)\n",
    "axes[0, 1].set_title('Sortino Ratio (Higher is Better)', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Model')\n",
    "axes[0, 1].set_ylabel('Sortino Ratio')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Maximum Drawdown\n",
    "avg_metrics['Max Drawdown'].plot(kind='bar', ax=axes[1, 0], color='red', alpha=0.7)\n",
    "axes[1, 0].set_title('Maximum Drawdown (Closer to 0 is Better)', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Model')\n",
    "axes[1, 0].set_ylabel('Max Drawdown')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Cumulative Return\n",
    "avg_metrics['Cumulative Return'].plot(kind='bar', ax=axes[1, 1], color='purple', alpha=0.7)\n",
    "axes[1, 1].set_title('Cumulative Return (Higher is Better)', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Model')\n",
    "axes[1, 1].set_ylabel('Cumulative Return')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.suptitle('Risk-Adjusted Performance Metrics', fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23903077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample prediction visualization (if test_df available)\n",
    "if 'ticker' in test_df.columns:\n",
    "    # Select one ticker for detailed visualization\n",
    "    sample_ticker = test_df['ticker'].iloc[0]\n",
    "    ticker_data = test_df[test_df['ticker'] == sample_ticker].head(50)\n",
    "    \n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    x = range(len(ticker_data))\n",
    "    plt.plot(x, ticker_data['actual_price'].values, 'ko-', label='Actual Price', linewidth=2, markersize=6)\n",
    "    plt.plot(x, ticker_data['llm_prediction'].values, 'bs--', label='LLM Prediction', linewidth=1.5, markersize=5, alpha=0.7)\n",
    "    \n",
    "    if 'ppo_adjusted_prediction' in ticker_data.columns:\n",
    "        plt.plot(x, ticker_data['ppo_adjusted_prediction'].values, 'r^--', label='LLM-PPO Prediction', linewidth=1.5, markersize=5, alpha=0.7)\n",
    "    \n",
    "    plt.title(f'Stock Price Predictions for {sample_ticker} (First 50 Test Samples)', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Stock Price')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6e9e18",
   "metadata": {},
   "source": [
    "## 12. Key Findings and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8482cbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"=\"*80)\n",
    "print(\"SUMMARY OF RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. PREDICTION ACCURACY (Lower is Better)\")\n",
    "print(\"-\" * 80)\n",
    "accuracy_summary = avg_metrics[['MAPE', 'RMSE']].round(4)\n",
    "print(accuracy_summary)\n",
    "\n",
    "print(\"\\n2. RISK-ADJUSTED RETURNS (Higher is Better for Ratios)\")\n",
    "print(\"-\" * 80)\n",
    "risk_summary = avg_metrics[['Sharpe Ratio', 'Sortino Ratio']].round(4)\n",
    "print(risk_summary)\n",
    "\n",
    "print(\"\\n3. RISK METRICS\")\n",
    "print(\"-\" * 80)\n",
    "drawdown_summary = avg_metrics[['Max Drawdown', 'Cumulative Return']].round(4)\n",
    "print(drawdown_summary)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONCLUSION\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "The two-stage LLM-PPO framework aims to:\n",
    "1. Generate initial predictions using LLM with historical data and sentiment\n",
    "2. Refine predictions using PPO with risk-aware adjustments (VaR, CVaR)\n",
    "\n",
    "Key Benefits:\n",
    "- Incorporates both market data and qualitative information (news sentiment)\n",
    "- Balances prediction accuracy with financial risk management\n",
    "- Provides more stable predictions compared to pure ML/DL approaches\n",
    "- Better risk-adjusted returns through CVaR-based reward function\n",
    "\n",
    "The framework demonstrates the potential of combining LLMs with reinforcement\n",
    "learning for robust financial forecasting in uncertain market environments.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d7ed89",
   "metadata": {},
   "source": [
    "## 13. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5dee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save comparison results\n",
    "output_dir = '../results'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save comparison table\n",
    "comparison_df.to_csv(f'{output_dir}/model_comparison_results.csv', index=False)\n",
    "print(f\"Comparison results saved to {output_dir}/model_comparison_results.csv\")\n",
    "\n",
    "# Save average metrics\n",
    "avg_metrics.to_csv(f'{output_dir}/average_metrics.csv')\n",
    "print(f\"Average metrics saved to {output_dir}/average_metrics.csv\")\n",
    "\n",
    "# Save PPO model\n",
    "model.save(f'{output_dir}/ppo_stock_prediction_model')\n",
    "print(f\"PPO model saved to {output_dir}/ppo_stock_prediction_model\")\n",
    "\n",
    "# Save test predictions\n",
    "if 'ppo_adjusted_prediction' in test_df.columns:\n",
    "    test_df.to_csv(f'{output_dir}/test_predictions.csv', index=False)\n",
    "    print(f\"Test predictions saved to {output_dir}/test_predictions.csv\")\n",
    "\n",
    "print(\"\\nAll results saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4e06a9",
   "metadata": {},
   "source": [
    "## 14. Next Steps and Extensions\n",
    "\n",
    "### Potential Improvements:\n",
    "1. **Fine-tune LLM**: Fine-tune the Llama model on financial data for better domain-specific predictions\n",
    "2. **Enhanced PPO**: Experiment with different reward functions and hyperparameters\n",
    "3. **More Baselines**: Implement TCN (Temporal Convolutional Network) for comparison\n",
    "4. **Real-time Prediction**: Adapt the framework for real-time stock prediction\n",
    "5. **Portfolio Optimization**: Extend to multi-stock portfolio management\n",
    "6. **Risk Metrics**: Incorporate additional risk metrics (CVaR at different confidence levels)\n",
    "7. **Ensemble Methods**: Combine multiple models for more robust predictions\n",
    "8. **Market Regime Detection**: Adapt strategy based on market conditions (bull/bear markets)\n",
    "\n",
    "### Research Directions:\n",
    "- Study the interpretability of LLM predictions\n",
    "- Analyze the impact of different sentiment sources\n",
    "- Investigate transfer learning across different stocks\n",
    "- Explore attention mechanisms in the PPO policy network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f291325b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Notes for Cloud Deployment\n",
    "\n",
    "### Google Colab Setup:\n",
    "1. Enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU\n",
    "2. Run all cells in order\n",
    "3. Data will be saved to `/content/` directory\n",
    "4. Download results before session ends\n",
    "\n",
    "### Kaggle Setup:\n",
    "1. Enable GPU: Settings ‚Üí Accelerator ‚Üí GPU T4 x2\n",
    "2. Upload data as a dataset or use !git clone\n",
    "3. Data saved to `/kaggle/working/`\n",
    "4. Results persist after run completion\n",
    "\n",
    "### Troubleshooting:\n",
    "- **Out of memory**: Restart runtime, clear cache with `torch.cuda.empty_cache()`\n",
    "- **Model download fails**: Check HuggingFace authentication\n",
    "- **Slow inference**: Verify GPU is enabled with `torch.cuda.is_available()`\n",
    "- **Data not found**: Check DATA_PATH variable matches your setup\n",
    "\n",
    "### Performance Expectations:\n",
    "- **Model loading**: 2-5 minutes (first time)\n",
    "- **Per prediction**: 2-5 seconds on GPU\n",
    "- **Total inference time**: 2-6 hours for all data\n",
    "- **Memory usage**: 6-8 GB VRAM (with 4-bit quantization)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
