{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85888fb3",
   "metadata": {},
   "source": [
    "# Inference of baseline small LLM (Llama 3.1 8B) on stock price data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3dacb7",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "245fb057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run once)\n",
    "#!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c500d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Hugging Face packages (run once if using local Llama)\n",
    "# !pip install transformers accelerate bitsandbytes torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8568c9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Standard library\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "# Environment variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# HTTP requests for HF endpoint\n",
    "import requests\n",
    "\n",
    "# # Machine Learning\n",
    "# from sklearn.svm import SVR\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
    "# from xgboost import XGBRegressor\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Reinforcement Learning\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "# Progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6439c850",
   "metadata": {},
   "source": [
    "## 2. Hugging Face Dedicated Endpoint Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17c9dd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Hugging Face Dedicated Endpoint configured!\n",
      "   Endpoint: https://o988k6zvcj6ifd2u.us-east-1.aws.endpoints.huggingface.cloud\n",
      "   Model: Llama 3.1 8B Instruct\n",
      "   Max Tokens: 1024\n",
      "   Temperature: 0.0\n",
      "   Rate limits: UNLIMITED! üéâ\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv('../.env')\n",
    "\n",
    "# LLM Configuration\n",
    "MAX_TOKENS = 1024\n",
    "TEMPERATURE = 0.0\n",
    "\n",
    "# Hugging Face Dedicated Endpoint\n",
    "HF_ENDPOINT_URL = \"https://o988k6zvcj6ifd2u.us-east-1.aws.endpoints.huggingface.cloud\"\n",
    "\n",
    "# Get HF token\n",
    "hf_token = os.getenv('HF_TOKEN')\n",
    "if not hf_token:\n",
    "    raise ValueError(\"HF_TOKEN not found in .env file. Get token from: https://huggingface.co/settings/tokens\")\n",
    "\n",
    "print(f\"‚úÖ Hugging Face Dedicated Endpoint configured!\")\n",
    "print(f\"   Endpoint: {HF_ENDPOINT_URL}\")\n",
    "print(f\"   Model: Llama 3.1 8B Instruct\")\n",
    "print(f\"   Max Tokens: {MAX_TOKENS}\")\n",
    "\n",
    "print(f\"   Temperature: {TEMPERATURE}\")\n",
    "print(f\"   Rate limits: UNLIMITED! üéâ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92e4277",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c97c9bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 8698\n",
      "Validation samples: 1243\n",
      "Test samples: 2477\n",
      "\n",
      "All labels shape: (12418, 16)\n",
      "\n",
      "Stocks in dataset: ['AAPL' 'HSBC' '0700.HK' 'PEP' '7203.T']\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "def load_jsonl(filepath):\n",
    "    \"\"\"Load JSONL file\"\"\"\n",
    "    data = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "# Load train, val, test data\n",
    "train_data = load_jsonl('../finetune_paper/train.jsonl')\n",
    "val_data = load_jsonl('../finetune_paper/val.jsonl')\n",
    "test_data = load_jsonl('../finetune_paper/test.jsonl')\n",
    "\n",
    "# Load supervised labels\n",
    "all_labels = pd.read_csv('../finetune_paper/all_supervised_price_labels.csv')\n",
    "\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Validation samples: {len(val_data)}\")\n",
    "print(f\"Test samples: {len(test_data)}\")\n",
    "print(f\"\\nAll labels shape: {all_labels.shape}\")\n",
    "print(f\"\\nStocks in dataset: {all_labels['ticker'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5df0427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample training data:\n",
      "Prompt (first 500 chars): You are a financial analyst with expertise in stock market forecasting.\n",
      "Your task is to analyze market data and predict the next trading day stock price.\n",
      "Use historical price trends, technical indicators, and sentiment analysis to provide an informed forecast.\n",
      "Ensure that your predictions are well-justified, considering multiple financial factors.\n",
      "\n",
      "‚Ä¢ Predicted Stock Price: The forecasted close price for the next trading day.\n",
      "‚Ä¢ Price Movement Likelihood: The likelihood of the predicted stock pric...\n",
      "\n",
      "Response: {\"predicted_close\": 27.18000030517578, \"likelihood\": 0.5, \"justification\": \"n/a\"}\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Sample supervised labels:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>SMA_20</th>\n",
       "      <th>SMA_50</th>\n",
       "      <th>EMA_12</th>\n",
       "      <th>EMA_26</th>\n",
       "      <th>RSI_14</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_signal</th>\n",
       "      <th>MACD_hist</th>\n",
       "      <th>BB_width_20_2</th>\n",
       "      <th>headline_count</th>\n",
       "      <th>sent_compound_mean</th>\n",
       "      <th>titles_joined</th>\n",
       "      <th>next_close</th>\n",
       "      <th>confidence_proxy</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-16 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.159062</td>\n",
       "      <td>27.234398</td>\n",
       "      <td>13.536208</td>\n",
       "      <td>-0.075335</td>\n",
       "      <td>-0.015690</td>\n",
       "      <td>-0.059645</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.079550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.180000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-16 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.765558</td>\n",
       "      <td>46.231136</td>\n",
       "      <td>4.645025</td>\n",
       "      <td>-0.465578</td>\n",
       "      <td>-0.348537</td>\n",
       "      <td>-0.117041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.308567</td>\n",
       "      <td>Which London business pays the highest busines...</td>\n",
       "      <td>45.360001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>HSBC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-16 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113.078837</td>\n",
       "      <td>109.846862</td>\n",
       "      <td>68.406756</td>\n",
       "      <td>3.231975</td>\n",
       "      <td>2.607665</td>\n",
       "      <td>0.624309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113.388344</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0700.HK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-16 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.059458</td>\n",
       "      <td>95.400737</td>\n",
       "      <td>36.546590</td>\n",
       "      <td>0.658721</td>\n",
       "      <td>0.411460</td>\n",
       "      <td>0.247261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.082980</td>\n",
       "      <td>Audrey P. \"Pep\" Landry Obituary January 16, 20...</td>\n",
       "      <td>97.510002</td>\n",
       "      <td>0.5</td>\n",
       "      <td>PEP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-19 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113.126453</td>\n",
       "      <td>110.109194</td>\n",
       "      <td>70.079261</td>\n",
       "      <td>3.017259</td>\n",
       "      <td>2.689584</td>\n",
       "      <td>0.327675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.361200</td>\n",
       "      <td>WeChat apologizes for showering Chinese users ...</td>\n",
       "      <td>114.402382</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0700.HK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Date  SMA_20  SMA_50      EMA_12      EMA_26  \\\n",
       "0  2015-01-16 00:00:00+00:00     NaN     NaN   27.159062   27.234398   \n",
       "1  2015-01-16 00:00:00+00:00     NaN     NaN   45.765558   46.231136   \n",
       "2  2015-01-16 00:00:00+00:00     NaN     NaN  113.078837  109.846862   \n",
       "3  2015-01-16 00:00:00+00:00     NaN     NaN   96.059458   95.400737   \n",
       "4  2015-01-19 00:00:00+00:00     NaN     NaN  113.126453  110.109194   \n",
       "\n",
       "      RSI_14      MACD  MACD_signal  MACD_hist  BB_width_20_2  headline_count  \\\n",
       "0  13.536208 -0.075335    -0.015690  -0.059645            NaN             4.0   \n",
       "1   4.645025 -0.465578    -0.348537  -0.117041            NaN             6.0   \n",
       "2  68.406756  3.231975     2.607665   0.624309            NaN             1.0   \n",
       "3  36.546590  0.658721     0.411460   0.247261            NaN            10.0   \n",
       "4  70.079261  3.017259     2.689584   0.327675            NaN             1.0   \n",
       "\n",
       "   sent_compound_mean                                      titles_joined  \\\n",
       "0           -0.079550                                                NaN   \n",
       "1            0.308567  Which London business pays the highest busines...   \n",
       "2            0.000000                                                NaN   \n",
       "3            0.082980  Audrey P. \"Pep\" Landry Obituary January 16, 20...   \n",
       "4            0.361200  WeChat apologizes for showering Chinese users ...   \n",
       "\n",
       "   next_close  confidence_proxy   ticker  \n",
       "0   27.180000               0.5     AAPL  \n",
       "1   45.360001               0.9     HSBC  \n",
       "2  113.388344               0.5  0700.HK  \n",
       "3   97.510002               0.5      PEP  \n",
       "4  114.402382               0.5  0700.HK  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display sample data\n",
    "print(\"Sample training data:\")\n",
    "print(f\"Prompt (first 500 chars): {train_data[0]['prompt'][:500]}...\")\n",
    "print(f\"\\nResponse: {train_data[0]['response']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "print(\"Sample supervised labels:\")\n",
    "all_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef5039f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed test data shape: (2477, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>predicted_close</th>\n",
       "      <th>likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HSBC</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>32.680000</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0700.HK</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>342.870056</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PEP</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>178.970001</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>126.360001</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7203.T</td>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>1807.500000</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker        date  predicted_close  likelihood\n",
       "0     HSBC  2023-01-03        32.680000         0.9\n",
       "1  0700.HK  2023-01-03       342.870056         0.5\n",
       "2      PEP  2023-01-03       178.970001         0.9\n",
       "3     AAPL  2023-01-03       126.360001         0.5\n",
       "4   7203.T  2023-01-04      1807.500000         0.7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse test data for evaluation\n",
    "POSITIVE_JUSTIFICATION_KEYWORDS = {\n",
    "    \"increase\", \"growth\", \"upward\", \"bullish\", \"positive\", \"gain\", \"improve\", \"strength\", \"rally\", \"optimistic\"\n",
    "}\n",
    "NEGATIVE_JUSTIFICATION_KEYWORDS = {\n",
    "    \"decrease\", \"decline\", \"downward\", \"bearish\", \"negative\", \"loss\", \"drop\", \"weakness\", \"sell\", \"pessimistic\"\n",
    "}\n",
    "RISK_JUSTIFICATION_KEYWORDS = {\n",
    "    \"volatility\", \"volatile\", \"risk\", \"uncertain\", \"uncertainty\", \"caution\", \"concern\", \"warning\", \"downside\"\n",
    "}\n",
    "\n",
    "def parse_prompt_data(prompt_text):\n",
    "    \"\"\"Extract key information from prompt\"\"\"\n",
    "    lines = prompt_text.split('\\n')\n",
    "    data = {}\n",
    "    \n",
    "    for line in lines:\n",
    "        if 'TICKER:' in line:\n",
    "            data['ticker'] = line.split('TICKER:')[1].strip()\n",
    "        elif 'DATE:' in line:\n",
    "            data['date'] = line.split('DATE:')[1].strip()\n",
    "        elif 'RECENT CLOSING PRICES' in line:\n",
    "            prices_line = lines[lines.index(line) + 1]\n",
    "            if prices_line.strip():\n",
    "                data['recent_prices'] = [float(p.strip()) for p in prices_line.split(',') if p.strip()]\n",
    "    \n",
    "    return data\n",
    "\n",
    "def safe_float(value, default=0.0) -> float:\n",
    "    try:\n",
    "        return float(value)\n",
    "    except (TypeError, ValueError):\n",
    "        return float(default)\n",
    "\n",
    "def extract_justification_features(justification: str) -> Dict[str, float]:\n",
    "    base = {\n",
    "        \"justification_pos_ratio\": 0.0,\n",
    "        \"justification_neg_ratio\": 0.0,\n",
    "        \"justification_risk_ratio\": 0.0,\n",
    "        \"justification_polarity\": 0.0,\n",
    "        \"justification_length\": 0.0,\n",
    "    }\n",
    "    if not justification:\n",
    "        return base.copy()\n",
    "    tokens = re.findall(r\"[a-zA-Z']+\", justification.lower())\n",
    "    token_count = max(len(tokens), 1)\n",
    "    pos_hits = sum(token in POSITIVE_JUSTIFICATION_KEYWORDS for token in tokens)\n",
    "    neg_hits = sum(token in NEGATIVE_JUSTIFICATION_KEYWORDS for token in tokens)\n",
    "    risk_hits = sum(token in RISK_JUSTIFICATION_KEYWORDS for token in tokens)\n",
    "    base.update({\n",
    "        \"justification_pos_ratio\": float(pos_hits / token_count),\n",
    "        \"justification_neg_ratio\": float(neg_hits / token_count),\n",
    "        \"justification_risk_ratio\": float(risk_hits / token_count),\n",
    "        \"justification_polarity\": float((pos_hits - neg_hits) / token_count),\n",
    "        \"justification_length\": float(np.log1p(token_count)),\n",
    "    })\n",
    "    return base\n",
    "\n",
    "# Parse test data\n",
    "test_parsed = []\n",
    "for item in test_data:\n",
    "    parsed = parse_prompt_data(item['prompt'])\n",
    "    response = json.loads(item['response'])\n",
    "    parsed['predicted_close'] = response['predicted_close']\n",
    "    parsed['likelihood'] = response['likelihood']\n",
    "    test_parsed.append(parsed)\n",
    "\n",
    "test_df = pd.DataFrame(test_parsed)\n",
    "print(f\"Parsed test data shape: {test_df.shape}\")\n",
    "test_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713b6114",
   "metadata": {},
   "source": [
    "## 4. Stage 1: LLM-Based Stock Price Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c62801f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing Hugging Face Dedicated Endpoint with a sample prediction...\n",
      "================================================================================\n",
      "Sample prompt (first 300 chars):\n",
      "You are a financial analyst with expertise in stock market forecasting.\n",
      "Your task is to analyze market data and predict the next trading day stock price.\n",
      "Use historical price trends, technical indicators, and sentiment analysis to provide an informed forecast.\n",
      "Ensure that your predictions are well-j...\n",
      "\n",
      "‚è∞ Generating prediction...\n",
      "[{\"generated_text\":\" {\\\"predicted_close\\\": 31.6300, \\\"likelihood\\\": 0.8, \\\"justification\\\": \\\"Based on recent closing prices, technical indicators, and sentiment analysis, the predicted close price for HSBC on 2023-01-03 is 31.6300. The likelihood of this prediction is 0.8. The justification for this prediction is as follows: The recent closing prices indicate a bullish trend, with the stock price increasing over the past few days. The technical indicators, such as the SMA, EMA, RSI, MACD, and Bollinger Bands, also suggest a bullish trend. The sentiment analysis shows a positive sentiment towards HSBC, with news headlines indicating potential growth opportunities for the company. Overall, these signals suggest a high likelihood of the predicted close price of 31.6300.\\\"}\\n\"}]\n",
      " {\"predicted_close\": 31.6300, \"likelihood\": 0.8, \"justification\": \"Based on recent closing prices, technical indicators, and sentiment analysis, the predicted close price for HSBC on 2023-01-03 is 31.6300. The likelihood of this prediction is 0.8. The justification for this prediction is as follows: The recent closing prices indicate a bullish trend, with the stock price increasing over the past few days. The technical indicators, such as the SMA, EMA, RSI, MACD, and Bollinger Bands, also suggest a bullish trend. The sentiment analysis shows a positive sentiment towards HSBC, with news headlines indicating potential growth opportunities for the company. Overall, these signals suggest a high likelihood of the predicted close price of 31.6300.\"}\n",
      "\n",
      "\n",
      "‚è±Ô∏è Inference time: 12.90 seconds\n",
      "\n",
      "HF Endpoint Prediction Result:\n",
      "{\n",
      "  \"predicted_close\": 31.63,\n",
      "  \"likelihood\": 0.8,\n",
      "  \"justification\": \"Based on recent closing prices, technical indicators, and sentiment analysis, the predicted close price for HSBC on 2023-01-03 is 31.6300. The likelihood of this prediction is 0.8. The justification for this prediction is as follows: The recent closing prices indicate a bullish trend, with the stock price increasing over the past few days. The technical indicators, such as the SMA, EMA, RSI, MACD, and Bollinger Bands, also suggest a bullish trend. The sentiment analysis shows a positive sentiment towards HSBC, with news headlines indicating potential growth opportunities for the company. Overall, these signals suggest a high likelihood of the predicted close price of 31.6300.\"\n",
      "}\n",
      "\n",
      "Actual Target Price: 32.68000030517578\n",
      "\n",
      "‚úÖ HF Dedicated Endpoint is working!\n",
      "üí° Speed: ~12.9s per prediction\n",
      "üí° No rate limits - run unlimited predictions!\n",
      "================================================================================\n",
      "[{\"generated_text\":\" {\\\"predicted_close\\\": 31.6300, \\\"likelihood\\\": 0.8, \\\"justification\\\": \\\"Based on recent closing prices, technical indicators, and sentiment analysis, the predicted close price for HSBC on 2023-01-03 is 31.6300. The likelihood of this prediction is 0.8. The justification for this prediction is as follows: The recent closing prices indicate a bullish trend, with the stock price increasing over the past few days. The technical indicators, such as the SMA, EMA, RSI, MACD, and Bollinger Bands, also suggest a bullish trend. The sentiment analysis shows a positive sentiment towards HSBC, with news headlines indicating potential growth opportunities for the company. Overall, these signals suggest a high likelihood of the predicted close price of 31.6300.\\\"}\\n\"}]\n",
      " {\"predicted_close\": 31.6300, \"likelihood\": 0.8, \"justification\": \"Based on recent closing prices, technical indicators, and sentiment analysis, the predicted close price for HSBC on 2023-01-03 is 31.6300. The likelihood of this prediction is 0.8. The justification for this prediction is as follows: The recent closing prices indicate a bullish trend, with the stock price increasing over the past few days. The technical indicators, such as the SMA, EMA, RSI, MACD, and Bollinger Bands, also suggest a bullish trend. The sentiment analysis shows a positive sentiment towards HSBC, with news headlines indicating potential growth opportunities for the company. Overall, these signals suggest a high likelihood of the predicted close price of 31.6300.\"}\n",
      "\n",
      "\n",
      "‚è±Ô∏è Inference time: 12.90 seconds\n",
      "\n",
      "HF Endpoint Prediction Result:\n",
      "{\n",
      "  \"predicted_close\": 31.63,\n",
      "  \"likelihood\": 0.8,\n",
      "  \"justification\": \"Based on recent closing prices, technical indicators, and sentiment analysis, the predicted close price for HSBC on 2023-01-03 is 31.6300. The likelihood of this prediction is 0.8. The justification for this prediction is as follows: The recent closing prices indicate a bullish trend, with the stock price increasing over the past few days. The technical indicators, such as the SMA, EMA, RSI, MACD, and Bollinger Bands, also suggest a bullish trend. The sentiment analysis shows a positive sentiment towards HSBC, with news headlines indicating potential growth opportunities for the company. Overall, these signals suggest a high likelihood of the predicted close price of 31.6300.\"\n",
      "}\n",
      "\n",
      "Actual Target Price: 32.68000030517578\n",
      "\n",
      "‚úÖ HF Dedicated Endpoint is working!\n",
      "üí° Speed: ~12.9s per prediction\n",
      "üí° No rate limits - run unlimited predictions!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def llm_predict_stock_price(prompt: str, retries: int = 3) -> Dict:\n",
    "    \"\"\"Use Hugging Face Dedicated Endpoint to predict stock price with retries.\"\"\"\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            headers = {\n",
    "                \"Accept\": \"application/json\",\n",
    "                \"Authorization\": f\"Bearer {hf_token}\",\n",
    "                \"Content-Type\": \"application/json\"\n",
    "            }\n",
    "            \n",
    "            payload = {\n",
    "                \"inputs\": prompt,\n",
    "                \"parameters\": {\n",
    "                    \"max_new_tokens\": MAX_TOKENS,\n",
    "                    \"temperature\": TEMPERATURE if TEMPERATURE > 0 else 0.1,\n",
    "                    \"return_full_text\": False\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            response = requests.post(\n",
    "                HF_ENDPOINT_URL,\n",
    "                headers=headers,\n",
    "                json=payload,\n",
    "                timeout=30\n",
    "            )\n",
    "\n",
    "            print(response.text)\n",
    "            \n",
    "            if response.status_code != 200:\n",
    "                print(f\"HF Endpoint Error (Attempt {attempt + 1}/{retries}): {response.status_code} - {response.text}\")\n",
    "                if attempt < retries - 1:\n",
    "                    time.sleep(2) # Wait 2 seconds before retrying\n",
    "                    continue\n",
    "                else:\n",
    "                    return {\"predicted_close\": None, \"likelihood\": 0.5, \"justification\": f\"API Error: {response.status_code}\"}\n",
    "            \n",
    "            result_data = response.json()\n",
    "            print(result_data[0].get('generated_text', ''))\n",
    "            \n",
    "            # Extract generated text\n",
    "            if isinstance(result_data, list) and len(result_data) > 0:\n",
    "                content = result_data[0].get('generated_text', '')\n",
    "            elif isinstance(result_data, dict):\n",
    "                content = result_data.get('generated_text', result_data.get('text', ''))\n",
    "            else:\n",
    "                content = str(result_data)\n",
    "            \n",
    "            # Parse JSON response\n",
    "            if '{' in content and '}' in content:\n",
    "                json_start = content.index('{')\n",
    "                json_end = content.rindex('}') + 1\n",
    "                json_str = content[json_start:json_end]\n",
    "                \n",
    "                try:\n",
    "                    result = json.loads(json_str)\n",
    "                    \n",
    "                    # Validate required fields\n",
    "                    if 'predicted_close' not in result:\n",
    "                        result['predicted_close'] = None\n",
    "                    if 'likelihood' not in result:\n",
    "                        result['likelihood'] = 0.5\n",
    "                    if 'justification' not in result:\n",
    "                        result['justification'] = ''\n",
    "                        \n",
    "                    return result # Success\n",
    "                except json.JSONDecodeError as je:\n",
    "                    print(f\"JSON parse error (Attempt {attempt + 1}/{retries}), attempting manual extraction: {je}\")\n",
    "                    \n",
    "                    # Try to extract values manually\n",
    "                    pred_match = re.search(r'\"predicted_close\"\\s*:\\s*([0-9.]+)', json_str)\n",
    "                    likelihood_match = re.search(r'\"likelihood\"\\s*:\\s*([0-9.]+)', json_str)\n",
    "                    \n",
    "                    if pred_match:\n",
    "                        return {\n",
    "                            \"predicted_close\": float(pred_match.group(1)),\n",
    "                            \"likelihood\": float(likelihood_match.group(1)) if likelihood_match else 0.5,\n",
    "                            \"justification\": \"Manually extracted from malformed JSON\"\n",
    "                        }\n",
    "                    else:\n",
    "                        # Manual extraction failed, retry if possible\n",
    "                        if attempt < retries - 1:\n",
    "                            time.sleep(2)\n",
    "                            continue\n",
    "                        else:\n",
    "                            return {\"predicted_close\": 0.0, \"likelihood\": 0.5, \"justification\": f\"JSON parse error: {str(je)}\"}\n",
    "            else:\n",
    "                # No JSON found, retry if possible\n",
    "                if attempt < retries - 1:\n",
    "                    time.sleep(2)\n",
    "                    continue\n",
    "                else:\n",
    "                    return {\"predicted_close\": 0.0, \"likelihood\": 0.5, \"justification\": \"No JSON found in response\"}\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in HF endpoint prediction (Attempt {attempt + 1}/{retries}): {e}\")\n",
    "            if attempt < retries - 1:\n",
    "                time.sleep(2) # Wait 2 seconds before retrying\n",
    "                continue\n",
    "            else:\n",
    "                return {\"predicted_close\": 0.0, \"likelihood\": 0.5, \"justification\": str(e)}\n",
    "    \n",
    "    # This is the fallback if all retries fail\n",
    "    return {\"predicted_close\": 0.0, \"likelihood\": 0.5, \"justification\": \"All retry attempts failed.\"}\n",
    "\n",
    "\n",
    "# Test HF Endpoint\n",
    "print(\"üß™ Testing Hugging Face Dedicated Endpoint with a sample prediction...\")\n",
    "print(\"=\"*80)\n",
    "print(\"Sample prompt (first 300 chars):\")\n",
    "sample_prompt = test_data[0]['prompt']\n",
    "print(sample_prompt[:300] + \"...\\n\")\n",
    "\n",
    "print(\"‚è∞ Generating prediction...\")\n",
    "start_time = time.time()\n",
    "llm_result = llm_predict_stock_price(sample_prompt)\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è Inference time: {elapsed:.2f} seconds\")\n",
    "print(\"\\nHF Endpoint Prediction Result:\")\n",
    "print(json.dumps(llm_result, indent=2))\n",
    "\n",
    "actual_response = json.loads(test_data[0]['response'])\n",
    "print(f\"\\nActual Target Price: {actual_response['predicted_close']}\")\n",
    "print(f\"\\n‚úÖ HF Dedicated Endpoint is working!\")\n",
    "print(f\"üí° Speed: ~{elapsed:.1f}s per prediction\")\n",
    "print(f\"üí° No rate limits - run unlimited predictions!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83e3c4a",
   "metadata": {},
   "source": [
    "### 4.1 Run LLM Inference on Training Data\n",
    "\n",
    "We'll generate LLM predictions for the training dataset to use for PPO training later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "111e1508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing training checkpoint from ../results/llm_predictions_train_checkpoint.json\n",
      "Resuming from index 8698/8698\n",
      "\n",
      "üîÑ Generating LLM predictions for 8698 TRAINING samples...\n",
      "‚è∞ This will take considerable time. You can stop and resume later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training LLM Inference: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Training LLM predictions completed: 8698 samples\n",
      "Checkpoint saved to: ../results/llm_predictions_train_checkpoint.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run LLM predictions on TRAINING data with checkpointing\n",
    "checkpoint_file_train = '../results/llm_predictions_train_checkpoint.json'\n",
    "\n",
    "# Load existing checkpoint if available\n",
    "if os.path.exists(checkpoint_file_train):\n",
    "    print(f\"Loading existing training checkpoint from {checkpoint_file_train}\")\n",
    "    with open(checkpoint_file_train, 'r') as f:\n",
    "        checkpoint = json.load(f)\n",
    "    train_llm_predictions = checkpoint['predictions']\n",
    "    train_actual_prices = checkpoint['actual_prices']\n",
    "    train_llm_results = checkpoint.get('llm_results', [])  # Full LLM responses\n",
    "    start_idx = checkpoint['last_idx'] + 1\n",
    "    print(f\"Resuming from index {start_idx}/{len(train_data)}\")\n",
    "else:\n",
    "    train_llm_predictions = []\n",
    "    train_actual_prices = []\n",
    "    train_llm_results = []\n",
    "    start_idx = 0\n",
    "    print(\"Starting fresh LLM predictions on training data...\")\n",
    "\n",
    "# Run LLM predictions\n",
    "print(f\"\\nüîÑ Generating LLM predictions for {len(train_data)} TRAINING samples...\")\n",
    "print(\"‚è∞ This will take considerable time. You can stop and resume later.\")\n",
    "\n",
    "for idx in tqdm(range(start_idx, len(train_data)), desc=\"Training LLM Inference\"):\n",
    "    item = train_data[idx]\n",
    "    \n",
    "    try:\n",
    "        # Get LLM prediction\n",
    "        llm_result = llm_predict_stock_price(item['prompt'])\n",
    "        \n",
    "        # Store full LLM result (including justification)\n",
    "        train_llm_results.append(llm_result)\n",
    "        \n",
    "        if llm_result['predicted_close'] is not None and float(llm_result['predicted_close']) > 0:\n",
    "            train_llm_predictions.append(llm_result['predicted_close'])\n",
    "        else:\n",
    "            # Fallback to 0.0 if prediction is invalid\n",
    "            train_llm_predictions.append(0.0)\n",
    "        \n",
    "        response = json.loads(item['response'])\n",
    "        train_actual_prices.append(response['predicted_close'])\n",
    "        \n",
    "        # # Delay to avoid rate limiting\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        # Checkpoint every 50 samples\n",
    "        if (idx + 1) % 50 == 0:\n",
    "            checkpoint = {\n",
    "                'predictions': train_llm_predictions,\n",
    "                'actual_prices': train_actual_prices,\n",
    "                'llm_results': train_llm_results,  # Full LLM responses with justification\n",
    "                'last_idx': idx\n",
    "            }\n",
    "            os.makedirs('../results', exist_ok=True)\n",
    "            with open(checkpoint_file_train, 'w') as f:\n",
    "                json.dump(checkpoint, f, indent=2)\n",
    "    \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        \n",
    "        if 'rate_limit' in error_msg.lower() or 'too many requests' in error_msg.lower():\n",
    "            print(f\"\\n‚ùå RATE LIMIT HIT at index {idx}!\")\n",
    "            print(f\"Saving checkpoint and stopping execution...\")\n",
    "            checkpoint = {\n",
    "                'predictions': train_llm_predictions,\n",
    "                'actual_prices': train_actual_prices,\n",
    "                'llm_results': train_llm_results,\n",
    "                'last_idx': idx - 1\n",
    "            }\n",
    "            os.makedirs('../results', exist_ok=True)\n",
    "            with open(checkpoint_file_train, 'w') as f:\n",
    "                json.dump(checkpoint, f, indent=2)\n",
    "            print(f\"‚úÖ Checkpoint saved to: {checkpoint_file_train}\")\n",
    "            print(f\"üìä Progress: {idx}/{len(train_data)} samples completed\")\n",
    "            print(f\"üí° Run this cell again to resume from where you left off.\")\n",
    "            break  # Stop execution\n",
    "        else:\n",
    "            print(f\"\\n‚ö†Ô∏è Error at index {idx}: {error_msg}\")\n",
    "            # Store error result\n",
    "            error_result = {\"predicted_close\": None, \"likelihood\": 0.5, \"justification\": f\"Error: {error_msg}\"}\n",
    "            train_llm_results.append(error_result)\n",
    "            # Use 0.0 as fallback for prediction\n",
    "            train_llm_predictions.append(0.0)\n",
    "            # Still append the actual price for comparison\n",
    "            response = json.loads(item['response'])\n",
    "            train_actual_prices.append(response['predicted_close'])\n",
    "\n",
    "# Final save\n",
    "checkpoint = {\n",
    "    'predictions': train_llm_predictions,\n",
    "    'actual_prices': train_actual_prices,\n",
    "    'llm_results': train_llm_results,\n",
    "    'last_idx': len(train_llm_predictions) - 1,\n",
    "    'completed': len(train_llm_predictions) == len(train_data)\n",
    "}\n",
    "with open(checkpoint_file_train, 'w') as f:\n",
    "    json.dump(checkpoint, f, indent=2)\n",
    "\n",
    "if len(train_llm_predictions) == len(train_data):\n",
    "    print(f\"\\n‚úÖ Training LLM predictions completed: {len(train_llm_predictions)} samples\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Partial completion: {len(train_llm_predictions)}/{len(train_data)} samples\")\n",
    "print(f\"Checkpoint saved to: {checkpoint_file_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca56443",
   "metadata": {},
   "source": [
    "### 4.2 Run LLM Inference on Validation Data\n",
    "\n",
    "Generate predictions for validation data (used for PPO training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "461999d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing validation checkpoint from ../results/llm_predictions_val_checkpoint.json\n",
      "Resuming from index 1243/1243\n",
      "\n",
      "üîÑ Generating LLM predictions for 1243 VALIDATION samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation LLM Inference: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Validation LLM predictions completed: 1243 samples\n",
      "Checkpoint saved to: ../results/llm_predictions_val_checkpoint.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run LLM predictions on VALIDATION data with checkpointing\n",
    "checkpoint_file_val = '../results/llm_predictions_val_checkpoint.json'\n",
    "\n",
    "if os.path.exists(checkpoint_file_val):\n",
    "    print(f\"Loading existing validation checkpoint from {checkpoint_file_val}\")\n",
    "    with open(checkpoint_file_val, 'r') as f:\n",
    "        checkpoint = json.load(f)\n",
    "    val_llm_predictions = checkpoint['predictions']\n",
    "    val_actual_prices = checkpoint['actual_prices']\n",
    "    val_llm_results = checkpoint.get('llm_results', [])\n",
    "    start_idx = checkpoint['last_idx'] + 1\n",
    "    print(f\"Resuming from index {start_idx}/{len(val_data)}\")\n",
    "else:\n",
    "    val_llm_predictions = []\n",
    "    val_actual_prices = []\n",
    "    val_llm_results = []\n",
    "    start_idx = 0\n",
    "    print(\"Starting fresh LLM predictions on validation data...\")\n",
    "\n",
    "print(f\"\\nüîÑ Generating LLM predictions for {len(val_data)} VALIDATION samples...\")\n",
    "\n",
    "for idx in tqdm(range(start_idx, len(val_data)), desc=\"Validation LLM Inference\"):\n",
    "    item = val_data[idx]\n",
    "    \n",
    "    try:\n",
    "        llm_result = llm_predict_stock_price(item['prompt'])\n",
    "        \n",
    "        # Store full LLM result\n",
    "        val_llm_results.append(llm_result)\n",
    "        \n",
    "        if llm_result['predicted_close'] is not None and float(llm_result['predicted_close']) > 0:\n",
    "            val_llm_predictions.append(llm_result['predicted_close'])\n",
    "        else:\n",
    "            # Fallback to 0.0 if prediction is invalid\n",
    "            val_llm_predictions.append(0.0)\n",
    "        \n",
    "        response = json.loads(item['response'])\n",
    "        val_actual_prices.append(response['predicted_close'])\n",
    "        \n",
    "        # time.sleep(0.5)\n",
    "        \n",
    "        if (idx + 1) % 50 == 0:\n",
    "            checkpoint = {\n",
    "                'predictions': val_llm_predictions,\n",
    "                'actual_prices': val_actual_prices,\n",
    "                'llm_results': val_llm_results,\n",
    "                'last_idx': idx\n",
    "            }\n",
    "            os.makedirs('../results', exist_ok=True)\n",
    "            with open(checkpoint_file_val, 'w') as f:\n",
    "                json.dump(checkpoint, f, indent=2)\n",
    "    \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        \n",
    "        if 'rate_limit' in error_msg.lower() or 'too many requests' in error_msg.lower():\n",
    "            print(f\"\\n‚ùå RATE LIMIT HIT at index {idx}!\")\n",
    "            print(f\"Saving checkpoint and stopping execution...\")\n",
    "            checkpoint = {\n",
    "                'predictions': val_llm_predictions,\n",
    "                'actual_prices': val_actual_prices,\n",
    "                'llm_results': val_llm_results,\n",
    "                'last_idx': idx - 1\n",
    "            }\n",
    "            os.makedirs('../results', exist_ok=True)\n",
    "            with open(checkpoint_file_val, 'w') as f:\n",
    "                json.dump(checkpoint, f, indent=2)\n",
    "            print(f\"‚úÖ Checkpoint saved to: {checkpoint_file_val}\")\n",
    "            print(f\"üìä Progress: {idx}/{len(val_data)} samples completed\")\n",
    "            print(f\"üí° Run this cell again to resume from where you left off.\")\n",
    "            break  # Stop execution\n",
    "        else:\n",
    "            print(f\"\\n‚ö†Ô∏è Error at index {idx}: {error_msg}\")\n",
    "            error_result = {\"predicted_close\": None, \"likelihood\": 0.5, \"justification\": f\"Error: {error_msg}\"}\n",
    "            val_llm_results.append(error_result)\n",
    "            # Use 0.0 as fallback for prediction\n",
    "            val_llm_predictions.append(0.0)\n",
    "            # Still append the actual price for comparison\n",
    "            response = json.loads(item['response'])\n",
    "            val_actual_prices.append(response['predicted_close'])\n",
    "\n",
    "checkpoint = {\n",
    "    'predictions': val_llm_predictions,\n",
    "    'actual_prices': val_actual_prices,\n",
    "    'llm_results': val_llm_results,\n",
    "    'last_idx': len(val_llm_predictions) - 1,\n",
    "    'completed': len(val_llm_predictions) == len(val_data)\n",
    "}\n",
    "with open(checkpoint_file_val, 'w') as f:\n",
    "    json.dump(checkpoint, f, indent=2)\n",
    "\n",
    "if len(val_llm_predictions) == len(val_data):\n",
    "    print(f\"\\n‚úÖ Validation LLM predictions completed: {len(val_llm_predictions)} samples\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Partial completion: {len(val_llm_predictions)}/{len(val_data)} samples\")\n",
    "print(f\"Checkpoint saved to: {checkpoint_file_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914cba71",
   "metadata": {},
   "source": [
    "### 4.3 Run LLM Inference on Test Data\n",
    "\n",
    "Generate predictions for test data (used for final evaluation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ad03246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing checkpoint from ../results/llm_predictions_checkpoint.json\n",
      "Resuming from index 2050/2477\n",
      "Generating LLM predictions for 2477 samples...\n",
      "This may take a while due to API rate limits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM Inference:  12%|‚ñà‚ñè        | 50/427 [10:32<1:38:25, 15.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at index 2100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM Inference:  15%|‚ñà‚ñç        | 62/427 [13:21<1:32:36, 15.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parse error (Attempt 1/3), attempting manual extraction: Invalid control character at: line 1 column 241 (char 240)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM Inference:  23%|‚ñà‚ñà‚ñé       | 100/427 [22:14<1:18:06, 14.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at index 2150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM Inference:  26%|‚ñà‚ñà‚ñã       | 113/427 [25:13<1:20:43, 15.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parse error (Attempt 1/3), attempting manual extraction: Invalid control character at: line 1 column 237 (char 236)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM Inference:  28%|‚ñà‚ñà‚ñä       | 119/427 [26:55<1:25:45, 16.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parse error (Attempt 1/3), attempting manual extraction: Extra data: line 3 column 1 (char 66)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM Inference:  29%|‚ñà‚ñà‚ñâ       | 123/427 [27:45<1:15:03, 14.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parse error (Attempt 1/3), attempting manual extraction: Invalid control character at: line 1 column 307 (char 306)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM Inference:  35%|‚ñà‚ñà‚ñà‚ñå      | 150/427 [34:07<51:10, 11.09s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at index 2200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM Inference:  41%|‚ñà‚ñà‚ñà‚ñà      | 175/427 [40:41<1:12:30, 17.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parse error (Attempt 1/3), attempting manual extraction: Invalid control character at: line 1 column 192 (char 191)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM Inference:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 200/427 [46:16<1:04:08, 16.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at index 2250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM Inference:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 250/427 [57:45<36:06, 12.24s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at index 2300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM Inference:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 285/427 [1:06:04<36:08, 15.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parse error (Attempt 1/3), attempting manual extraction: Invalid control character at: line 1 column 237 (char 236)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM Inference:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 300/427 [1:09:04<24:32, 11.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at index 2350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM Inference:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 339/427 [1:18:46<21:25, 14.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parse error (Attempt 1/3), attempting manual extraction: Invalid control character at: line 1 column 196 (char 195)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM Inference:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 350/427 [1:21:19<16:33, 12.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at index 2400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM Inference:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 380/427 [1:28:28<10:58, 14.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in HF endpoint prediction (Attempt 1/3): HTTPSConnectionPool(host='o988k6zvcj6ifd2u.us-east-1.aws.endpoints.huggingface.cloud', port=443): Read timed out. (read timeout=30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM Inference:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 400/427 [1:33:33<06:13, 13.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at index 2450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM Inference: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 427/427 [1:39:30<00:00, 13.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM predictions completed: 2477 samples\n",
      "Checkpoint saved to: ../results/llm_predictions_checkpoint.json\n",
      "Sample predictions:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run LLM predictions on test data with checkpointing\n",
    "import time\n",
    "\n",
    "# Checkpoint file to save progress\n",
    "checkpoint_file = '../results/llm_predictions_checkpoint.json'\n",
    "\n",
    "# Load existing checkpoint if available\n",
    "if os.path.exists(checkpoint_file):\n",
    "    print(f\"Loading existing checkpoint from {checkpoint_file}\")\n",
    "    with open(checkpoint_file, 'r') as f:\n",
    "        checkpoint = json.load(f)\n",
    "    llm_predictions = checkpoint['predictions']\n",
    "    actual_prices = checkpoint['actual_prices']\n",
    "    llm_results = checkpoint.get('llm_results', [])\n",
    "    start_idx = checkpoint['last_idx'] + 1\n",
    "    print(f\"Resuming from index {start_idx}/{len(test_data)}\")\n",
    "else:\n",
    "    llm_predictions = []\n",
    "    actual_prices = []\n",
    "    llm_results = []\n",
    "    start_idx = 0\n",
    "    print(\"Starting fresh LLM predictions...\")\n",
    "\n",
    "# Run LLM predictions with rate limiting and checkpointing\n",
    "print(f\"Generating LLM predictions for {len(test_data)} samples...\")\n",
    "print(\"This may take a while due to API rate limits...\")\n",
    "\n",
    "for idx in tqdm(range(start_idx, len(test_data)), desc=\"LLM Inference\"):\n",
    "    item = test_data[idx]\n",
    "    \n",
    "    try:\n",
    "        # Get LLM prediction\n",
    "        llm_result = llm_predict_stock_price(item['prompt'])\n",
    "        \n",
    "        # Store full LLM result\n",
    "        llm_results.append(llm_result)\n",
    "        \n",
    "        # Extract prediction\n",
    "        if llm_result['predicted_close'] is not None and float(llm_result['predicted_close']) > 0:\n",
    "            llm_predictions.append(llm_result['predicted_close'])\n",
    "        else:\n",
    "            # Fallback: use 0.0 if LLM fails\n",
    "            llm_predictions.append(0.0)\n",
    "        \n",
    "        # Get actual price from response\n",
    "        response = json.loads(item['response'])\n",
    "        actual_prices.append(response['predicted_close'])\n",
    "        \n",
    "        # Small delay to avoid rate limiting (adjust based on your API limits)\n",
    "        #time.sleep(0.5)\n",
    "\n",
    "        # Checkpoint every 50 samples\n",
    "        if (idx + 1) % 50 == 0:\n",
    "            checkpoint = {\n",
    "                'predictions': llm_predictions,\n",
    "                'actual_prices': actual_prices,\n",
    "                'llm_results': llm_results,\n",
    "                'last_idx': idx\n",
    "            }\n",
    "            os.makedirs('../results', exist_ok=True)\n",
    "            with open(checkpoint_file, 'w') as f:\n",
    "                json.dump(checkpoint, f, indent=2)\n",
    "            print(f\"Checkpoint saved at index {idx + 1}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        \n",
    "        # Handle rate limiting\n",
    "        if 'rate_limit' in error_msg.lower() or 'too many requests' in error_msg.lower():\n",
    "            print(f\"‚ùå RATE LIMIT HIT at index {idx}!\")\n",
    "            print(f\"Saving checkpoint and stopping execution...\")\n",
    "            \n",
    "            # Save checkpoint\n",
    "            checkpoint = {\n",
    "                'predictions': llm_predictions,\n",
    "                'actual_prices': actual_prices,\n",
    "                'llm_results': llm_results,\n",
    "                'last_idx': idx - 1\n",
    "            }\n",
    "            os.makedirs('../results', exist_ok=True)\n",
    "            with open(checkpoint_file, 'w') as f:\n",
    "                json.dump(checkpoint, f, indent=2)\n",
    "            \n",
    "            print(f\"‚úÖ Checkpoint saved to: {checkpoint_file}\")\n",
    "            print(f\"üìä Progress: {idx}/{len(test_data)} samples completed\")\n",
    "            print(f\"üí° Run this cell again to resume from where you left off.\")\n",
    "            break  # Stop execution\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Error at index {idx}: {error_msg}\")\n",
    "            # Store error result\n",
    "            error_result = {\"predicted_close\": None, \"likelihood\": 0.5, \"justification\": f\"Error: {error_msg}\"}\n",
    "            llm_results.append(error_result)\n",
    "            # Use fallback\n",
    "            # Use 0.0 as fallback for prediction\n",
    "            llm_predictions.append(0.0)\n",
    "            # Still append the actual price for comparison\n",
    "            response = json.loads(item['response'])\n",
    "            actual_prices.append(response['predicted_close'])\n",
    "\n",
    "# Final save\n",
    "checkpoint = {\n",
    "    'predictions': llm_predictions,\n",
    "    'actual_prices': actual_prices,\n",
    "    'llm_results': llm_results,\n",
    "    'last_idx': len(llm_predictions) - 1,\n",
    "    'completed': len(llm_predictions) == len(test_data)\n",
    "}\n",
    "with open(checkpoint_file, 'w') as f:\n",
    "    json.dump(checkpoint, f, indent=2)\n",
    "\n",
    "# Merge with test_df\n",
    "test_df['llm_prediction'] = llm_predictions\n",
    "test_df['actual_price'] = actual_prices\n",
    "\n",
    "if len(llm_results) == len(test_df):\n",
    "    justifications = []\n",
    "    likelihoods = []\n",
    "    feature_rows = []\n",
    "    for res in llm_results:\n",
    "        res = res if isinstance(res, dict) else {}\n",
    "        justification = res.get('justification', '')\n",
    "        justifications.append(justification)\n",
    "        likelihoods.append(safe_float(res.get('likelihood'), 0.5))\n",
    "        feature_rows.append(extract_justification_features(justification))\n",
    "else:\n",
    "    justifications = [''] * len(test_df)\n",
    "    likelihoods = [0.5] * len(test_df)\n",
    "    feature_rows = [extract_justification_features('') for _ in range(len(test_df))]\n",
    "\n",
    "if feature_rows:\n",
    "    feature_keys = list(feature_rows[0].keys())\n",
    "else:\n",
    "    feature_keys = list(extract_justification_features('').keys())\n",
    "\n",
    "test_df['llm_justification'] = justifications\n",
    "test_df['llm_likelihood'] = likelihoods\n",
    "for key in feature_keys:\n",
    "    test_df[key] = [row[key] for row in feature_rows]\n",
    "\n",
    "if len(llm_predictions) == len(test_data):\n",
    "    print(f\"‚úÖ LLM predictions completed: {len(llm_predictions)} samples\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Partial completion: {len(llm_predictions)}/{len(test_data)} samples\")\n",
    "print(f\"Checkpoint saved to: {checkpoint_file}\")\n",
    "print(\"Sample predictions:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e6e7a4",
   "metadata": {},
   "source": [
    "### 4.4 Check for Failed Predictions in Checkpoints\n",
    "\n",
    "Before training PPO, let's verify all predictions succeeded and fix any failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e1e8b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç CHECKING ALL CHECKPOINT FILES FOR FAILED/ZERO PREDICTIONS\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "üìä TRAINING CHECKPOINT ANALYSIS\n",
      "================================================================================\n",
      "Total predictions: 8698\n",
      "Failed/Zero predictions: 0\n",
      "Success rate: 100.00%\n",
      "\n",
      "‚úÖ All predictions are valid (not None and not zero)!\n",
      "\n",
      "================================================================================\n",
      "üìä VALIDATION CHECKPOINT ANALYSIS\n",
      "================================================================================\n",
      "Total predictions: 1243\n",
      "Failed/Zero predictions: 0\n",
      "Success rate: 100.00%\n",
      "\n",
      "‚úÖ All predictions are valid (not None and not zero)!\n",
      "\n",
      "================================================================================\n",
      "üìä TEST CHECKPOINT ANALYSIS\n",
      "================================================================================\n",
      "Total predictions: 2477\n",
      "Failed/Zero predictions: 123\n",
      "Success rate: 95.03%\n",
      "\n",
      "‚ö†Ô∏è Failed/Zero prediction indices (first 20): [1, 8, 14, 20, 61, 80, 91, 95, 100, 105, 173, 181, 194, 233, 246, 250, 251, 257, 259, 277]\n",
      "   ... and 103 more\n",
      "\n",
      "================================================================================\n",
      "üìà OVERALL SUMMARY\n",
      "================================================================================\n",
      "Training:   0/8698 failed or zero\n",
      "Validation: 0/1243 failed or zero\n",
      "Test:       123/2477 failed or zero\n",
      "\n",
      "Total failed or zero: 123/12418 (0.99%)\n",
      "\n",
      "üí° If any predictions failed, run the next cell to fix them.\n"
     ]
    }
   ],
   "source": [
    "# Check for failed predictions in all checkpoint files\n",
    "import json\n",
    "import os\n",
    "\n",
    "def check_failed_predictions(checkpoint_file, data_name):\n",
    "    \"\"\"Check for failed/None or zero predictions in checkpoint\"\"\"\n",
    "    if not os.path.exists(checkpoint_file):\n",
    "        print(f\"‚ùå {data_name} checkpoint not found: {checkpoint_file}\")\n",
    "        return None\n",
    "    \n",
    "    with open(checkpoint_file, 'r') as f:\n",
    "        checkpoint = json.load(f)\n",
    "    \n",
    "    predictions = checkpoint.get('predictions', [])\n",
    "    llm_results = checkpoint.get('llm_results', [])\n",
    "    \n",
    "    # Find indices with failed predictions (None or 0)\n",
    "    failed_indices = []\n",
    "    for idx, (pred, result) in enumerate(zip(predictions, llm_results)):\n",
    "        # A prediction is considered failed if it's None, 0, or the result object indicates failure.\n",
    "        is_pred_zero = False\n",
    "        try:\n",
    "            if pred is not None and float(pred) == 0.0:\n",
    "                is_pred_zero = True\n",
    "        except (ValueError, TypeError):\n",
    "            pass # Not a number, will be caught by `is None` check if problematic\n",
    "\n",
    "        if pred is None or is_pred_zero or (isinstance(result, dict) and result.get('predicted_close') is None):\n",
    "            failed_indices.append(idx)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üìä {data_name.upper()} CHECKPOINT ANALYSIS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Total predictions: {len(predictions)}\")\n",
    "    print(f\"Failed/Zero predictions: {len(failed_indices)}\")\n",
    "    \n",
    "    if len(predictions) > 0:\n",
    "        success_rate = ((len(predictions) - len(failed_indices)) / len(predictions) * 100)\n",
    "        print(f\"Success rate: {success_rate:.2f}%\")\n",
    "    \n",
    "    if failed_indices:\n",
    "        print(f\"\\n‚ö†Ô∏è Failed/Zero prediction indices (first 20): {failed_indices[:20]}\")\n",
    "        if len(failed_indices) > 20:\n",
    "            print(f\"   ... and {len(failed_indices) - 20} more\")\n",
    "    else:\n",
    "        print(f\"\\n‚úÖ All predictions are valid (not None and not zero)!\")\n",
    "    \n",
    "    return {\n",
    "        'checkpoint_file': checkpoint_file,\n",
    "        'total': len(predictions),\n",
    "        'failed': len(failed_indices),\n",
    "        'failed_indices': failed_indices,\n",
    "        'checkpoint': checkpoint\n",
    "    }\n",
    "\n",
    "# Check all three checkpoints\n",
    "print(\"üîç CHECKING ALL CHECKPOINT FILES FOR FAILED/ZERO PREDICTIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "train_check = check_failed_predictions(\n",
    "    '../results/llm_predictions_train_checkpoint.json', \n",
    "    'Training'\n",
    ")\n",
    "\n",
    "val_check = check_failed_predictions(\n",
    "    '../results/llm_predictions_val_checkpoint.json', \n",
    "    'Validation'\n",
    ")\n",
    "\n",
    "test_check = check_failed_predictions(\n",
    "    '../results/llm_predictions_checkpoint.json', \n",
    "    'Test'\n",
    ")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"üìà OVERALL SUMMARY\")\n",
    "print(f\"{'='*80}\")\n",
    "if train_check:\n",
    "    print(f\"Training:   {train_check['failed']}/{train_check['total']} failed or zero\")\n",
    "if val_check:\n",
    "    print(f\"Validation: {val_check['failed']}/{val_check['total']} failed or zero\")\n",
    "if test_check:\n",
    "    print(f\"Test:       {test_check['failed']}/{test_check['total']} failed or zero\")\n",
    "\n",
    "total_failed = 0\n",
    "total_samples = 0\n",
    "if train_check:\n",
    "    total_failed += train_check['failed']\n",
    "    total_samples += train_check['total']\n",
    "if val_check:\n",
    "    total_failed += val_check['failed']\n",
    "    total_samples += val_check['total']\n",
    "if test_check:\n",
    "    total_failed += test_check['failed']\n",
    "    total_samples += test_check['total']\n",
    "\n",
    "if total_samples > 0:\n",
    "    print(f\"\\nTotal failed or zero: {total_failed}/{total_samples} ({(total_failed/total_samples*100):.2f}%)\")\n",
    "print(f\"\\nüí° If any predictions failed, run the next cell to fix them.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6689abd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FIXING TEST DATA\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "üîÑ FIXING FAILED PREDICTIONS FOR TEST\n",
      "================================================================================\n",
      "Failed predictions to fix: 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fixing Test:   0%|          | 0/123 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"generated_text\":\" {\\\"predicted_close\\\": 0.0, \\\"likelihood\\\": 0.0, \\\"justification\\\": \\\"\\\"}\\n\\n\"}]\n",
      " {\"predicted_close\": 0.0, \"likelihood\": 0.0, \"justification\": \"\"}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fixing Test:   1%|          | 1/123 [00:02<06:02,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"generated_text\":\" {\\\"predicted_close\\\": 0.0, \\\"likelihood\\\": 0.0, \\\"justification\\\": \\\"\\\"}\\n\\n\"}]\n",
      " {\"predicted_close\": 0.0, \"likelihood\": 0.0, \"justification\": \"\"}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fixing Test:   2%|‚ñè         | 2/123 [00:05<05:55,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"generated_text\":\" {\\\"predicted_close\\\": 0.0, \\\"likelihood\\\": 0.0, \\\"justification\\\": \\\"\\\"}\\n\\n\"}]\n",
      " {\"predicted_close\": 0.0, \"likelihood\": 0.0, \"justification\": \"\"}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fixing Test:   2%|‚ñè         | 3/123 [00:08<05:54,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"generated_text\":\" {\\\"predicted_close\\\": 0.0, \\\"likelihood\\\": 0.0, \\\"justification\\\": \\\"\\\"}\\n\\n\"}]\n",
      " {\"predicted_close\": 0.0, \"likelihood\": 0.0, \"justification\": \"\"}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fixing Test:   3%|‚ñé         | 4/123 [00:13<06:29,  3.27s/it]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 100\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFIXING TEST DATA\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     99\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m80\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m test_checkpoint_fixed = \u001b[43mfix_failed_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_check\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[38;5;66;03m# Update global variables\u001b[39;00m\n\u001b[32m    102\u001b[39m llm_predictions = test_checkpoint_fixed[\u001b[33m'\u001b[39m\u001b[33mpredictions\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mfix_failed_predictions\u001b[39m\u001b[34m(checkpoint_info, original_data, data_name)\u001b[39m\n\u001b[32m     23\u001b[39m item = original_data[idx]\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Re-run LLM prediction\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m llm_result = \u001b[43mllm_predict_stock_price\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mprompt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Update results\u001b[39;00m\n\u001b[32m     29\u001b[39m llm_results[idx] = llm_result\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mllm_predict_stock_price\u001b[39m\u001b[34m(prompt, retries)\u001b[39m\n\u001b[32m      5\u001b[39m headers = {\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mAccept\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mAuthorization\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBearer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhf_token\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m }\n\u001b[32m     11\u001b[39m payload = {\n\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33minputs\u001b[39m\u001b[33m\"\u001b[39m: prompt,\n\u001b[32m     13\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mparameters\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m     }\n\u001b[32m     18\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mHF_ENDPOINT_URL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\n\u001b[32m     25\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(response.text)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code != \u001b[32m200\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/requests/api.py:115\u001b[39m, in \u001b[36mpost\u001b[39m\u001b[34m(url, data, json, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(url, data=\u001b[38;5;28;01mNone\u001b[39;00m, json=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    104\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    112\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/requests/adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    641\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/StockPPOLLMresearch/venv/lib/python3.13/site-packages/urllib3/connection.py:565\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    562\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    568\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1428\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1432\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Re-run inference ONLY for failed predictions\n",
    "def fix_failed_predictions(checkpoint_info, original_data, data_name):\n",
    "    \"\"\"Re-run inference for failed predictions only\"\"\"\n",
    "    if not checkpoint_info or not checkpoint_info['failed_indices']:\n",
    "        print(f\"‚úÖ {data_name}: No failed predictions to fix!\")\n",
    "        return checkpoint_info['checkpoint']\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üîÑ FIXING FAILED PREDICTIONS FOR {data_name.upper()}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Failed predictions to fix: {len(checkpoint_info['failed_indices'])}\")\n",
    "    \n",
    "    checkpoint = checkpoint_info['checkpoint']\n",
    "    predictions = checkpoint['predictions']\n",
    "    actual_prices = checkpoint['actual_prices']\n",
    "    llm_results = checkpoint['llm_results']\n",
    "    \n",
    "    fixed_count = 0\n",
    "    still_failed = []\n",
    "    \n",
    "    for idx in tqdm(checkpoint_info['failed_indices'], desc=f\"Fixing {data_name}\"):\n",
    "        try:\n",
    "            item = original_data[idx]\n",
    "            \n",
    "            # Re-run LLM prediction\n",
    "            llm_result = llm_predict_stock_price(item['prompt'])\n",
    "            \n",
    "            # Update results\n",
    "            llm_results[idx] = llm_result\n",
    "            \n",
    "            # Update prediction\n",
    "            if llm_result['predicted_close'] is not None and float(llm_result['predicted_close']) > 0:\n",
    "                predictions[idx] = llm_result['predicted_close']\n",
    "                fixed_count += 1\n",
    "            else:\n",
    "                # Still failed, use fallback\n",
    "                # response = json.loads(item['response'])\n",
    "                # predictions[idx] = response['predicted_close']\n",
    "                # still_failed.append(idx)\n",
    "                predictions[idx] = 0.0\n",
    "                still_failed.append(idx)\n",
    "            \n",
    "            # Small delay\n",
    "            time.sleep(0.3)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ö†Ô∏è Error fixing index {idx}: {e}\")\n",
    "            still_failed.append(idx)\n",
    "            try:\n",
    "                response = json.loads(original_data[idx]['response'])\n",
    "                predictions[idx] = response['predicted_close']\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # Save updated checkpoint\n",
    "    checkpoint['predictions'] = predictions\n",
    "    checkpoint['llm_results'] = llm_results\n",
    "    checkpoint['last_idx'] = len(predictions) - 1\n",
    "    checkpoint['completed'] = True\n",
    "    with open(checkpoint_info['checkpoint_file'], 'w') as f:\n",
    "        json.dump(checkpoint, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Fixed {fixed_count}/{len(checkpoint_info['failed_indices'])} predictions\")\n",
    "    if still_failed:\n",
    "        print(f\"‚ö†Ô∏è Still failed: {len(still_failed)} predictions (using fallback values)\")\n",
    "        print(f\"   Indices: {still_failed[:10]}\")\n",
    "    print(f\"üíæ Updated checkpoint saved to: {checkpoint_info['checkpoint_file']}\")\n",
    "    \n",
    "    return checkpoint\n",
    "\n",
    "# Fix training data\n",
    "if train_check and train_check['failed'] > 0:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FIXING TRAINING DATA\")\n",
    "    print(\"=\"*80)\n",
    "    train_checkpoint_fixed = fix_failed_predictions(train_check, train_data, \"Training\")\n",
    "    # Update global variables\n",
    "    train_llm_predictions = train_checkpoint_fixed['predictions']\n",
    "    train_actual_prices = train_checkpoint_fixed['actual_prices']\n",
    "    train_llm_results = train_checkpoint_fixed['llm_results']\n",
    "    print(f\"‚úÖ Training data updated: {len(train_llm_predictions)} predictions\")\n",
    "\n",
    "# Fix validation data\n",
    "if val_check and val_check['failed'] > 0:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FIXING VALIDATION DATA\")\n",
    "    print(\"=\"*80)\n",
    "    val_checkpoint_fixed = fix_failed_predictions(val_check, val_data, \"Validation\")\n",
    "    # Update global variables\n",
    "    val_llm_predictions = val_checkpoint_fixed['predictions']\n",
    "    val_actual_prices = val_checkpoint_fixed['actual_prices']\n",
    "    val_llm_results = val_checkpoint_fixed['llm_results']\n",
    "    print(f\"‚úÖ Validation data updated: {len(val_llm_predictions)} predictions\")\n",
    "\n",
    "# Fix test data\n",
    "if test_check and test_check['failed'] > 0:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FIXING TEST DATA\")\n",
    "    print(\"=\"*80)\n",
    "    test_checkpoint_fixed = fix_failed_predictions(test_check, test_data, \"Test\")\n",
    "    # Update global variables\n",
    "    llm_predictions = test_checkpoint_fixed['predictions']\n",
    "    actual_prices = test_checkpoint_fixed['actual_prices']\n",
    "    llm_results = test_checkpoint_fixed['llm_results']\n",
    "    print(f\"‚úÖ Test data updated: {len(llm_predictions)} predictions\")\n",
    "    \n",
    "    test_df['actual_price'] = actual_prices\n",
    "    test_df['llm_prediction'] = llm_predictions\n",
    "    test_df['actual_price'] = actual_prices\n",
    "    # Update test_df\n",
    "    # Update justification features\n",
    "    justifications = []\n",
    "    likelihoods = []\n",
    "    feature_rows = []\n",
    "    for res in llm_results:\n",
    "        res = res if isinstance(res, dict) else {}\n",
    "        justification = res.get('justification', '')\n",
    "        justifications.append(justification)\n",
    "        likelihoods.append(safe_float(res.get('likelihood'), 0.5))\n",
    "        feature_rows.append(extract_justification_features(justification))\n",
    "    test_df['llm_likelihood'] = likelihoods\n",
    "    test_df['llm_justification'] = justifications\n",
    "    test_df['llm_likelihood'] = likelihoods\n",
    "    \n",
    "    feature_keys = list(feature_rows[0].keys()) if feature_rows else []\n",
    "    for key in feature_keys:\n",
    "        test_df[key] = [row[key] for row in feature_rows]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ ALL FAILED PREDICTIONS HAVE BEEN PROCESSED!\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"You can now proceed with PPO training.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
