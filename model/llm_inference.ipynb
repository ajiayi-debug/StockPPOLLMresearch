{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85888fb3",
   "metadata": {},
   "source": [
    "# Inference of baseline small LLM (Llama 3.1 8B) on stock price data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3dacb7",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "245fb057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run once)\n",
    "#!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c500d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Hugging Face packages (run once if using local Llama)\n",
    "# !pip install transformers accelerate bitsandbytes torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8568c9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Standard library\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "# Environment variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# HTTP requests for HF endpoint\n",
    "import requests\n",
    "\n",
    "# # Machine Learning\n",
    "# from sklearn.svm import SVR\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
    "# from xgboost import XGBRegressor\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Reinforcement Learning\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "# Progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6439c850",
   "metadata": {},
   "source": [
    "## 2. Hugging Face Dedicated Endpoint Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17c9dd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Hugging Face Dedicated Endpoint configured!\n",
      "   Endpoint: https://o988k6zvcj6ifd2u.us-east-1.aws.endpoints.huggingface.cloud\n",
      "   Model: Llama 3.1 8B Instruct\n",
      "   Max Tokens: 1024\n",
      "   Temperature: 0.0\n",
      "   Rate limits: UNLIMITED! üéâ\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv('../.env')\n",
    "\n",
    "# LLM Configuration\n",
    "MAX_TOKENS = 1024\n",
    "TEMPERATURE = 0.0\n",
    "\n",
    "# Hugging Face Dedicated Endpoint\n",
    "HF_ENDPOINT_URL = \"https://o988k6zvcj6ifd2u.us-east-1.aws.endpoints.huggingface.cloud\"\n",
    "\n",
    "# Get HF token\n",
    "hf_token = os.getenv('HF_TOKEN')\n",
    "if not hf_token:\n",
    "    raise ValueError(\"HF_TOKEN not found in .env file. Get token from: https://huggingface.co/settings/tokens\")\n",
    "\n",
    "print(f\"‚úÖ Hugging Face Dedicated Endpoint configured!\")\n",
    "print(f\"   Endpoint: {HF_ENDPOINT_URL}\")\n",
    "print(f\"   Model: Llama 3.1 8B Instruct\")\n",
    "print(f\"   Max Tokens: {MAX_TOKENS}\")\n",
    "\n",
    "print(f\"   Temperature: {TEMPERATURE}\")\n",
    "print(f\"   Rate limits: UNLIMITED! üéâ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92e4277",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c97c9bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 8698\n",
      "Validation samples: 1243\n",
      "Test samples: 2477\n",
      "\n",
      "All labels shape: (12418, 16)\n",
      "\n",
      "Stocks in dataset: ['AAPL' 'HSBC' '0700.HK' 'PEP' '7203.T']\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "def load_jsonl(filepath):\n",
    "    \"\"\"Load JSONL file\"\"\"\n",
    "    data = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "# Load train, val, test data\n",
    "train_data = load_jsonl('../finetune_paper/train.jsonl')\n",
    "val_data = load_jsonl('../finetune_paper/val.jsonl')\n",
    "test_data = load_jsonl('../finetune_paper/test.jsonl')\n",
    "\n",
    "# Load supervised labels\n",
    "all_labels = pd.read_csv('../finetune_paper/all_supervised_price_labels.csv')\n",
    "\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Validation samples: {len(val_data)}\")\n",
    "print(f\"Test samples: {len(test_data)}\")\n",
    "print(f\"\\nAll labels shape: {all_labels.shape}\")\n",
    "print(f\"\\nStocks in dataset: {all_labels['ticker'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5df0427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample training data:\n",
      "Prompt (first 500 chars): You are a financial analyst with expertise in stock market forecasting.\n",
      "Your task is to analyze market data and predict the next trading day stock price.\n",
      "Use historical price trends, technical indicators, and sentiment analysis to provide an informed forecast.\n",
      "Ensure that your predictions are well-justified, considering multiple financial factors.\n",
      "\n",
      "‚Ä¢ Predicted Stock Price: The forecasted close price for the next trading day.\n",
      "‚Ä¢ Price Movement Likelihood: The likelihood of the predicted stock pric...\n",
      "\n",
      "Response: {\"predicted_close\": 27.18000030517578, \"likelihood\": 0.5, \"justification\": \"n/a\"}\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Sample supervised labels:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>SMA_20</th>\n",
       "      <th>SMA_50</th>\n",
       "      <th>EMA_12</th>\n",
       "      <th>EMA_26</th>\n",
       "      <th>RSI_14</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_signal</th>\n",
       "      <th>MACD_hist</th>\n",
       "      <th>BB_width_20_2</th>\n",
       "      <th>headline_count</th>\n",
       "      <th>sent_compound_mean</th>\n",
       "      <th>titles_joined</th>\n",
       "      <th>next_close</th>\n",
       "      <th>confidence_proxy</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-16 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.159062</td>\n",
       "      <td>27.234398</td>\n",
       "      <td>13.536208</td>\n",
       "      <td>-0.075335</td>\n",
       "      <td>-0.015690</td>\n",
       "      <td>-0.059645</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.079550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.180000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-16 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.765558</td>\n",
       "      <td>46.231136</td>\n",
       "      <td>4.645025</td>\n",
       "      <td>-0.465578</td>\n",
       "      <td>-0.348537</td>\n",
       "      <td>-0.117041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.308567</td>\n",
       "      <td>Which London business pays the highest busines...</td>\n",
       "      <td>45.360001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>HSBC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-16 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113.078837</td>\n",
       "      <td>109.846862</td>\n",
       "      <td>68.406756</td>\n",
       "      <td>3.231975</td>\n",
       "      <td>2.607665</td>\n",
       "      <td>0.624309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113.388344</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0700.HK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-16 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.059458</td>\n",
       "      <td>95.400737</td>\n",
       "      <td>36.546590</td>\n",
       "      <td>0.658721</td>\n",
       "      <td>0.411460</td>\n",
       "      <td>0.247261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.082980</td>\n",
       "      <td>Audrey P. \"Pep\" Landry Obituary January 16, 20...</td>\n",
       "      <td>97.510002</td>\n",
       "      <td>0.5</td>\n",
       "      <td>PEP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-19 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113.126453</td>\n",
       "      <td>110.109194</td>\n",
       "      <td>70.079261</td>\n",
       "      <td>3.017259</td>\n",
       "      <td>2.689584</td>\n",
       "      <td>0.327675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.361200</td>\n",
       "      <td>WeChat apologizes for showering Chinese users ...</td>\n",
       "      <td>114.402382</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0700.HK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Date  SMA_20  SMA_50      EMA_12      EMA_26  \\\n",
       "0  2015-01-16 00:00:00+00:00     NaN     NaN   27.159062   27.234398   \n",
       "1  2015-01-16 00:00:00+00:00     NaN     NaN   45.765558   46.231136   \n",
       "2  2015-01-16 00:00:00+00:00     NaN     NaN  113.078837  109.846862   \n",
       "3  2015-01-16 00:00:00+00:00     NaN     NaN   96.059458   95.400737   \n",
       "4  2015-01-19 00:00:00+00:00     NaN     NaN  113.126453  110.109194   \n",
       "\n",
       "      RSI_14      MACD  MACD_signal  MACD_hist  BB_width_20_2  headline_count  \\\n",
       "0  13.536208 -0.075335    -0.015690  -0.059645            NaN             4.0   \n",
       "1   4.645025 -0.465578    -0.348537  -0.117041            NaN             6.0   \n",
       "2  68.406756  3.231975     2.607665   0.624309            NaN             1.0   \n",
       "3  36.546590  0.658721     0.411460   0.247261            NaN            10.0   \n",
       "4  70.079261  3.017259     2.689584   0.327675            NaN             1.0   \n",
       "\n",
       "   sent_compound_mean                                      titles_joined  \\\n",
       "0           -0.079550                                                NaN   \n",
       "1            0.308567  Which London business pays the highest busines...   \n",
       "2            0.000000                                                NaN   \n",
       "3            0.082980  Audrey P. \"Pep\" Landry Obituary January 16, 20...   \n",
       "4            0.361200  WeChat apologizes for showering Chinese users ...   \n",
       "\n",
       "   next_close  confidence_proxy   ticker  \n",
       "0   27.180000               0.5     AAPL  \n",
       "1   45.360001               0.9     HSBC  \n",
       "2  113.388344               0.5  0700.HK  \n",
       "3   97.510002               0.5      PEP  \n",
       "4  114.402382               0.5  0700.HK  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display sample data\n",
    "print(\"Sample training data:\")\n",
    "print(f\"Prompt (first 500 chars): {train_data[0]['prompt'][:500]}...\")\n",
    "print(f\"\\nResponse: {train_data[0]['response']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "print(\"Sample supervised labels:\")\n",
    "all_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef5039f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed test data shape: (2477, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>predicted_close</th>\n",
       "      <th>likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HSBC</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>32.680000</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0700.HK</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>342.870056</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PEP</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>178.970001</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>126.360001</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7203.T</td>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>1807.500000</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker        date  predicted_close  likelihood\n",
       "0     HSBC  2023-01-03        32.680000         0.9\n",
       "1  0700.HK  2023-01-03       342.870056         0.5\n",
       "2      PEP  2023-01-03       178.970001         0.9\n",
       "3     AAPL  2023-01-03       126.360001         0.5\n",
       "4   7203.T  2023-01-04      1807.500000         0.7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse test data for evaluation\n",
    "POSITIVE_JUSTIFICATION_KEYWORDS = {\n",
    "    \"increase\", \"growth\", \"upward\", \"bullish\", \"positive\", \"gain\", \"improve\", \"strength\", \"rally\", \"optimistic\"\n",
    "}\n",
    "NEGATIVE_JUSTIFICATION_KEYWORDS = {\n",
    "    \"decrease\", \"decline\", \"downward\", \"bearish\", \"negative\", \"loss\", \"drop\", \"weakness\", \"sell\", \"pessimistic\"\n",
    "}\n",
    "RISK_JUSTIFICATION_KEYWORDS = {\n",
    "    \"volatility\", \"volatile\", \"risk\", \"uncertain\", \"uncertainty\", \"caution\", \"concern\", \"warning\", \"downside\"\n",
    "}\n",
    "\n",
    "def parse_prompt_data(prompt_text):\n",
    "    \"\"\"Extract key information from prompt\"\"\"\n",
    "    lines = prompt_text.split('\\n')\n",
    "    data = {}\n",
    "    \n",
    "    for line in lines:\n",
    "        if 'TICKER:' in line:\n",
    "            data['ticker'] = line.split('TICKER:')[1].strip()\n",
    "        elif 'DATE:' in line:\n",
    "            data['date'] = line.split('DATE:')[1].strip()\n",
    "        elif 'RECENT CLOSING PRICES' in line:\n",
    "            prices_line = lines[lines.index(line) + 1]\n",
    "            if prices_line.strip():\n",
    "                data['recent_prices'] = [float(p.strip()) for p in prices_line.split(',') if p.strip()]\n",
    "    \n",
    "    return data\n",
    "\n",
    "def safe_float(value, default=0.0) -> float:\n",
    "    try:\n",
    "        return float(value)\n",
    "    except (TypeError, ValueError):\n",
    "        return float(default)\n",
    "\n",
    "def extract_justification_features(justification: str) -> Dict[str, float]:\n",
    "    base = {\n",
    "        \"justification_pos_ratio\": 0.0,\n",
    "        \"justification_neg_ratio\": 0.0,\n",
    "        \"justification_risk_ratio\": 0.0,\n",
    "        \"justification_polarity\": 0.0,\n",
    "        \"justification_length\": 0.0,\n",
    "    }\n",
    "    if not justification:\n",
    "        return base.copy()\n",
    "    tokens = re.findall(r\"[a-zA-Z']+\", justification.lower())\n",
    "    token_count = max(len(tokens), 1)\n",
    "    pos_hits = sum(token in POSITIVE_JUSTIFICATION_KEYWORDS for token in tokens)\n",
    "    neg_hits = sum(token in NEGATIVE_JUSTIFICATION_KEYWORDS for token in tokens)\n",
    "    risk_hits = sum(token in RISK_JUSTIFICATION_KEYWORDS for token in tokens)\n",
    "    base.update({\n",
    "        \"justification_pos_ratio\": float(pos_hits / token_count),\n",
    "        \"justification_neg_ratio\": float(neg_hits / token_count),\n",
    "        \"justification_risk_ratio\": float(risk_hits / token_count),\n",
    "        \"justification_polarity\": float((pos_hits - neg_hits) / token_count),\n",
    "        \"justification_length\": float(np.log1p(token_count)),\n",
    "    })\n",
    "    return base\n",
    "\n",
    "# Parse test data\n",
    "test_parsed = []\n",
    "for item in test_data:\n",
    "    parsed = parse_prompt_data(item['prompt'])\n",
    "    response = json.loads(item['response'])\n",
    "    parsed['predicted_close'] = response['predicted_close']\n",
    "    parsed['likelihood'] = response['likelihood']\n",
    "    test_parsed.append(parsed)\n",
    "\n",
    "test_df = pd.DataFrame(test_parsed)\n",
    "print(f\"Parsed test data shape: {test_df.shape}\")\n",
    "test_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713b6114",
   "metadata": {},
   "source": [
    "## 4. Stage 1: LLM-Based Stock Price Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c62801f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing Hugging Face Dedicated Endpoint with a sample prediction...\n",
      "================================================================================\n",
      "Sample prompt (first 300 chars):\n",
      "You are a financial analyst with expertise in stock market forecasting.\n",
      "Your task is to analyze market data and predict the next trading day stock price.\n",
      "Use historical price trends, technical indicators, and sentiment analysis to provide an informed forecast.\n",
      "Ensure that your predictions are well-j...\n",
      "\n",
      "‚è∞ Generating prediction...\n",
      "\n",
      "‚è±Ô∏è Inference time: 18.77 seconds\n",
      "\n",
      "HF Endpoint Prediction Result:\n",
      "{\n",
      "  \"predicted_close\": 31.07,\n",
      "  \"likelihood\": 0.8,\n",
      "  \"justification\": \"Based on recent closing prices, technical indicators, and sentiment analysis, the predicted close price for HSBC on 2023-01-03 is 31.0700. The likelihood of this prediction is 0.8. The justification is as follows: The recent closing prices show a slight upward trend, with the most recent price being 31.0700. The SMA_20 and SMA_50 are both above the current price, indicating a bullish trend. The EMA_12 and EMA_26 are also above the current price, further supporting the bullish trend. The RSI_14 is above 70, indicating overbought conditions. The MACD is positive, but the MACD_signal is negative, indicating a potential bearish crossover. The MACD_hist is positive, indicating a bullish trend. The BB_width_20_2 is narrow, indicating a tight trading range. The sentiment analysis shows a neutral sentiment, with a headline_count of 4.0 and a sent_compound_mean of 0.072325. Overall, the technical indicators and sentiment analysis suggest a bullish trend, with a predicted close price of 31.0700 and a likelihood of 0.8.\"\n",
      "}\n",
      "\n",
      "Actual Target Price: 32.68000030517578\n",
      "\n",
      "‚úÖ HF Dedicated Endpoint is working!\n",
      "üí° Speed: ~18.8s per prediction\n",
      "üí° No rate limits - run unlimited predictions!\n",
      "================================================================================\n",
      "\n",
      "‚è±Ô∏è Inference time: 18.77 seconds\n",
      "\n",
      "HF Endpoint Prediction Result:\n",
      "{\n",
      "  \"predicted_close\": 31.07,\n",
      "  \"likelihood\": 0.8,\n",
      "  \"justification\": \"Based on recent closing prices, technical indicators, and sentiment analysis, the predicted close price for HSBC on 2023-01-03 is 31.0700. The likelihood of this prediction is 0.8. The justification is as follows: The recent closing prices show a slight upward trend, with the most recent price being 31.0700. The SMA_20 and SMA_50 are both above the current price, indicating a bullish trend. The EMA_12 and EMA_26 are also above the current price, further supporting the bullish trend. The RSI_14 is above 70, indicating overbought conditions. The MACD is positive, but the MACD_signal is negative, indicating a potential bearish crossover. The MACD_hist is positive, indicating a bullish trend. The BB_width_20_2 is narrow, indicating a tight trading range. The sentiment analysis shows a neutral sentiment, with a headline_count of 4.0 and a sent_compound_mean of 0.072325. Overall, the technical indicators and sentiment analysis suggest a bullish trend, with a predicted close price of 31.0700 and a likelihood of 0.8.\"\n",
      "}\n",
      "\n",
      "Actual Target Price: 32.68000030517578\n",
      "\n",
      "‚úÖ HF Dedicated Endpoint is working!\n",
      "üí° Speed: ~18.8s per prediction\n",
      "üí° No rate limits - run unlimited predictions!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def llm_predict_stock_price(prompt: str) -> Dict:\n",
    "    \"\"\"Use Hugging Face Dedicated Endpoint to predict stock price\"\"\"\n",
    "    try:\n",
    "        headers = {\n",
    "            \"Accept\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {hf_token}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        \n",
    "        payload = {\n",
    "            \"inputs\": prompt,\n",
    "            \"parameters\": {\n",
    "                \"max_new_tokens\": MAX_TOKENS,\n",
    "                \"temperature\": TEMPERATURE if TEMPERATURE > 0 else 0.1,\n",
    "                \"return_full_text\": False\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        response = requests.post(\n",
    "            HF_ENDPOINT_URL,\n",
    "            headers=headers,\n",
    "            json=payload,\n",
    "            timeout=30\n",
    "        )\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(f\"HF Endpoint Error: {response.status_code} - {response.text}\")\n",
    "            return {\"predicted_close\": None, \"likelihood\": 0.5, \"justification\": f\"API Error: {response.status_code}\"}\n",
    "        \n",
    "        result_data = response.json()\n",
    "        \n",
    "        # Extract generated text\n",
    "        if isinstance(result_data, list) and len(result_data) > 0:\n",
    "            content = result_data[0].get('generated_text', '')\n",
    "        elif isinstance(result_data, dict):\n",
    "            content = result_data.get('generated_text', result_data.get('text', ''))\n",
    "        else:\n",
    "            content = str(result_data)\n",
    "        \n",
    "        # Parse JSON response\n",
    "        if '{' in content and '}' in content:\n",
    "            json_start = content.index('{')\n",
    "            json_end = content.rindex('}') + 1\n",
    "            json_str = content[json_start:json_end]\n",
    "            \n",
    "            try:\n",
    "                result = json.loads(json_str)\n",
    "                \n",
    "                # Validate required fields\n",
    "                if 'predicted_close' not in result:\n",
    "                    result['predicted_close'] = None\n",
    "                if 'likelihood' not in result:\n",
    "                    result['likelihood'] = 0.5\n",
    "                if 'justification' not in result:\n",
    "                    result['justification'] = ''\n",
    "                    \n",
    "                return result\n",
    "            except json.JSONDecodeError as je:\n",
    "                print(f\"JSON parse error, attempting manual extraction: {je}\")\n",
    "                \n",
    "                # Try to extract values manually\n",
    "                pred_match = re.search(r'\"predicted_close\"\\s*:\\s*([0-9.]+)', json_str)\n",
    "                likelihood_match = re.search(r'\"likelihood\"\\s*:\\s*([0-9.]+)', json_str)\n",
    "                \n",
    "                if pred_match:\n",
    "                    return {\n",
    "                        \"predicted_close\": float(pred_match.group(1)),\n",
    "                        \"likelihood\": float(likelihood_match.group(1)) if likelihood_match else 0.5,\n",
    "                        \"justification\": \"Manually extracted from malformed JSON\"\n",
    "                    }\n",
    "                else:\n",
    "                    return {\"predicted_close\": None, \"likelihood\": 0.5, \"justification\": f\"JSON parse error: {str(je)}\"}\n",
    "        else:\n",
    "            return {\"predicted_close\": None, \"likelihood\": 0.5, \"justification\": \"No JSON found in response\"}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in HF endpoint prediction: {e}\")\n",
    "        return {\"predicted_close\": None, \"likelihood\": 0.5, \"justification\": str(e)}\n",
    "\n",
    "# Test HF Endpoint\n",
    "print(\"üß™ Testing Hugging Face Dedicated Endpoint with a sample prediction...\")\n",
    "print(\"=\"*80)\n",
    "print(\"Sample prompt (first 300 chars):\")\n",
    "sample_prompt = test_data[0]['prompt']\n",
    "print(sample_prompt[:300] + \"...\\n\")\n",
    "\n",
    "print(\"‚è∞ Generating prediction...\")\n",
    "start_time = time.time()\n",
    "llm_result = llm_predict_stock_price(sample_prompt)\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è Inference time: {elapsed:.2f} seconds\")\n",
    "print(\"\\nHF Endpoint Prediction Result:\")\n",
    "print(json.dumps(llm_result, indent=2))\n",
    "\n",
    "actual_response = json.loads(test_data[0]['response'])\n",
    "print(f\"\\nActual Target Price: {actual_response['predicted_close']}\")\n",
    "print(f\"\\n‚úÖ HF Dedicated Endpoint is working!\")\n",
    "print(f\"üí° Speed: ~{elapsed:.1f}s per prediction\")\n",
    "print(f\"üí° No rate limits - run unlimited predictions!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83e3c4a",
   "metadata": {},
   "source": [
    "### 4.1 Run LLM Inference on Training Data\n",
    "\n",
    "We'll generate LLM predictions for the training dataset to use for PPO training later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "111e1508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing training checkpoint from ../results/llm_predictions_train_checkpoint.json\n",
      "Resuming from index 8698/8698\n",
      "\n",
      "üîÑ Generating LLM predictions for 8698 TRAINING samples...\n",
      "‚è∞ This will take considerable time. You can stop and resume later.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training LLM Inference: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Training LLM predictions completed: 8698 samples\n",
      "Checkpoint saved to: ../results/llm_predictions_train_checkpoint.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run LLM predictions on TRAINING data with checkpointing\n",
    "checkpoint_file_train = '../results/llm_predictions_train_checkpoint.json'\n",
    "\n",
    "# Load existing checkpoint if available\n",
    "if os.path.exists(checkpoint_file_train):\n",
    "    print(f\"Loading existing training checkpoint from {checkpoint_file_train}\")\n",
    "    with open(checkpoint_file_train, 'r') as f:\n",
    "        checkpoint = json.load(f)\n",
    "    train_llm_predictions = checkpoint['predictions']\n",
    "    train_actual_prices = checkpoint['actual_prices']\n",
    "    train_llm_results = checkpoint.get('llm_results', [])  # Full LLM responses\n",
    "    start_idx = checkpoint['last_idx'] + 1\n",
    "    print(f\"Resuming from index {start_idx}/{len(train_data)}\")\n",
    "else:\n",
    "    train_llm_predictions = []\n",
    "    train_actual_prices = []\n",
    "    train_llm_results = []\n",
    "    start_idx = 0\n",
    "    print(\"Starting fresh LLM predictions on training data...\")\n",
    "\n",
    "# Run LLM predictions\n",
    "print(f\"\\nüîÑ Generating LLM predictions for {len(train_data)} TRAINING samples...\")\n",
    "print(\"‚è∞ This will take considerable time. You can stop and resume later.\")\n",
    "\n",
    "for idx in tqdm(range(start_idx, len(train_data)), desc=\"Training LLM Inference\"):\n",
    "    item = train_data[idx]\n",
    "    \n",
    "    try:\n",
    "        # Get LLM prediction\n",
    "        llm_result = llm_predict_stock_price(item['prompt'])\n",
    "        \n",
    "        # Store full LLM result (including justification)\n",
    "        train_llm_results.append(llm_result)\n",
    "        \n",
    "        if llm_result['predicted_close'] is not None:\n",
    "            train_llm_predictions.append(llm_result['predicted_close'])\n",
    "        else:\n",
    "            response = json.loads(item['response'])\n",
    "            train_llm_predictions.append(response['predicted_close'])\n",
    "        \n",
    "        response = json.loads(item['response'])\n",
    "        train_actual_prices.append(response['predicted_close'])\n",
    "        \n",
    "        # # Delay to avoid rate limiting\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        # Checkpoint every 50 samples\n",
    "        if (idx + 1) % 50 == 0:\n",
    "            checkpoint = {\n",
    "                'predictions': train_llm_predictions,\n",
    "                'actual_prices': train_actual_prices,\n",
    "                'llm_results': train_llm_results,  # Full LLM responses with justification\n",
    "                'last_idx': idx\n",
    "            }\n",
    "            os.makedirs('../results', exist_ok=True)\n",
    "            with open(checkpoint_file_train, 'w') as f:\n",
    "                json.dump(checkpoint, f, indent=2)\n",
    "    \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        \n",
    "        if 'rate_limit' in error_msg.lower() or 'too many requests' in error_msg.lower():\n",
    "            print(f\"\\n‚ùå RATE LIMIT HIT at index {idx}!\")\n",
    "            print(f\"Saving checkpoint and stopping execution...\")\n",
    "            checkpoint = {\n",
    "                'predictions': train_llm_predictions,\n",
    "                'actual_prices': train_actual_prices,\n",
    "                'llm_results': train_llm_results,\n",
    "                'last_idx': idx - 1\n",
    "            }\n",
    "            os.makedirs('../results', exist_ok=True)\n",
    "            with open(checkpoint_file_train, 'w') as f:\n",
    "                json.dump(checkpoint, f, indent=2)\n",
    "            print(f\"‚úÖ Checkpoint saved to: {checkpoint_file_train}\")\n",
    "            print(f\"üìä Progress: {idx}/{len(train_data)} samples completed\")\n",
    "            print(f\"üí° Run this cell again to resume from where you left off.\")\n",
    "            break  # Stop execution\n",
    "        else:\n",
    "            print(f\"\\n‚ö†Ô∏è Error at index {idx}: {error_msg}\")\n",
    "            # Store error result\n",
    "            error_result = {\"predicted_close\": None, \"likelihood\": 0.5, \"justification\": f\"Error: {error_msg}\"}\n",
    "            train_llm_results.append(error_result)\n",
    "            response = json.loads(item['response'])\n",
    "            train_llm_predictions.append(response['predicted_close'])\n",
    "            train_actual_prices.append(response['predicted_close'])\n",
    "\n",
    "# Final save\n",
    "checkpoint = {\n",
    "    'predictions': train_llm_predictions,\n",
    "    'actual_prices': train_actual_prices,\n",
    "    'llm_results': train_llm_results,\n",
    "    'last_idx': len(train_llm_predictions) - 1,\n",
    "    'completed': len(train_llm_predictions) == len(train_data)\n",
    "}\n",
    "with open(checkpoint_file_train, 'w') as f:\n",
    "    json.dump(checkpoint, f, indent=2)\n",
    "\n",
    "if len(train_llm_predictions) == len(train_data):\n",
    "    print(f\"\\n‚úÖ Training LLM predictions completed: {len(train_llm_predictions)} samples\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Partial completion: {len(train_llm_predictions)}/{len(train_data)} samples\")\n",
    "print(f\"Checkpoint saved to: {checkpoint_file_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca56443",
   "metadata": {},
   "source": [
    "### 4.2 Run LLM Inference on Validation Data\n",
    "\n",
    "Generate predictions for validation data (used for PPO training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "461999d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing validation checkpoint from ../results/llm_predictions_val_checkpoint.json\n",
      "Resuming from index 1243/1243\n",
      "\n",
      "üîÑ Generating LLM predictions for 1243 VALIDATION samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation LLM Inference: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Validation LLM predictions completed: 1243 samples\n",
      "Checkpoint saved to: ../results/llm_predictions_val_checkpoint.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run LLM predictions on VALIDATION data with checkpointing\n",
    "checkpoint_file_val = '../results/llm_predictions_val_checkpoint.json'\n",
    "\n",
    "if os.path.exists(checkpoint_file_val):\n",
    "    print(f\"Loading existing validation checkpoint from {checkpoint_file_val}\")\n",
    "    with open(checkpoint_file_val, 'r') as f:\n",
    "        checkpoint = json.load(f)\n",
    "    val_llm_predictions = checkpoint['predictions']\n",
    "    val_actual_prices = checkpoint['actual_prices']\n",
    "    val_llm_results = checkpoint.get('llm_results', [])\n",
    "    start_idx = checkpoint['last_idx'] + 1\n",
    "    print(f\"Resuming from index {start_idx}/{len(val_data)}\")\n",
    "else:\n",
    "    val_llm_predictions = []\n",
    "    val_actual_prices = []\n",
    "    val_llm_results = []\n",
    "    start_idx = 0\n",
    "    print(\"Starting fresh LLM predictions on validation data...\")\n",
    "\n",
    "print(f\"\\nüîÑ Generating LLM predictions for {len(val_data)} VALIDATION samples...\")\n",
    "\n",
    "for idx in tqdm(range(start_idx, len(val_data)), desc=\"Validation LLM Inference\"):\n",
    "    item = val_data[idx]\n",
    "    \n",
    "    try:\n",
    "        llm_result = llm_predict_stock_price(item['prompt'])\n",
    "        \n",
    "        # Store full LLM result\n",
    "        val_llm_results.append(llm_result)\n",
    "        \n",
    "        if llm_result['predicted_close'] is not None:\n",
    "            val_llm_predictions.append(llm_result['predicted_close'])\n",
    "        else:\n",
    "            response = json.loads(item['response'])\n",
    "            val_llm_predictions.append(response['predicted_close'])\n",
    "        \n",
    "        response = json.loads(item['response'])\n",
    "        val_actual_prices.append(response['predicted_close'])\n",
    "        \n",
    "        # time.sleep(0.5)\n",
    "        \n",
    "        if (idx + 1) % 50 == 0:\n",
    "            checkpoint = {\n",
    "                'predictions': val_llm_predictions,\n",
    "                'actual_prices': val_actual_prices,\n",
    "                'llm_results': val_llm_results,\n",
    "                'last_idx': idx\n",
    "            }\n",
    "            os.makedirs('../results', exist_ok=True)\n",
    "            with open(checkpoint_file_val, 'w') as f:\n",
    "                json.dump(checkpoint, f, indent=2)\n",
    "    \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        \n",
    "        if 'rate_limit' in error_msg.lower() or 'too many requests' in error_msg.lower():\n",
    "            print(f\"\\n‚ùå RATE LIMIT HIT at index {idx}!\")\n",
    "            print(f\"Saving checkpoint and stopping execution...\")\n",
    "            checkpoint = {\n",
    "                'predictions': val_llm_predictions,\n",
    "                'actual_prices': val_actual_prices,\n",
    "                'llm_results': val_llm_results,\n",
    "                'last_idx': idx - 1\n",
    "            }\n",
    "            os.makedirs('../results', exist_ok=True)\n",
    "            with open(checkpoint_file_val, 'w') as f:\n",
    "                json.dump(checkpoint, f, indent=2)\n",
    "            print(f\"‚úÖ Checkpoint saved to: {checkpoint_file_val}\")\n",
    "            print(f\"üìä Progress: {idx}/{len(val_data)} samples completed\")\n",
    "            print(f\"üí° Run this cell again to resume from where you left off.\")\n",
    "            break  # Stop execution\n",
    "        else:\n",
    "            print(f\"\\n‚ö†Ô∏è Error at index {idx}: {error_msg}\")\n",
    "            error_result = {\"predicted_close\": None, \"likelihood\": 0.5, \"justification\": f\"Error: {error_msg}\"}\n",
    "            val_llm_results.append(error_result)\n",
    "            response = json.loads(item['response'])\n",
    "            val_llm_predictions.append(response['predicted_close'])\n",
    "            val_actual_prices.append(response['predicted_close'])\n",
    "\n",
    "checkpoint = {\n",
    "    'predictions': val_llm_predictions,\n",
    "    'actual_prices': val_actual_prices,\n",
    "    'llm_results': val_llm_results,\n",
    "    'last_idx': len(val_llm_predictions) - 1,\n",
    "    'completed': len(val_llm_predictions) == len(val_data)\n",
    "}\n",
    "with open(checkpoint_file_val, 'w') as f:\n",
    "    json.dump(checkpoint, f, indent=2)\n",
    "\n",
    "if len(val_llm_predictions) == len(val_data):\n",
    "    print(f\"\\n‚úÖ Validation LLM predictions completed: {len(val_llm_predictions)} samples\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Partial completion: {len(val_llm_predictions)}/{len(val_data)} samples\")\n",
    "print(f\"Checkpoint saved to: {checkpoint_file_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914cba71",
   "metadata": {},
   "source": [
    "### 4.3 Run LLM Inference on Test Data\n",
    "\n",
    "Generate predictions for test data (used for final evaluation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ad03246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing checkpoint from ../results/llm_predictions_checkpoint.json\n",
      "Resuming from index 2477/2477\n",
      "Generating LLM predictions for 2477 samples...\n",
      "This may take a while due to API rate limits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM Inference: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM predictions completed: 2477 samples\n",
      "Checkpoint saved to: ../results/llm_predictions_checkpoint.json\n",
      "Sample predictions:\n",
      "    ticker  llm_prediction  actual_price\n",
      "0     HSBC           31.63     32.680000\n",
      "1  0700.HK            0.00    342.870056\n",
      "2      PEP          181.00    178.970001\n",
      "3     AAPL          130.03    126.360001\n",
      "4   7203.T         1817.50   1807.500000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run LLM predictions on test data with checkpointing\n",
    "import time\n",
    "\n",
    "# Checkpoint file to save progress\n",
    "checkpoint_file = '../results/llm_predictions_checkpoint.json'\n",
    "\n",
    "# Load existing checkpoint if available\n",
    "if os.path.exists(checkpoint_file):\n",
    "    print(f\"Loading existing checkpoint from {checkpoint_file}\")\n",
    "    with open(checkpoint_file, 'r') as f:\n",
    "        checkpoint = json.load(f)\n",
    "    llm_predictions = checkpoint['predictions']\n",
    "    actual_prices = checkpoint['actual_prices']\n",
    "    llm_results = checkpoint.get('llm_results', [])\n",
    "    start_idx = checkpoint['last_idx'] + 1\n",
    "    print(f\"Resuming from index {start_idx}/{len(test_data)}\")\n",
    "else:\n",
    "    llm_predictions = []\n",
    "    actual_prices = []\n",
    "    llm_results = []\n",
    "    start_idx = 0\n",
    "    print(\"Starting fresh LLM predictions...\")\n",
    "\n",
    "# Run LLM predictions with rate limiting and checkpointing\n",
    "print(f\"Generating LLM predictions for {len(test_data)} samples...\")\n",
    "print(\"This may take a while due to API rate limits...\")\n",
    "\n",
    "for idx in tqdm(range(start_idx, len(test_data)), desc=\"LLM Inference\"):\n",
    "    item = test_data[idx]\n",
    "    \n",
    "    try:\n",
    "        # Get LLM prediction\n",
    "        llm_result = llm_predict_stock_price(item['prompt'])\n",
    "        \n",
    "        # Store full LLM result\n",
    "        llm_results.append(llm_result)\n",
    "        \n",
    "        # Extract prediction\n",
    "        if llm_result['predicted_close'] is not None:\n",
    "            llm_predictions.append(llm_result['predicted_close'])\n",
    "        else:\n",
    "            # Fallback: use a simple baseline if LLM fails\n",
    "            response = json.loads(item['response'])\n",
    "            llm_predictions.append(response['predicted_close'])\n",
    "        \n",
    "        # Get actual price from response\n",
    "        response = json.loads(item['response'])\n",
    "        actual_prices.append(response['predicted_close'])\n",
    "        \n",
    "        # Small delay to avoid rate limiting (adjust based on your API limits)\n",
    "        #time.sleep(0.5)\n",
    "\n",
    "        # Checkpoint every 50 samples\n",
    "        if (idx + 1) % 50 == 0:\n",
    "            checkpoint = {\n",
    "                'predictions': llm_predictions,\n",
    "                'actual_prices': actual_prices,\n",
    "                'llm_results': llm_results,\n",
    "                'last_idx': idx\n",
    "            }\n",
    "            os.makedirs('../results', exist_ok=True)\n",
    "            with open(checkpoint_file, 'w') as f:\n",
    "                json.dump(checkpoint, f, indent=2)\n",
    "            print(f\"Checkpoint saved at index {idx + 1}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        \n",
    "        # Handle rate limiting\n",
    "        if 'rate_limit' in error_msg.lower() or 'too many requests' in error_msg.lower():\n",
    "            print(f\"‚ùå RATE LIMIT HIT at index {idx}!\")\n",
    "            print(f\"Saving checkpoint and stopping execution...\")\n",
    "            \n",
    "            # Save checkpoint\n",
    "            checkpoint = {\n",
    "                'predictions': llm_predictions,\n",
    "                'actual_prices': actual_prices,\n",
    "                'llm_results': llm_results,\n",
    "                'last_idx': idx - 1\n",
    "            }\n",
    "            os.makedirs('../results', exist_ok=True)\n",
    "            with open(checkpoint_file, 'w') as f:\n",
    "                json.dump(checkpoint, f, indent=2)\n",
    "            \n",
    "            print(f\"‚úÖ Checkpoint saved to: {checkpoint_file}\")\n",
    "            print(f\"üìä Progress: {idx}/{len(test_data)} samples completed\")\n",
    "            print(f\"üí° Run this cell again to resume from where you left off.\")\n",
    "            break  # Stop execution\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Error at index {idx}: {error_msg}\")\n",
    "            # Store error result\n",
    "            error_result = {\"predicted_close\": None, \"likelihood\": 0.5, \"justification\": f\"Error: {error_msg}\"}\n",
    "            llm_results.append(error_result)\n",
    "            # Use fallback\n",
    "            response = json.loads(item['response'])\n",
    "            llm_predictions.append(response['predicted_close'])\n",
    "            actual_prices.append(response['predicted_close'])\n",
    "\n",
    "# Final save\n",
    "checkpoint = {\n",
    "    'predictions': llm_predictions,\n",
    "    'actual_prices': actual_prices,\n",
    "    'llm_results': llm_results,\n",
    "    'last_idx': len(llm_predictions) - 1,\n",
    "    'completed': len(llm_predictions) == len(test_data)\n",
    "}\n",
    "with open(checkpoint_file, 'w') as f:\n",
    "    json.dump(checkpoint, f, indent=2)\n",
    "\n",
    "# Merge with test_df\n",
    "test_df['llm_prediction'] = llm_predictions\n",
    "test_df['actual_price'] = actual_prices\n",
    "\n",
    "if len(llm_results) == len(test_df):\n",
    "    justifications = []\n",
    "    likelihoods = []\n",
    "    feature_rows = []\n",
    "    for res in llm_results:\n",
    "        res = res if isinstance(res, dict) else {}\n",
    "        justification = res.get('justification', '')\n",
    "        justifications.append(justification)\n",
    "        likelihoods.append(safe_float(res.get('likelihood'), 0.5))\n",
    "        feature_rows.append(extract_justification_features(justification))\n",
    "else:\n",
    "    justifications = [''] * len(test_df)\n",
    "    likelihoods = [0.5] * len(test_df)\n",
    "    feature_rows = [extract_justification_features('') for _ in range(len(test_df))]\n",
    "\n",
    "if feature_rows:\n",
    "    feature_keys = list(feature_rows[0].keys())\n",
    "else:\n",
    "    feature_keys = list(extract_justification_features('').keys())\n",
    "\n",
    "test_df['llm_justification'] = justifications\n",
    "test_df['llm_likelihood'] = likelihoods\n",
    "for key in feature_keys:\n",
    "    test_df[key] = [row[key] for row in feature_rows]\n",
    "\n",
    "if len(llm_predictions) == len(test_data):\n",
    "    print(f\"‚úÖ LLM predictions completed: {len(llm_predictions)} samples\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Partial completion: {len(llm_predictions)}/{len(test_data)} samples\")\n",
    "print(f\"Checkpoint saved to: {checkpoint_file}\")\n",
    "print(\"Sample predictions:\")\n",
    "print(test_df[['ticker', 'llm_prediction', 'actual_price']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e6e7a4",
   "metadata": {},
   "source": [
    "### 4.4 Check for Failed Predictions in Checkpoints\n",
    "\n",
    "Before training PPO, let's verify all predictions succeeded and fix any failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e1e8b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check for failed predictions in all checkpoint files\n",
    "# import json\n",
    "# import os\n",
    "\n",
    "# def check_failed_predictions(checkpoint_file, data_name):\n",
    "#     \"\"\"Check for failed/None predictions in checkpoint\"\"\"\n",
    "#     if not os.path.exists(checkpoint_file):\n",
    "#         print(f\"‚ùå {data_name} checkpoint not found: {checkpoint_file}\")\n",
    "#         return None\n",
    "    \n",
    "#     with open(checkpoint_file, 'r') as f:\n",
    "#         checkpoint = json.load(f)\n",
    "    \n",
    "#     predictions = checkpoint.get('predictions', [])\n",
    "#     llm_results = checkpoint.get('llm_results', [])\n",
    "    \n",
    "#     # Find indices with failed predictions\n",
    "#     failed_indices = []\n",
    "#     for idx, (pred, result) in enumerate(zip(predictions, llm_results)):\n",
    "#         if pred is None or (isinstance(result, dict) and result.get('predicted_close') is None):\n",
    "#             failed_indices.append(idx)\n",
    "    \n",
    "#     print(f\"\\n{'='*80}\")\n",
    "#     print(f\"üìä {data_name.upper()} CHECKPOINT ANALYSIS\")\n",
    "#     print(f\"{'='*80}\")\n",
    "#     print(f\"Total predictions: {len(predictions)}\")\n",
    "#     print(f\"Failed predictions: {len(failed_indices)}\")\n",
    "#     print(f\"Success rate: {((len(predictions) - len(failed_indices)) / len(predictions) * 100):.2f}%\")\n",
    "    \n",
    "#     if failed_indices:\n",
    "#         print(f\"\\n‚ö†Ô∏è Failed prediction indices (first 20): {failed_indices[:20]}\")\n",
    "#         if len(failed_indices) > 20:\n",
    "#             print(f\"   ... and {len(failed_indices) - 20} more\")\n",
    "#     else:\n",
    "#         print(f\"\\n‚úÖ All predictions successful!\")\n",
    "    \n",
    "#     return {\n",
    "#         'checkpoint_file': checkpoint_file,\n",
    "#         'total': len(predictions),\n",
    "#         'failed': len(failed_indices),\n",
    "#         'failed_indices': failed_indices,\n",
    "#         'checkpoint': checkpoint\n",
    "#     }\n",
    "\n",
    "# # Check all three checkpoints\n",
    "# print(\"üîç CHECKING ALL CHECKPOINT FILES FOR FAILED PREDICTIONS\")\n",
    "# print(\"=\"*80)\n",
    "\n",
    "# train_check = check_failed_predictions(\n",
    "#     '../results/llm_predictions_train_checkpoint.json', \n",
    "#     'Training'\n",
    "# )\n",
    "\n",
    "# val_check = check_failed_predictions(\n",
    "#     '../results/llm_predictions_val_checkpoint.json', \n",
    "#     'Validation'\n",
    "# )\n",
    "\n",
    "# test_check = check_failed_predictions(\n",
    "#     '../results/llm_predictions_checkpoint.json', \n",
    "#     'Test'\n",
    "# )\n",
    "\n",
    "# # Summary\n",
    "# print(f\"\\n{'='*80}\")\n",
    "# print(f\"üìà OVERALL SUMMARY\")\n",
    "# print(f\"{'='*80}\")\n",
    "# if train_check:\n",
    "#     print(f\"Training:   {train_check['failed']}/{train_check['total']} failed\")\n",
    "# if val_check:\n",
    "#     print(f\"Validation: {val_check['failed']}/{val_check['total']} failed\")\n",
    "# if test_check:\n",
    "#     print(f\"Test:       {test_check['failed']}/{test_check['total']} failed\")\n",
    "\n",
    "# total_failed = 0\n",
    "# total_samples = 0\n",
    "# if train_check:\n",
    "#     total_failed += train_check['failed']\n",
    "#     total_samples += train_check['total']\n",
    "# if val_check:\n",
    "#     total_failed += val_check['failed']\n",
    "#     total_samples += val_check['total']\n",
    "# if test_check:\n",
    "#     total_failed += test_check['failed']\n",
    "#     total_samples += test_check['total']\n",
    "\n",
    "# print(f\"\\nTotal failed: {total_failed}/{total_samples} ({(total_failed/total_samples*100):.2f}%)\")\n",
    "# print(f\"\\nüí° If any predictions failed, run the next cell to fix them.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6689abd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Re-run inference ONLY for failed predictions\n",
    "# def fix_failed_predictions(checkpoint_info, original_data, data_name):\n",
    "#     \"\"\"Re-run inference for failed predictions only\"\"\"\n",
    "#     if not checkpoint_info or not checkpoint_info['failed_indices']:\n",
    "#         print(f\"‚úÖ {data_name}: No failed predictions to fix!\")\n",
    "#         return checkpoint_info['checkpoint']\n",
    "    \n",
    "#     print(f\"\\n{'='*80}\")\n",
    "#     print(f\"üîÑ FIXING FAILED PREDICTIONS FOR {data_name.upper()}\")\n",
    "#     print(f\"{'='*80}\")\n",
    "#     print(f\"Failed predictions to fix: {len(checkpoint_info['failed_indices'])}\")\n",
    "    \n",
    "#     checkpoint = checkpoint_info['checkpoint']\n",
    "#     predictions = checkpoint['predictions']\n",
    "#     actual_prices = checkpoint['actual_prices']\n",
    "#     llm_results = checkpoint['llm_results']\n",
    "    \n",
    "#     fixed_count = 0\n",
    "#     still_failed = []\n",
    "    \n",
    "#     for idx in tqdm(checkpoint_info['failed_indices'], desc=f\"Fixing {data_name}\"):\n",
    "#         try:\n",
    "#             item = original_data[idx]\n",
    "            \n",
    "#             # Re-run LLM prediction\n",
    "#             llm_result = llm_predict_stock_price(item['prompt'])\n",
    "            \n",
    "#             # Update results\n",
    "#             llm_results[idx] = llm_result\n",
    "            \n",
    "#             # Update prediction\n",
    "#             if llm_result['predicted_close'] is not None:\n",
    "#                 predictions[idx] = llm_result['predicted_close']\n",
    "#                 fixed_count += 1\n",
    "#             else:\n",
    "#                 # Still failed, use fallback\n",
    "#                 response = json.loads(item['response'])\n",
    "#                 predictions[idx] = response['predicted_close']\n",
    "#                 still_failed.append(idx)\n",
    "            \n",
    "#             # Small delay\n",
    "#             time.sleep(0.3)\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             print(f\"\\n‚ö†Ô∏è Error fixing index {idx}: {e}\")\n",
    "#             still_failed.append(idx)\n",
    "#             # Use fallback\n",
    "#             try:\n",
    "#                 response = json.loads(original_data[idx]['response'])\n",
    "#                 predictions[idx] = response['predicted_close']\n",
    "#             except:\n",
    "#                 pass\n",
    "    \n",
    "#     # Save updated checkpoint\n",
    "#     checkpoint['predictions'] = predictions\n",
    "#     checkpoint['llm_results'] = llm_results\n",
    "#     checkpoint['last_idx'] = len(predictions) - 1\n",
    "#     checkpoint['completed'] = True\n",
    "    \n",
    "#     with open(checkpoint_info['checkpoint_file'], 'w') as f:\n",
    "#         json.dump(checkpoint, f, indent=2)\n",
    "    \n",
    "#     print(f\"\\n‚úÖ Fixed {fixed_count}/{len(checkpoint_info['failed_indices'])} predictions\")\n",
    "#     if still_failed:\n",
    "#         print(f\"‚ö†Ô∏è Still failed: {len(still_failed)} predictions (using fallback values)\")\n",
    "#         print(f\"   Indices: {still_failed[:10]}\")\n",
    "#     print(f\"üíæ Updated checkpoint saved to: {checkpoint_info['checkpoint_file']}\")\n",
    "    \n",
    "#     return checkpoint\n",
    "\n",
    "# # Fix training data\n",
    "# if train_check and train_check['failed'] > 0:\n",
    "#     print(\"\\n\" + \"=\"*80)\n",
    "#     print(\"FIXING TRAINING DATA\")\n",
    "#     print(\"=\"*80)\n",
    "#     train_checkpoint_fixed = fix_failed_predictions(train_check, train_data, \"Training\")\n",
    "#     # Update global variables\n",
    "#     train_llm_predictions = train_checkpoint_fixed['predictions']\n",
    "#     train_actual_prices = train_checkpoint_fixed['actual_prices']\n",
    "#     train_llm_results = train_checkpoint_fixed['llm_results']\n",
    "#     print(f\"‚úÖ Training data updated: {len(train_llm_predictions)} predictions\")\n",
    "\n",
    "# # Fix validation data\n",
    "# if val_check and val_check['failed'] > 0:\n",
    "#     print(\"\\n\" + \"=\"*80)\n",
    "#     print(\"FIXING VALIDATION DATA\")\n",
    "#     print(\"=\"*80)\n",
    "#     val_checkpoint_fixed = fix_failed_predictions(val_check, val_data, \"Validation\")\n",
    "#     # Update global variables\n",
    "#     val_llm_predictions = val_checkpoint_fixed['predictions']\n",
    "#     val_actual_prices = val_checkpoint_fixed['actual_prices']\n",
    "#     val_llm_results = val_checkpoint_fixed['llm_results']\n",
    "#     print(f\"‚úÖ Validation data updated: {len(val_llm_predictions)} predictions\")\n",
    "\n",
    "# # Fix test data\n",
    "# if test_check and test_check['failed'] > 0:\n",
    "#     print(\"\\n\" + \"=\"*80)\n",
    "#     print(\"FIXING TEST DATA\")\n",
    "#     print(\"=\"*80)\n",
    "#     test_checkpoint_fixed = fix_failed_predictions(test_check, test_data, \"Test\")\n",
    "#     # Update global variables\n",
    "#     llm_predictions = test_checkpoint_fixed['predictions']\n",
    "#     actual_prices = test_checkpoint_fixed['actual_prices']\n",
    "#     llm_results = test_checkpoint_fixed['llm_results']\n",
    "#     print(f\"‚úÖ Test data updated: {len(llm_predictions)} predictions\")\n",
    "    \n",
    "#     # Update test_df\n",
    "#     test_df['llm_prediction'] = llm_predictions\n",
    "#     test_df['actual_price'] = actual_prices\n",
    "    \n",
    "#     # Update justification features\n",
    "#     justifications = []\n",
    "#     likelihoods = []\n",
    "#     feature_rows = []\n",
    "#     for res in llm_results:\n",
    "#         res = res if isinstance(res, dict) else {}\n",
    "#         justification = res.get('justification', '')\n",
    "#         justifications.append(justification)\n",
    "#         likelihoods.append(safe_float(res.get('likelihood'), 0.5))\n",
    "#         feature_rows.append(extract_justification_features(justification))\n",
    "    \n",
    "#     test_df['llm_justification'] = justifications\n",
    "#     test_df['llm_likelihood'] = likelihoods\n",
    "    \n",
    "#     feature_keys = list(feature_rows[0].keys()) if feature_rows else []\n",
    "#     for key in feature_keys:\n",
    "#         test_df[key] = [row[key] for row in feature_rows]\n",
    "\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"‚úÖ ALL FAILED PREDICTIONS HAVE BEEN PROCESSED!\")\n",
    "# print(\"=\"*80)\n",
    "# print(\"You can now proceed with PPO training.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
